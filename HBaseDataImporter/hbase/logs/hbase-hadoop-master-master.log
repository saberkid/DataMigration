Sun Nov  8 13:42:09 CST 2015 Starting master on master
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 30141
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 10240
cpu time               (seconds, -t) unlimited
max user processes              (-u) 1024
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2015-11-08 13:42:09,659 INFO  [main] util.VersionInfo: HBase 1.1.2
2015-11-08 13:42:09,659 INFO  [main] util.VersionInfo: Source code repository git://hw11397.local/Volumes/hbase-1.1.2RC2/hbase revision=cc2b70cf03e3378800661ec5cab11eb43fafe0fc
2015-11-08 13:42:09,659 INFO  [main] util.VersionInfo: Compiled by ndimiduk on Wed Aug 26 20:11:27 PDT 2015
2015-11-08 13:42:09,659 INFO  [main] util.VersionInfo: From source with checksum 73da41f3d1b867b7aba6166c77fafc17
2015-11-08 13:42:10,018 INFO  [main] master.HMasterCommandLine: Starting a zookeeper cluster
2015-11-08 13:42:10,056 INFO  [main] server.ZooKeeperServer: Server environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2015-11-08 13:42:10,056 INFO  [main] server.ZooKeeperServer: Server environment:host.name=master
2015-11-08 13:42:10,056 INFO  [main] server.ZooKeeperServer: Server environment:java.version=1.7.0_79
2015-11-08 13:42:10,056 INFO  [main] server.ZooKeeperServer: Server environment:java.vendor=Oracle Corporation
2015-11-08 13:42:10,056 INFO  [main] server.ZooKeeperServer: Server environment:java.home=/opt/java/jre
2015-11-08 13:42:10,056 INFO  [main] server.ZooKeeperServer: Server environment:java.class.path=/opt/hbase/bin/../conf:/opt/java/lib/tools.jar:/opt/hbase/bin/..:/opt/hbase/bin/../lib/activation-1.1.jar:/opt/hbase/bin/../lib/aopalliance-1.0.jar:/opt/hbase/bin/../lib/apacheds-i18n-2.0.0-M15.jar:/opt/hbase/bin/../lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hbase/bin/../lib/api-asn1-api-1.0.0-M20.jar:/opt/hbase/bin/../lib/api-util-1.0.0-M20.jar:/opt/hbase/bin/../lib/asm-3.1.jar:/opt/hbase/bin/../lib/avro-1.7.4.jar:/opt/hbase/bin/../lib/commons-beanutils-1.7.0.jar:/opt/hbase/bin/../lib/commons-beanutils-core-1.8.0.jar:/opt/hbase/bin/../lib/commons-cli-1.2.jar:/opt/hbase/bin/../lib/commons-codec-1.9.jar:/opt/hbase/bin/../lib/commons-collections-3.2.1.jar:/opt/hbase/bin/../lib/commons-compress-1.4.1.jar:/opt/hbase/bin/../lib/commons-configuration-1.6.jar:/opt/hbase/bin/../lib/commons-daemon-1.0.13.jar:/opt/hbase/bin/../lib/commons-digester-1.8.jar:/opt/hbase/bin/../lib/commons-el-1.0.jar:/opt/hbase/bin/../lib/commons-httpclient-3.1.jar:/opt/hbase/bin/../lib/commons-io-2.4.jar:/opt/hbase/bin/../lib/commons-lang-2.6.jar:/opt/hbase/bin/../lib/commons-logging-1.2.jar:/opt/hbase/bin/../lib/commons-math-2.2.jar:/opt/hbase/bin/../lib/commons-math3-3.1.1.jar:/opt/hbase/bin/../lib/commons-net-3.1.jar:/opt/hbase/bin/../lib/disruptor-3.3.0.jar:/opt/hbase/bin/../lib/findbugs-annotations-1.3.9-1.jar:/opt/hbase/bin/../lib/guava-12.0.1.jar:/opt/hbase/bin/../lib/guice-3.0.jar:/opt/hbase/bin/../lib/guice-servlet-3.0.jar:/opt/hbase/bin/../lib/hadoop-annotations-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-auth-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-client-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-common-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-hdfs-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-app-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-common-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-core-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-jobclient-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-shuffle-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-api-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-client-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-common-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-server-common-2.5.1.jar:/opt/hbase/bin/../lib/hbase-annotations-1.1.2.jar:/opt/hbase/bin/../lib/hbase-annotations-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-client-1.1.2.jar:/opt/hbase/bin/../lib/hbase-common-1.1.2.jar:/opt/hbase/bin/../lib/hbase-common-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-examples-1.1.2.jar:/opt/hbase/bin/../lib/hbase-hadoop2-compat-1.1.2.jar:/opt/hbase/bin/../lib/hbase-hadoop-compat-1.1.2.jar:/opt/hbase/bin/../lib/hbase-it-1.1.2.jar:/opt/hbase/bin/../lib/hbase-it-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-prefix-tree-1.1.2.jar:/opt/hbase/bin/../lib/hbase-procedure-1.1.2.jar:/opt/hbase/bin/../lib/hbase-protocol-1.1.2.jar:/opt/hbase/bin/../lib/hbase-resource-bundle-1.1.2.jar:/opt/hbase/bin/../lib/hbase-rest-1.1.2.jar:/opt/hbase/bin/../lib/hbase-server-1.1.2.jar:/opt/hbase/bin/../lib/hbase-server-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-shell-1.1.2.jar:/opt/hbase/bin/../lib/hbase-thrift-1.1.2.jar:/opt/hbase/bin/../lib/htrace-core-3.1.0-incubating.jar:/opt/hbase/bin/../lib/httpclient-4.2.5.jar:/opt/hbase/bin/../lib/httpcore-4.1.3.jar:/opt/hbase/bin/../lib/jackson-core-asl-1.9.13.jar:/opt/hbase/bin/../lib/jackson-jaxrs-1.9.13.jar:/opt/hbase/bin/../lib/jackson-mapper-asl-1.9.13.jar:/opt/hbase/bin/../lib/jackson-xc-1.9.13.jar:/opt/hbase/bin/../lib/jamon-runtime-2.3.1.jar:/opt/hbase/bin/../lib/jasper-compiler-5.5.23.jar:/opt/hbase/bin/../lib/jasper-runtime-5.5.23.jar:/opt/hbase/bin/../lib/javax.inject-1.jar:/opt/hbase/bin/../lib/java-xmlbuilder-0.4.jar:/opt/hbase/bin/../lib/jaxb-api-2.2.2.jar:/opt/hbase/bin/../lib/jaxb-impl-2.2.3-1.jar:/opt/hbase/bin/../lib/jcodings-1.0.8.jar:/opt/hbase/bin/../lib/jersey-client-1.9.jar:/opt/hbase/bin/../lib/jersey-core-1.9.jar:/opt/hbase/bin/../lib/jersey-guice-1.9.jar:/opt/hbase/bin/../lib/jersey-json-1.9.jar:/opt/hbase/bin/../lib/jersey-server-1.9.jar:/opt/hbase/bin/../lib/jets3t-0.9.0.jar:/opt/hbase/bin/../lib/jettison-1.3.3.jar:/opt/hbase/bin/../lib/jetty-6.1.26.jar:/opt/hbase/bin/../lib/jetty-sslengine-6.1.26.jar:/opt/hbase/bin/../lib/jetty-util-6.1.26.jar:/opt/hbase/bin/../lib/joni-2.1.2.jar:/opt/hbase/bin/../lib/jruby-complete-1.6.8.jar:/opt/hbase/bin/../lib/jsch-0.1.42.jar:/opt/hbase/bin/../lib/jsp-2.1-6.1.14.jar:/opt/hbase/bin/../lib/jsp-api-2.1-6.1.14.jar:/opt/hbase/bin/../lib/jsr305-1.3.9.jar:/opt/hbase/bin/../lib/junit-4.11.jar:/opt/hbase/bin/../lib/leveldbjni-all-1.8.jar:/opt/hbase/bin/../lib/libthrift-0.9.0.jar:/opt/hbase/bin/../lib/log4j-1.2.17.jar:/opt/hbase/bin/../lib/metrics-core-2.2.0.jar:/opt/hbase/bin/../lib/netty-3.2.4.Final.jar:/opt/hbase/bin/../lib/netty-all-4.0.23.Final.jar:/opt/hbase/bin/../lib/paranamer-2.3.jar:/opt/hbase/bin/../lib/protobuf-java-2.5.0.jar:/opt/hbase/bin/../lib/servlet-api-2.5-6.1.14.jar:/opt/hbase/bin/../lib/servlet-api-2.5.jar:/opt/hbase/bin/../lib/slf4j-api-1.7.7.jar:/opt/hbase/bin/../lib/slf4j-log4j12-1.7.5.jar:/opt/hbase/bin/../lib/snappy-java-1.0.4.1.jar:/opt/hbase/bin/../lib/spymemcached-2.11.6.jar:/opt/hbase/bin/../lib/xmlenc-0.52.jar:/opt/hbase/bin/../lib/xz-1.0.jar:/opt/hbase/bin/../lib/zookeeper-3.4.6.jar:/opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-auth-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/opt/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/opt/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop/share/hadoop/common/lib/curator-framework-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/opt/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/opt/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop/share/hadoop/common/lib/curator-client-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/opt/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-annotations-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/opt/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop/share/hadoop/common/lib/htrace-core-3.0.4.jar:/opt/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop/share/hadoop/common/hadoop-common-2.6.0-tests.jar:/opt/hadoop/share/hadoop/common/hadoop-common-2.6.0.jar:/opt/hadoop/share/hadoop/common/hadoop-nfs-2.6.0.jar:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/opt/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.0-tests.jar:/opt/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jline-0.9.94.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-tests.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar
2015-11-08 13:42:10,056 INFO  [main] server.ZooKeeperServer: Server environment:java.library.path=/opt/hadoop/lib/native::/opt/hadoop/lib/native:
2015-11-08 13:42:10,056 INFO  [main] server.ZooKeeperServer: Server environment:java.io.tmpdir=/tmp
2015-11-08 13:42:10,056 INFO  [main] server.ZooKeeperServer: Server environment:java.compiler=<NA>
2015-11-08 13:42:10,056 INFO  [main] server.ZooKeeperServer: Server environment:os.name=Linux
2015-11-08 13:42:10,056 INFO  [main] server.ZooKeeperServer: Server environment:os.arch=amd64
2015-11-08 13:42:10,056 INFO  [main] server.ZooKeeperServer: Server environment:os.version=2.6.32-573.el6.x86_64
2015-11-08 13:42:10,056 INFO  [main] server.ZooKeeperServer: Server environment:user.name=hadoop
2015-11-08 13:42:10,056 INFO  [main] server.ZooKeeperServer: Server environment:user.home=/home/hadoop
2015-11-08 13:42:10,057 INFO  [main] server.ZooKeeperServer: Server environment:user.dir=/opt/hbase/bin
2015-11-08 13:42:10,084 INFO  [main] server.ZooKeeperServer: Created server with tickTime 2000 minSessionTimeout 4000 maxSessionTimeout 40000 datadir /home/hadoop/zookeeper/zookeeper_0/version-2 snapdir /home/hadoop/zookeeper/zookeeper_0/version-2
2015-11-08 13:42:10,094 INFO  [main] server.NIOServerCnxnFactory: binding to port 0.0.0.0/0.0.0.0:2181
2015-11-08 13:42:10,173 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:60463
2015-11-08 13:42:10,180 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxn: Processing stat command from /127.0.0.1:60463
2015-11-08 13:42:10,184 INFO  [Thread-2] server.NIOServerCnxn: Stat command output
2015-11-08 13:42:10,185 INFO  [Thread-2] server.NIOServerCnxn: Closed socket connection for client /127.0.0.1:60463 (no session established for client)
2015-11-08 13:42:10,185 INFO  [main] zookeeper.MiniZooKeeperCluster: Started MiniZooKeeperCluster and ran successful 'stat' on client port=2181
2015-11-08 13:42:10,185 INFO  [main] master.HMasterCommandLine: Starting up instance of localHBaseCluster; master=1, regionserversCount=1
2015-11-08 13:42:10,600 WARN  [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-11-08 13:42:10,843 INFO  [main] regionserver.RSRpcServices: master/master/192.168.1.101:0 server-side HConnection retries=350
2015-11-08 13:42:10,974 INFO  [main] ipc.SimpleRpcScheduler: Using deadline as user call queue, count=3
2015-11-08 13:42:10,983 INFO  [main] ipc.RpcServer: master/master/192.168.1.101:0: started 10 reader(s).
2015-11-08 13:42:11,035 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2015-11-08 13:42:11,053 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-11-08 13:42:11,053 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2015-11-08 13:42:11,325 INFO  [main] zookeeper.RecoverableZooKeeper: Process identifier=master:34688 connecting to ZooKeeper ensemble=localhost:2181
2015-11-08 13:42:11,330 INFO  [main] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2015-11-08 13:42:11,330 INFO  [main] zookeeper.ZooKeeper: Client environment:host.name=master
2015-11-08 13:42:11,330 INFO  [main] zookeeper.ZooKeeper: Client environment:java.version=1.7.0_79
2015-11-08 13:42:11,330 INFO  [main] zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
2015-11-08 13:42:11,330 INFO  [main] zookeeper.ZooKeeper: Client environment:java.home=/opt/java/jre
2015-11-08 13:42:11,331 INFO  [main] zookeeper.ZooKeeper: Client environment:java.class.path=/opt/hbase/bin/../conf:/opt/java/lib/tools.jar:/opt/hbase/bin/..:/opt/hbase/bin/../lib/activation-1.1.jar:/opt/hbase/bin/../lib/aopalliance-1.0.jar:/opt/hbase/bin/../lib/apacheds-i18n-2.0.0-M15.jar:/opt/hbase/bin/../lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hbase/bin/../lib/api-asn1-api-1.0.0-M20.jar:/opt/hbase/bin/../lib/api-util-1.0.0-M20.jar:/opt/hbase/bin/../lib/asm-3.1.jar:/opt/hbase/bin/../lib/avro-1.7.4.jar:/opt/hbase/bin/../lib/commons-beanutils-1.7.0.jar:/opt/hbase/bin/../lib/commons-beanutils-core-1.8.0.jar:/opt/hbase/bin/../lib/commons-cli-1.2.jar:/opt/hbase/bin/../lib/commons-codec-1.9.jar:/opt/hbase/bin/../lib/commons-collections-3.2.1.jar:/opt/hbase/bin/../lib/commons-compress-1.4.1.jar:/opt/hbase/bin/../lib/commons-configuration-1.6.jar:/opt/hbase/bin/../lib/commons-daemon-1.0.13.jar:/opt/hbase/bin/../lib/commons-digester-1.8.jar:/opt/hbase/bin/../lib/commons-el-1.0.jar:/opt/hbase/bin/../lib/commons-httpclient-3.1.jar:/opt/hbase/bin/../lib/commons-io-2.4.jar:/opt/hbase/bin/../lib/commons-lang-2.6.jar:/opt/hbase/bin/../lib/commons-logging-1.2.jar:/opt/hbase/bin/../lib/commons-math-2.2.jar:/opt/hbase/bin/../lib/commons-math3-3.1.1.jar:/opt/hbase/bin/../lib/commons-net-3.1.jar:/opt/hbase/bin/../lib/disruptor-3.3.0.jar:/opt/hbase/bin/../lib/findbugs-annotations-1.3.9-1.jar:/opt/hbase/bin/../lib/guava-12.0.1.jar:/opt/hbase/bin/../lib/guice-3.0.jar:/opt/hbase/bin/../lib/guice-servlet-3.0.jar:/opt/hbase/bin/../lib/hadoop-annotations-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-auth-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-client-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-common-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-hdfs-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-app-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-common-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-core-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-jobclient-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-shuffle-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-api-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-client-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-common-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-server-common-2.5.1.jar:/opt/hbase/bin/../lib/hbase-annotations-1.1.2.jar:/opt/hbase/bin/../lib/hbase-annotations-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-client-1.1.2.jar:/opt/hbase/bin/../lib/hbase-common-1.1.2.jar:/opt/hbase/bin/../lib/hbase-common-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-examples-1.1.2.jar:/opt/hbase/bin/../lib/hbase-hadoop2-compat-1.1.2.jar:/opt/hbase/bin/../lib/hbase-hadoop-compat-1.1.2.jar:/opt/hbase/bin/../lib/hbase-it-1.1.2.jar:/opt/hbase/bin/../lib/hbase-it-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-prefix-tree-1.1.2.jar:/opt/hbase/bin/../lib/hbase-procedure-1.1.2.jar:/opt/hbase/bin/../lib/hbase-protocol-1.1.2.jar:/opt/hbase/bin/../lib/hbase-resource-bundle-1.1.2.jar:/opt/hbase/bin/../lib/hbase-rest-1.1.2.jar:/opt/hbase/bin/../lib/hbase-server-1.1.2.jar:/opt/hbase/bin/../lib/hbase-server-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-shell-1.1.2.jar:/opt/hbase/bin/../lib/hbase-thrift-1.1.2.jar:/opt/hbase/bin/../lib/htrace-core-3.1.0-incubating.jar:/opt/hbase/bin/../lib/httpclient-4.2.5.jar:/opt/hbase/bin/../lib/httpcore-4.1.3.jar:/opt/hbase/bin/../lib/jackson-core-asl-1.9.13.jar:/opt/hbase/bin/../lib/jackson-jaxrs-1.9.13.jar:/opt/hbase/bin/../lib/jackson-mapper-asl-1.9.13.jar:/opt/hbase/bin/../lib/jackson-xc-1.9.13.jar:/opt/hbase/bin/../lib/jamon-runtime-2.3.1.jar:/opt/hbase/bin/../lib/jasper-compiler-5.5.23.jar:/opt/hbase/bin/../lib/jasper-runtime-5.5.23.jar:/opt/hbase/bin/../lib/javax.inject-1.jar:/opt/hbase/bin/../lib/java-xmlbuilder-0.4.jar:/opt/hbase/bin/../lib/jaxb-api-2.2.2.jar:/opt/hbase/bin/../lib/jaxb-impl-2.2.3-1.jar:/opt/hbase/bin/../lib/jcodings-1.0.8.jar:/opt/hbase/bin/../lib/jersey-client-1.9.jar:/opt/hbase/bin/../lib/jersey-core-1.9.jar:/opt/hbase/bin/../lib/jersey-guice-1.9.jar:/opt/hbase/bin/../lib/jersey-json-1.9.jar:/opt/hbase/bin/../lib/jersey-server-1.9.jar:/opt/hbase/bin/../lib/jets3t-0.9.0.jar:/opt/hbase/bin/../lib/jettison-1.3.3.jar:/opt/hbase/bin/../lib/jetty-6.1.26.jar:/opt/hbase/bin/../lib/jetty-sslengine-6.1.26.jar:/opt/hbase/bin/../lib/jetty-util-6.1.26.jar:/opt/hbase/bin/../lib/joni-2.1.2.jar:/opt/hbase/bin/../lib/jruby-complete-1.6.8.jar:/opt/hbase/bin/../lib/jsch-0.1.42.jar:/opt/hbase/bin/../lib/jsp-2.1-6.1.14.jar:/opt/hbase/bin/../lib/jsp-api-2.1-6.1.14.jar:/opt/hbase/bin/../lib/jsr305-1.3.9.jar:/opt/hbase/bin/../lib/junit-4.11.jar:/opt/hbase/bin/../lib/leveldbjni-all-1.8.jar:/opt/hbase/bin/../lib/libthrift-0.9.0.jar:/opt/hbase/bin/../lib/log4j-1.2.17.jar:/opt/hbase/bin/../lib/metrics-core-2.2.0.jar:/opt/hbase/bin/../lib/netty-3.2.4.Final.jar:/opt/hbase/bin/../lib/netty-all-4.0.23.Final.jar:/opt/hbase/bin/../lib/paranamer-2.3.jar:/opt/hbase/bin/../lib/protobuf-java-2.5.0.jar:/opt/hbase/bin/../lib/servlet-api-2.5-6.1.14.jar:/opt/hbase/bin/../lib/servlet-api-2.5.jar:/opt/hbase/bin/../lib/slf4j-api-1.7.7.jar:/opt/hbase/bin/../lib/slf4j-log4j12-1.7.5.jar:/opt/hbase/bin/../lib/snappy-java-1.0.4.1.jar:/opt/hbase/bin/../lib/spymemcached-2.11.6.jar:/opt/hbase/bin/../lib/xmlenc-0.52.jar:/opt/hbase/bin/../lib/xz-1.0.jar:/opt/hbase/bin/../lib/zookeeper-3.4.6.jar:/opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-auth-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/opt/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/opt/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop/share/hadoop/common/lib/curator-framework-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/opt/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/opt/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop/share/hadoop/common/lib/curator-client-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/opt/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-annotations-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/opt/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop/share/hadoop/common/lib/htrace-core-3.0.4.jar:/opt/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop/share/hadoop/common/hadoop-common-2.6.0-tests.jar:/opt/hadoop/share/hadoop/common/hadoop-common-2.6.0.jar:/opt/hadoop/share/hadoop/common/hadoop-nfs-2.6.0.jar:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/opt/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.0-tests.jar:/opt/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jline-0.9.94.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-tests.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar
2015-11-08 13:42:11,331 INFO  [main] zookeeper.ZooKeeper: Client environment:java.library.path=/opt/hadoop/lib/native::/opt/hadoop/lib/native:
2015-11-08 13:42:11,331 INFO  [main] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2015-11-08 13:42:11,331 INFO  [main] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2015-11-08 13:42:11,331 INFO  [main] zookeeper.ZooKeeper: Client environment:os.name=Linux
2015-11-08 13:42:11,331 INFO  [main] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2015-11-08 13:42:11,331 INFO  [main] zookeeper.ZooKeeper: Client environment:os.version=2.6.32-573.el6.x86_64
2015-11-08 13:42:11,331 INFO  [main] zookeeper.ZooKeeper: Client environment:user.name=hadoop
2015-11-08 13:42:11,331 INFO  [main] zookeeper.ZooKeeper: Client environment:user.home=/home/hadoop
2015-11-08 13:42:11,331 INFO  [main] zookeeper.ZooKeeper: Client environment:user.dir=/opt/hbase/bin
2015-11-08 13:42:11,332 INFO  [main] zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=10000 watcher=master:346880x0, quorum=localhost:2181, baseZNode=/hbase
2015-11-08 13:42:11,351 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 13:42:11,351 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:60464
2015-11-08 13:42:11,351 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
2015-11-08 13:42:11,355 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.ZooKeeperServer: Client attempting to establish new session at /127.0.0.1:60464
2015-11-08 13:42:11,358 INFO  [SyncThread:0] persistence.FileTxnLog: Creating new log file: log.1
2015-11-08 13:42:11,404 INFO  [SyncThread:0] server.ZooKeeperServer: Established session 0x150e59db7b40000 with negotiated timeout 10000 for client /127.0.0.1:60464
2015-11-08 13:42:11,405 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x150e59db7b40000, negotiated timeout = 10000
2015-11-08 13:42:11,519 INFO  [RpcServer.listener,port=34688] ipc.RpcServer: RpcServer.listener,port=34688: starting
2015-11-08 13:42:11,519 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2015-11-08 13:42:11,578 INFO  [main] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-11-08 13:42:11,583 INFO  [main] http.HttpRequestLog: Http request log for http.requests.master is not defined
2015-11-08 13:42:11,597 INFO  [main] http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.hbase.http.HttpServer$QuotingInputFilter)
2015-11-08 13:42:11,600 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context master
2015-11-08 13:42:11,600 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-11-08 13:42:11,600 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-11-08 13:42:11,618 INFO  [main] http.HttpServer: Jetty bound to port 16010
2015-11-08 13:42:11,618 INFO  [main] mortbay.log: jetty-6.1.26
2015-11-08 13:42:12,022 INFO  [main] mortbay.log: Started SelectChannelConnector@0.0.0.0:16010
2015-11-08 13:42:12,028 INFO  [main] master.HMaster: hbase.rootdir=file:/home/hadoop/HBase/HFiles, hbase.cluster.distributed=false
2015-11-08 13:42:12,044 INFO  [main] master.HMaster: Adding backup master ZNode /hbase/backup-masters/master,34688,1446961331067
2015-11-08 13:42:12,162 INFO  [master:34688.activeMasterManager] master.ActiveMasterManager: Deleting ZNode for /hbase/backup-masters/master,34688,1446961331067 from backup master directory
2015-11-08 13:42:12,170 INFO  [master:34688.activeMasterManager] master.ActiveMasterManager: Registered Active Master=master,34688,1446961331067
2015-11-08 13:42:12,173 INFO  [main] regionserver.RSRpcServices: regionserver/master/192.168.1.101:0 server-side HConnection retries=350
2015-11-08 13:42:12,173 INFO  [main] ipc.SimpleRpcScheduler: Using deadline as user call queue, count=3
2015-11-08 13:42:12,176 INFO  [main] ipc.RpcServer: regionserver/master/192.168.1.101:0: started 10 reader(s).
2015-11-08 13:42:12,177 INFO  [main] zookeeper.RecoverableZooKeeper: Process identifier=regionserver:47972 connecting to ZooKeeper ensemble=localhost:2181
2015-11-08 13:42:12,178 INFO  [main] zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=10000 watcher=regionserver:479720x0, quorum=localhost:2181, baseZNode=/hbase
2015-11-08 13:42:12,180 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 13:42:12,180 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
2015-11-08 13:42:12,180 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:60465
2015-11-08 13:42:12,181 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.ZooKeeperServer: Client attempting to establish new session at /127.0.0.1:60465
2015-11-08 13:42:12,184 INFO  [SyncThread:0] server.ZooKeeperServer: Established session 0x150e59db7b40001 with negotiated timeout 10000 for client /127.0.0.1:60465
2015-11-08 13:42:12,185 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x150e59db7b40001, negotiated timeout = 10000
2015-11-08 13:42:12,186 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2015-11-08 13:42:12,186 INFO  [RpcServer.listener,port=47972] ipc.RpcServer: RpcServer.listener,port=47972: starting
2015-11-08 13:42:12,191 INFO  [main] http.HttpRequestLog: Http request log for http.requests.regionserver is not defined
2015-11-08 13:42:12,191 INFO  [main] http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.hbase.http.HttpServer$QuotingInputFilter)
2015-11-08 13:42:12,193 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context regionserver
2015-11-08 13:42:12,193 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-11-08 13:42:12,193 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-11-08 13:42:12,195 INFO  [master:34688.activeMasterManager] util.FSUtils: Created version file at file:/home/hadoop/HBase/HFiles with version=8
2015-11-08 13:42:12,196 INFO  [main] http.HttpServer: Jetty bound to port 44721
2015-11-08 13:42:12,196 INFO  [main] mortbay.log: jetty-6.1.26
2015-11-08 13:42:12,233 INFO  [master:34688.activeMasterManager] master.MasterFileSystem: BOOTSTRAP: creating hbase:meta region
2015-11-08 13:42:12,235 INFO  [master:34688.activeMasterManager] regionserver.HRegion: creating HRegion hbase:meta HTD == 'hbase:meta', {TABLE_ATTRIBUTES => {IS_META => 'true', coprocessor$1 => '|org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint|536870911|'}, {NAME => 'info', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'NONE', REPLICATION_SCOPE => '0', COMPRESSION => 'NONE', VERSIONS => '10', TTL => 'FOREVER', MIN_VERSIONS => '0', KEEP_DELETED_CELLS => 'FALSE', BLOCKSIZE => '8192', IN_MEMORY => 'false', BLOCKCACHE => 'false'} RootDir = file:/home/hadoop/HBase/HFiles Table name == hbase:meta
2015-11-08 13:42:12,271 INFO  [master:34688.activeMasterManager] wal.WALFactory: Instantiating WALProvider of type class org.apache.hadoop.hbase.wal.DefaultWALProvider
2015-11-08 13:42:12,284 INFO  [master:34688.activeMasterManager] wal.FSHLog: WAL configuration: blocksize=32 MB, rollsize=30.40 MB, prefix=hregion-24548099.default, suffix=, logDir=file:/home/hadoop/HBase/HFiles/WALs/hregion-24548099, archiveDir=file:/home/hadoop/HBase/HFiles/oldWALs
2015-11-08 13:42:12,297 INFO  [master:34688.activeMasterManager] wal.FSHLog: Slow sync cost: 0 ms, current pipeline: []
2015-11-08 13:42:12,298 INFO  [master:34688.activeMasterManager] wal.FSHLog: New WAL /home/hadoop/HBase/HFiles/WALs/hregion-24548099/hregion-24548099.default.1446961332284
2015-11-08 13:42:12,298 INFO  [master:34688.activeMasterManager] wal.FSHLog: FileSystem's output stream doesn't support getNumCurrentReplicas; HDFS-826 not available; fsOut=java.io.BufferedOutputStream
2015-11-08 13:42:12,298 INFO  [master:34688.activeMasterManager] wal.FSHLog: FileSystem's output stream doesn't support getPipeline; not available; fsOut=java.io.BufferedOutputStream
2015-11-08 13:42:12,367 INFO  [main] mortbay.log: Started SelectChannelConnector@0.0.0.0:44721
2015-11-08 13:42:12,411 INFO  [StoreOpener-1588230740-1] hfile.CacheConfig: Allocating LruBlockCache size=743.50 MB, blockSize=64 KB
2015-11-08 13:42:12,430 INFO  [StoreOpener-1588230740-1] hfile.CacheConfig: blockCache=LruBlockCache{blockCount=0, currentSize=800720, freeSize=778815536, maxSize=779616256, heapSize=800720, minSize=740635456, minFactor=0.95, multiSize=370317728, multiFactor=0.5, singleSize=185158864, singleFactor=0.25}, cacheDataOnRead=false, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheDataCompressed=false, prefetchOnOpen=false
2015-11-08 13:42:12,440 INFO  [M:0;master:34688] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x49847f5 connecting to ZooKeeper ensemble=localhost:2181
2015-11-08 13:42:12,440 INFO  [M:0;master:34688] zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=10000 watcher=hconnection-0x49847f50x0, quorum=localhost:2181, baseZNode=/hbase
2015-11-08 13:42:12,441 INFO  [RS:0;master:47972] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x48afca92 connecting to ZooKeeper ensemble=localhost:2181
2015-11-08 13:42:12,441 INFO  [RS:0;master:47972] zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=10000 watcher=hconnection-0x48afca920x0, quorum=localhost:2181, baseZNode=/hbase
2015-11-08 13:42:12,443 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; major period 604800000, major jitter 0.500000, min locality to compact 0.000000
2015-11-08 13:42:12,451 INFO  [M:0;master:34688-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 13:42:12,452 INFO  [M:0;master:34688-SendThread(localhost:2181)] zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
2015-11-08 13:42:12,452 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:60466
2015-11-08 13:42:12,452 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.ZooKeeperServer: Client attempting to establish new session at /127.0.0.1:60466
2015-11-08 13:42:12,457 INFO  [RS:0;master:47972-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 13:42:12,457 INFO  [RS:0;master:47972-SendThread(localhost:2181)] zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
2015-11-08 13:42:12,457 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:60467
2015-11-08 13:42:12,458 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.ZooKeeperServer: Client attempting to establish new session at /127.0.0.1:60467
2015-11-08 13:42:12,481 INFO  [SyncThread:0] server.ZooKeeperServer: Established session 0x150e59db7b40002 with negotiated timeout 10000 for client /127.0.0.1:60466
2015-11-08 13:42:12,481 INFO  [M:0;master:34688-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x150e59db7b40002, negotiated timeout = 10000
2015-11-08 13:42:12,484 INFO  [master:34688.activeMasterManager] regionserver.HRegion: Onlined 1588230740; next sequenceid=2
2015-11-08 13:42:12,485 INFO  [StoreCloserThread-hbase:meta,,1.1588230740-1] regionserver.HStore: Closed info
2015-11-08 13:42:12,486 INFO  [master:34688.activeMasterManager] regionserver.HRegion: Closed hbase:meta,,1.1588230740
2015-11-08 13:42:12,487 INFO  [master:34688.activeMasterManager] wal.FSHLog: Closed WAL: FSHLog hregion-24548099.default:(num 1446961332284)
2015-11-08 13:42:12,493 INFO  [SyncThread:0] server.ZooKeeperServer: Established session 0x150e59db7b40003 with negotiated timeout 10000 for client /127.0.0.1:60467
2015-11-08 13:42:12,493 INFO  [RS:0;master:47972-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x150e59db7b40003, negotiated timeout = 10000
2015-11-08 13:42:12,494 INFO  [M:0;master:34688] client.ZooKeeperRegistry: ClusterId read in ZooKeeper is null
2015-11-08 13:42:12,498 INFO  [RS:0;master:47972] client.ZooKeeperRegistry: ClusterId read in ZooKeeper is null
2015-11-08 13:42:12,525 INFO  [master:34688.activeMasterManager] coordination.SplitLogManagerCoordination: Found 0 orphan tasks and 0 rescan nodes
2015-11-08 13:42:12,539 INFO  [master:34688.activeMasterManager] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x77db3f0d connecting to ZooKeeper ensemble=localhost:2181
2015-11-08 13:42:12,539 INFO  [master:34688.activeMasterManager] zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=10000 watcher=hconnection-0x77db3f0d0x0, quorum=localhost:2181, baseZNode=/hbase
2015-11-08 13:42:12,541 INFO  [master:34688.activeMasterManager-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 13:42:12,541 INFO  [master:34688.activeMasterManager-SendThread(localhost:2181)] zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
2015-11-08 13:42:12,541 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:60468
2015-11-08 13:42:12,542 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.ZooKeeperServer: Client attempting to establish new session at /127.0.0.1:60468
2015-11-08 13:42:12,551 INFO  [SyncThread:0] server.ZooKeeperServer: Established session 0x150e59db7b40004 with negotiated timeout 10000 for client /127.0.0.1:60468
2015-11-08 13:42:12,551 INFO  [master:34688.activeMasterManager-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x150e59db7b40004, negotiated timeout = 10000
2015-11-08 13:42:12,590 INFO  [master:34688.activeMasterManager] balancer.StochasticLoadBalancer: loading config
2015-11-08 13:42:12,636 INFO  [master:34688.activeMasterManager] master.HMaster: Server active/primary master=master,34688,1446961331067, sessionid=0x150e59db7b40000, setting cluster-up flag (Was=false)
2015-11-08 13:42:12,637 INFO  [M:0;master:34688] regionserver.HRegionServer: ClusterId : e22a8e48-7630-4b77-8089-9e2520c0a75f
2015-11-08 13:42:12,637 INFO  [RS:0;master:47972] regionserver.HRegionServer: ClusterId : e22a8e48-7630-4b77-8089-9e2520c0a75f
2015-11-08 13:42:12,646 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Got user-level KeeperException when processing sessionid:0x150e59db7b40001 type:create cxid:0x7 zxid:0x14 txntype:-1 reqpath:n/a Error Path:/hbase/online-snapshot Error:KeeperErrorCode = NoNode for /hbase/online-snapshot
2015-11-08 13:42:12,647 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Got user-level KeeperException when processing sessionid:0x150e59db7b40000 type:create cxid:0x2b zxid:0x15 txntype:-1 reqpath:n/a Error Path:/hbase/online-snapshot Error:KeeperErrorCode = NoNode for /hbase/online-snapshot
2015-11-08 13:42:12,660 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Got user-level KeeperException when processing sessionid:0x150e59db7b40000 type:create cxid:0x2c zxid:0x17 txntype:-1 reqpath:n/a Error Path:/hbase/online-snapshot Error:KeeperErrorCode = NodeExists for /hbase/online-snapshot
2015-11-08 13:42:12,677 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Got user-level KeeperException when processing sessionid:0x150e59db7b40000 type:create cxid:0x2d zxid:0x19 txntype:-1 reqpath:n/a Error Path:/hbase/online-snapshot/acquired Error:KeeperErrorCode = NodeExists for /hbase/online-snapshot/acquired
2015-11-08 13:42:12,694 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Got user-level KeeperException when processing sessionid:0x150e59db7b40000 type:create cxid:0x2f zxid:0x1b txntype:-1 reqpath:n/a Error Path:/hbase/online-snapshot/reached Error:KeeperErrorCode = NodeExists for /hbase/online-snapshot/reached
2015-11-08 13:42:12,711 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Got user-level KeeperException when processing sessionid:0x150e59db7b40000 type:create cxid:0x31 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/hbase/online-snapshot/abort Error:KeeperErrorCode = NodeExists for /hbase/online-snapshot/abort
2015-11-08 13:42:12,721 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Got user-level KeeperException when processing sessionid:0x150e59db7b40001 type:create cxid:0xe zxid:0x1e txntype:-1 reqpath:n/a Error Path:/hbase/flush-table-proc Error:KeeperErrorCode = NoNode for /hbase/flush-table-proc
2015-11-08 13:42:12,726 INFO  [master:34688.activeMasterManager] procedure.ZKProcedureUtil: Clearing all procedure znodes: /hbase/online-snapshot/acquired /hbase/online-snapshot/reached /hbase/online-snapshot/abort
2015-11-08 13:42:12,755 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Got user-level KeeperException when processing sessionid:0x150e59db7b40000 type:create cxid:0x35 zxid:0x22 txntype:-1 reqpath:n/a Error Path:/hbase/flush-table-proc/acquired Error:KeeperErrorCode = NodeExists for /hbase/flush-table-proc/acquired
2015-11-08 13:42:12,776 INFO  [master:34688.activeMasterManager] procedure.ZKProcedureUtil: Clearing all procedure znodes: /hbase/flush-table-proc/acquired /hbase/flush-table-proc/reached /hbase/flush-table-proc/abort
2015-11-08 13:42:12,782 INFO  [RS:0;master:47972] regionserver.MemStoreFlusher: globalMemStoreLimit=743.5 M, globalMemStoreLimitLowMark=706.3 M, maxHeap=1.8 G
2015-11-08 13:42:12,787 INFO  [RS:0;master:47972] regionserver.HRegionServer: CompactionChecker runs every 10sec
2015-11-08 13:42:12,810 INFO  [master:34688.activeMasterManager] master.MasterCoprocessorHost: System coprocessor loading is enabled
2015-11-08 13:42:12,814 INFO  [RS:0;master:47972] regionserver.RegionServerCoprocessorHost: System coprocessor loading is enabled
2015-11-08 13:42:12,814 INFO  [RS:0;master:47972] regionserver.RegionServerCoprocessorHost: Table coprocessor loading is enabled
2015-11-08 13:42:12,815 INFO  [RS:0;master:47972] regionserver.HRegionServer: reportForDuty to master=master,34688,1446961331067 with port=47972, startcode=1446961332176
2015-11-08 13:42:12,820 INFO  [master:34688.activeMasterManager] procedure2.ProcedureExecutor: Starting procedure executor threads=5
2015-11-08 13:42:12,820 INFO  [master:34688.activeMasterManager] wal.WALProcedureStore: Starting WAL Procedure Store lease recovery
2015-11-08 13:42:12,821 WARN  [master:34688.activeMasterManager] wal.WALProcedureStore: Log directory not found: File file:/home/hadoop/HBase/HFiles/MasterProcWALs does not exist
2015-11-08 13:42:12,827 INFO  [master:34688.activeMasterManager] wal.WALProcedureStore: Lease acquired for flushLogId: 1
2015-11-08 13:42:12,832 INFO  [master:34688.activeMasterManager] zookeeper.RecoverableZooKeeper: Process identifier=replicationLogCleaner connecting to ZooKeeper ensemble=localhost:2181
2015-11-08 13:42:12,832 INFO  [master:34688.activeMasterManager] zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=10000 watcher=replicationLogCleaner0x0, quorum=localhost:2181, baseZNode=/hbase
2015-11-08 13:42:12,834 INFO  [master:34688.activeMasterManager-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 13:42:12,834 INFO  [master:34688.activeMasterManager-SendThread(localhost:2181)] zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
2015-11-08 13:42:12,834 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:60469
2015-11-08 13:42:12,834 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.ZooKeeperServer: Client attempting to establish new session at /127.0.0.1:60469
2015-11-08 13:42:12,843 INFO  [SyncThread:0] server.ZooKeeperServer: Established session 0x150e59db7b40005 with negotiated timeout 10000 for client /127.0.0.1:60469
2015-11-08 13:42:12,843 INFO  [master:34688.activeMasterManager-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x150e59db7b40005, negotiated timeout = 10000
2015-11-08 13:42:12,843 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Got user-level KeeperException when processing sessionid:0x150e59db7b40005 type:create cxid:0x1 zxid:0x26 txntype:-1 reqpath:n/a Error Path:/hbase/replication Error:KeeperErrorCode = NoNode for /hbase/replication
2015-11-08 13:42:12,872 INFO  [master:34688.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 0 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2015-11-08 13:42:12,965 INFO  [PriorityRpcServer.handler=0,queue=0,port=34688] master.ServerManager: Registering server=master,47972,1446961332176
2015-11-08 13:42:12,972 INFO  [master:34688.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 1, slept for 100 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2015-11-08 13:42:12,972 INFO  [RS:0;master:47972] hfile.CacheConfig: blockCache=LruBlockCache{blockCount=0, currentSize=800720, freeSize=778815536, maxSize=779616256, heapSize=800720, minSize=740635456, minFactor=0.95, multiSize=370317728, multiFactor=0.5, singleSize=185158864, singleFactor=0.25}, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheDataCompressed=false, prefetchOnOpen=false
2015-11-08 13:42:13,028 INFO  [RS:0;master:47972] wal.WALFactory: Instantiating WALProvider of type class org.apache.hadoop.hbase.wal.DefaultWALProvider
2015-11-08 13:42:13,052 INFO  [RS:0;master:47972] wal.FSHLog: WAL configuration: blocksize=32 MB, rollsize=30.40 MB, prefix=master%2C47972%2C1446961332176.default, suffix=, logDir=file:/home/hadoop/HBase/HFiles/WALs/master,47972,1446961332176, archiveDir=file:/home/hadoop/HBase/HFiles/oldWALs
2015-11-08 13:42:13,060 INFO  [RS:0;master:47972] wal.FSHLog: Slow sync cost: 0 ms, current pipeline: []
2015-11-08 13:42:13,060 INFO  [RS:0;master:47972] wal.FSHLog: New WAL /home/hadoop/HBase/HFiles/WALs/master,47972,1446961332176/master%2C47972%2C1446961332176.default.1446961333052
2015-11-08 13:42:13,060 INFO  [RS:0;master:47972] wal.FSHLog: FileSystem's output stream doesn't support getNumCurrentReplicas; HDFS-826 not available; fsOut=java.io.BufferedOutputStream
2015-11-08 13:42:13,060 INFO  [RS:0;master:47972] wal.FSHLog: FileSystem's output stream doesn't support getPipeline; not available; fsOut=java.io.BufferedOutputStream
2015-11-08 13:42:13,071 INFO  [RS:0;master:47972] regionserver.MetricsRegionServerWrapperImpl: Computing regionserver metrics every 5000 milliseconds
2015-11-08 13:42:13,081 INFO  [RS:0;master:47972] regionserver.ReplicationSourceManager: Current list of replicators: [master,47972,1446961332176] other RSs: [master,47972,1446961332176]
2015-11-08 13:42:13,120 INFO  [RS:0;master:47972] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x67335fea connecting to ZooKeeper ensemble=localhost:2181
2015-11-08 13:42:13,120 INFO  [RS:0;master:47972] zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=10000 watcher=hconnection-0x67335fea0x0, quorum=localhost:2181, baseZNode=/hbase
2015-11-08 13:42:13,123 INFO  [RS:0;master:47972-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 13:42:13,123 INFO  [RS:0;master:47972-SendThread(localhost:2181)] zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
2015-11-08 13:42:13,123 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:60470
2015-11-08 13:42:13,123 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.ZooKeeperServer: Client attempting to establish new session at /127.0.0.1:60470
2015-11-08 13:42:13,135 INFO  [SyncThread:0] server.ZooKeeperServer: Established session 0x150e59db7b40006 with negotiated timeout 10000 for client /127.0.0.1:60470
2015-11-08 13:42:13,135 INFO  [RS:0;master:47972-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x150e59db7b40006, negotiated timeout = 10000
2015-11-08 13:42:13,167 INFO  [SplitLogWorker-master:47972] regionserver.SplitLogWorker: SplitLogWorker master,47972,1446961332176 starting
2015-11-08 13:42:13,169 INFO  [RS:0;master:47972] regionserver.HeapMemoryManager: Starting HeapMemoryTuner chore.
2015-11-08 13:42:13,171 INFO  [RS:0;master:47972] regionserver.HRegionServer: Serving as master,47972,1446961332176, RpcServer on master/192.168.1.101:47972, sessionid=0x150e59db7b40001
2015-11-08 13:42:13,181 INFO  [RS:0;master:47972] quotas.RegionServerQuotaManager: Quota support disabled
2015-11-08 13:42:14,475 INFO  [master:34688.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 1, slept for 1603 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2015-11-08 13:42:15,978 INFO  [master:34688.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 1, slept for 3106 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2015-11-08 13:42:17,381 INFO  [master:34688.activeMasterManager] master.ServerManager: Finished waiting for region servers count to settle; checked in 1, slept for 4509 ms, expecting minimum of 1, maximum of 2147483647, master is running
2015-11-08 13:42:17,383 INFO  [master:34688.activeMasterManager] master.MasterFileSystem: Log folder file:/home/hadoop/HBase/HFiles/WALs/master,47972,1446961332176 belongs to an existing region server
2015-11-08 13:42:18,201 INFO  [master:34688.activeMasterManager] zookeeper.MetaTableLocator: Deleting hbase:meta region location in ZooKeeper
2015-11-08 13:42:18,202 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Got user-level KeeperException when processing sessionid:0x150e59db7b40000 type:delete cxid:0x4b zxid:0x2c txntype:-1 reqpath:n/a Error Path:/hbase/meta-region-server Error:KeeperErrorCode = NoNode for /hbase/meta-region-server
2015-11-08 13:42:18,218 INFO  [master:34688.activeMasterManager] zookeeper.RecoverableZooKeeper: Node /hbase/meta-region-server already deleted, retry=false
2015-11-08 13:42:18,260 INFO  [master:34688.activeMasterManager] zookeeper.ZKTableStateManager: Moving table hbase:meta state from null to ENABLED
2015-11-08 13:42:18,301 INFO  [master:34688.activeMasterManager] master.AssignmentManager: Assigning hbase:meta,,1.1588230740 to master,47972,1446961332176
2015-11-08 13:42:18,302 INFO  [master:34688.activeMasterManager] master.RegionStates: Transition {1588230740 state=OFFLINE, ts=1446961338222, server=null} to {1588230740 state=PENDING_OPEN, ts=1446961338302, server=master,47972,1446961332176}
2015-11-08 13:42:18,326 INFO  [PriorityRpcServer.handler=1,queue=1,port=47972] regionserver.RSRpcServices: Open hbase:meta,,1.1588230740
2015-11-08 13:42:18,332 INFO  [master:34688.activeMasterManager] master.ServerManager: AssignmentManager hasn't finished failover cleanup; waiting
2015-11-08 13:42:18,335 INFO  [RS_OPEN_META-master:47972-0] wal.WALFactory: Instantiating WALProvider of type class org.apache.hadoop.hbase.wal.DefaultWALProvider
2015-11-08 13:42:18,337 INFO  [RS_OPEN_META-master:47972-0] wal.FSHLog: WAL configuration: blocksize=32 MB, rollsize=30.40 MB, prefix=master%2C47972%2C1446961332176..meta, suffix=.meta, logDir=file:/home/hadoop/HBase/HFiles/WALs/master,47972,1446961332176, archiveDir=file:/home/hadoop/HBase/HFiles/oldWALs
2015-11-08 13:42:18,338 INFO  [AM.ZK.Worker-pool3-t1] master.RegionStates: Transition {1588230740 state=PENDING_OPEN, ts=1446961338302, server=master,47972,1446961332176} to {1588230740 state=OPENING, ts=1446961338338, server=master,47972,1446961332176}
2015-11-08 13:42:18,348 INFO  [RS_OPEN_META-master:47972-0] wal.FSHLog: Slow sync cost: 0 ms, current pipeline: []
2015-11-08 13:42:18,348 INFO  [RS_OPEN_META-master:47972-0] wal.FSHLog: New WAL /home/hadoop/HBase/HFiles/WALs/master,47972,1446961332176/master%2C47972%2C1446961332176..meta.1446961338337.meta
2015-11-08 13:42:18,348 INFO  [RS_OPEN_META-master:47972-0] wal.FSHLog: FileSystem's output stream doesn't support getNumCurrentReplicas; HDFS-826 not available; fsOut=java.io.BufferedOutputStream
2015-11-08 13:42:18,348 INFO  [RS_OPEN_META-master:47972-0] wal.FSHLog: FileSystem's output stream doesn't support getPipeline; not available; fsOut=java.io.BufferedOutputStream
2015-11-08 13:42:18,393 INFO  [RS_OPEN_META-master:47972-0] regionserver.RegionCoprocessorHost: Loaded coprocessor org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint from HTD of hbase:meta successfully.
2015-11-08 13:42:18,406 INFO  [StoreOpener-1588230740-1] hfile.CacheConfig: blockCache=LruBlockCache{blockCount=0, currentSize=800720, freeSize=778815536, maxSize=779616256, heapSize=800720, minSize=740635456, minFactor=0.95, multiSize=370317728, multiFactor=0.5, singleSize=185158864, singleFactor=0.25}, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheDataCompressed=false, prefetchOnOpen=false
2015-11-08 13:42:18,407 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; major period 604800000, major jitter 0.500000, min locality to compact 0.000000
2015-11-08 13:42:18,422 INFO  [RS_OPEN_META-master:47972-0] regionserver.HRegion: Onlined 1588230740; next sequenceid=3
2015-11-08 13:42:18,448 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer: Post open deploy tasks for hbase:meta,,1.1588230740
2015-11-08 13:42:18,449 INFO  [PostOpenDeployTasks:1588230740] zookeeper.MetaTableLocator: Setting hbase:meta region location in ZooKeeper as master,47972,1446961332176
2015-11-08 13:42:18,455 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Got user-level KeeperException when processing sessionid:0x150e59db7b40001 type:setData cxid:0x2d zxid:0x31 txntype:-1 reqpath:n/a Error Path:/hbase/meta-region-server Error:KeeperErrorCode = NoNode for /hbase/meta-region-server
2015-11-08 13:42:18,477 INFO  [AM.ZK.Worker-pool3-t2] master.RegionStates: Transition {1588230740 state=OPENING, ts=1446961338338, server=master,47972,1446961332176} to {1588230740 state=OPEN, ts=1446961338477, server=master,47972,1446961332176}
2015-11-08 13:42:18,479 INFO  [AM.ZK.Worker-pool3-t2] coordination.ZkOpenRegionCoordination: Handling OPENED of 1588230740 from master,34688,1446961331067; deleting unassigned node
2015-11-08 13:42:18,487 INFO  [master:34688.activeMasterManager] master.HMaster: hbase:meta with replicaId 0 assigned=1, rit=false, location=master,47972,1446961332176
2015-11-08 13:42:18,584 INFO  [master:34688.activeMasterManager] hbase.MetaMigrationConvertingToPB: hbase:meta doesn't have any entries to update.
2015-11-08 13:42:18,584 INFO  [master:34688.activeMasterManager] hbase.MetaMigrationConvertingToPB: META already up-to date with PB serialization
2015-11-08 13:42:18,596 INFO  [master:34688.activeMasterManager] master.AssignmentManager: Clean cluster startup. Assigning user regions
2015-11-08 13:42:18,599 INFO  [master:34688.activeMasterManager] master.AssignmentManager: Joined the cluster in 15ms, failover=false
2015-11-08 13:42:18,615 INFO  [master:34688.activeMasterManager] master.TableNamespaceManager: Namespace table not found. Creating...
2015-11-08 13:42:18,756 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Got user-level KeeperException when processing sessionid:0x150e59db7b40000 type:create cxid:0x176 zxid:0x35 txntype:-1 reqpath:n/a Error Path:/hbase/table-lock/hbase:namespace Error:KeeperErrorCode = NoNode for /hbase/table-lock/hbase:namespace
2015-11-08 13:42:18,914 INFO  [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion: creating HRegion hbase:namespace HTD == 'hbase:namespace', {NAME => 'info', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', COMPRESSION => 'NONE', VERSIONS => '10', TTL => 'FOREVER', MIN_VERSIONS => '0', CACHE_DATA_IN_L1 => 'true', KEEP_DELETED_CELLS => 'FALSE', BLOCKSIZE => '8192', IN_MEMORY => 'true', BLOCKCACHE => 'true'} RootDir = file:/home/hadoop/HBase/HFiles/.tmp Table name == hbase:namespace
2015-11-08 13:42:18,925 INFO  [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion: Closed hbase:namespace,,1446961338615.c2d378c38e3567a6b4af7755173aa9bc.
2015-11-08 13:42:19,085 INFO  [ProcedureExecutorThread-0] hbase.MetaTableAccessor: Added 1
2015-11-08 13:42:19,187 INFO  [ProcedureExecutorThread-0] zookeeper.ZKTableStateManager: Moving table hbase:namespace state from null to ENABLING
2015-11-08 13:42:19,202 INFO  [ProcedureExecutorThread-0] master.AssignmentManager: Assigning 1 region(s) to master,47972,1446961332176
2015-11-08 13:42:19,215 INFO  [ProcedureExecutorThread-0] master.RegionStates: Transition {c2d378c38e3567a6b4af7755173aa9bc state=OFFLINE, ts=1446961339204, server=null} to {c2d378c38e3567a6b4af7755173aa9bc state=PENDING_OPEN, ts=1446961339215, server=master,47972,1446961332176}
2015-11-08 13:42:19,218 INFO  [PriorityRpcServer.handler=10,queue=0,port=47972] regionserver.RSRpcServices: Open hbase:namespace,,1446961338615.c2d378c38e3567a6b4af7755173aa9bc.
2015-11-08 13:42:19,223 INFO  [ProcedureExecutorThread-0] zookeeper.ZKTableStateManager: Moving table hbase:namespace state from ENABLING to ENABLED
2015-11-08 13:42:19,244 INFO  [AM.ZK.Worker-pool3-t5] master.RegionStates: Transition {c2d378c38e3567a6b4af7755173aa9bc state=PENDING_OPEN, ts=1446961339215, server=master,47972,1446961332176} to {c2d378c38e3567a6b4af7755173aa9bc state=OPENING, ts=1446961339244, server=master,47972,1446961332176}
2015-11-08 13:42:19,252 INFO  [StoreOpener-c2d378c38e3567a6b4af7755173aa9bc-1] hfile.CacheConfig: blockCache=LruBlockCache{blockCount=0, currentSize=800720, freeSize=778815536, maxSize=779616256, heapSize=800720, minSize=740635456, minFactor=0.95, multiSize=370317728, multiFactor=0.5, singleSize=185158864, singleFactor=0.25}, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheDataCompressed=false, prefetchOnOpen=false
2015-11-08 13:42:19,253 INFO  [StoreOpener-c2d378c38e3567a6b4af7755173aa9bc-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; major period 604800000, major jitter 0.500000, min locality to compact 0.000000
2015-11-08 13:42:19,265 INFO  [RS_OPEN_REGION-master:47972-0] regionserver.HRegion: Onlined c2d378c38e3567a6b4af7755173aa9bc; next sequenceid=2
2015-11-08 13:42:19,268 INFO  [PostOpenDeployTasks:c2d378c38e3567a6b4af7755173aa9bc] regionserver.HRegionServer: Post open deploy tasks for hbase:namespace,,1446961338615.c2d378c38e3567a6b4af7755173aa9bc.
2015-11-08 13:42:19,277 INFO  [PostOpenDeployTasks:c2d378c38e3567a6b4af7755173aa9bc] hbase.MetaTableAccessor: Updated row hbase:namespace,,1446961338615.c2d378c38e3567a6b4af7755173aa9bc. with server=master,47972,1446961332176
2015-11-08 13:42:19,285 INFO  [AM.ZK.Worker-pool3-t6] master.RegionStates: Transition {c2d378c38e3567a6b4af7755173aa9bc state=OPENING, ts=1446961339244, server=master,47972,1446961332176} to {c2d378c38e3567a6b4af7755173aa9bc state=OPEN, ts=1446961339285, server=master,47972,1446961332176}
2015-11-08 13:42:19,451 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Got user-level KeeperException when processing sessionid:0x150e59db7b40000 type:create cxid:0x198 zxid:0x44 txntype:-1 reqpath:n/a Error Path:/hbase/namespace/default Error:KeeperErrorCode = NodeExists for /hbase/namespace/default
2015-11-08 13:42:19,469 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Got user-level KeeperException when processing sessionid:0x150e59db7b40000 type:create cxid:0x19b zxid:0x46 txntype:-1 reqpath:n/a Error Path:/hbase/namespace/hbase Error:KeeperErrorCode = NodeExists for /hbase/namespace/hbase
2015-11-08 13:42:19,485 INFO  [master:34688.activeMasterManager] master.HMaster: Master has completed initialization
2015-11-08 13:42:19,487 INFO  [master:34688.activeMasterManager] quotas.MasterQuotaManager: Quota support disabled
2015-11-08 13:47:12,426 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=781.95 KB, freeSize=742.74 MB, max=743.50 MB, blockCount=0, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=29, evicted=0, evictedPerRun=0.0
2015-11-08 13:47:23,080 INFO  [master,47972,1446961332176_ChoreService_1] regionserver.HRegionServer: master,47972,1446961332176-MemstoreFlusherChore requesting flush for region hbase:meta,,1.1588230740 after a delay of 19419
2015-11-08 13:47:33,078 INFO  [master,47972,1446961332176_ChoreService_1] regionserver.HRegionServer: master,47972,1446961332176-MemstoreFlusherChore requesting flush for region hbase:meta,,1.1588230740 after a delay of 10142
2015-11-08 13:47:42,502 INFO  [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for hbase:meta,,1.1588230740, current region memstore size 992 B, and 1/1 column families' memstores are being flushed.
2015-11-08 13:47:42,565 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9, memsize=992, hasBloomFilter=false, into tmp file file:/home/hadoop/HBase/HFiles/data/hbase/meta/1588230740/.tmp/e018d12b54644c82b9543403919a50a9
2015-11-08 13:47:42,607 INFO  [MemStoreFlusher.1] regionserver.HStore: Added file:/home/hadoop/HBase/HFiles/data/hbase/meta/1588230740/info/e018d12b54644c82b9543403919a50a9, entries=4, sequenceid=9, filesize=5.2 K
2015-11-08 13:47:42,608 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~992 B/992, currentsize=0 B/0 for region hbase:meta,,1.1588230740 in 106ms, sequenceid=9, compaction requested=false
2015-11-08 13:52:12,426 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=781.95 KB, freeSize=742.74 MB, max=743.50 MB, blockCount=0, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=59, evicted=0, evictedPerRun=0.0
2015-11-08 13:57:12,426 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=783.05 KB, freeSize=742.74 MB, max=743.50 MB, blockCount=1, accesses=1, hits=0, hitRatio=0, cachingAccesses=1, cachingHits=0, cachingHitsRatio=0,evictions=89, evicted=0, evictedPerRun=0.0
2015-11-08 14:02:12,426 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=783.05 KB, freeSize=742.74 MB, max=743.50 MB, blockCount=1, accesses=2, hits=1, hitRatio=50.00%, , cachingAccesses=2, cachingHits=1, cachingHitsRatio=50.00%, evictions=119, evicted=0, evictedPerRun=0.0
2015-11-08 14:07:12,426 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=783.05 KB, freeSize=742.74 MB, max=743.50 MB, blockCount=1, accesses=3, hits=2, hitRatio=66.67%, , cachingAccesses=3, cachingHits=2, cachingHitsRatio=66.67%, evictions=149, evicted=0, evictedPerRun=0.0
2015-11-08 14:12:12,426 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=783.05 KB, freeSize=742.74 MB, max=743.50 MB, blockCount=1, accesses=4, hits=3, hitRatio=75.00%, , cachingAccesses=4, cachingHits=3, cachingHitsRatio=75.00%, evictions=179, evicted=0, evictedPerRun=0.0
2015-11-08 14:17:12,426 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=783.05 KB, freeSize=742.74 MB, max=743.50 MB, blockCount=1, accesses=5, hits=4, hitRatio=80.00%, , cachingAccesses=5, cachingHits=4, cachingHitsRatio=80.00%, evictions=209, evicted=0, evictedPerRun=0.0
2015-11-08 14:22:12,426 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=783.05 KB, freeSize=742.74 MB, max=743.50 MB, blockCount=1, accesses=6, hits=5, hitRatio=83.33%, , cachingAccesses=6, cachingHits=5, cachingHitsRatio=83.33%, evictions=239, evicted=0, evictedPerRun=0.0
2015-11-08 14:27:12,426 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=783.05 KB, freeSize=742.74 MB, max=743.50 MB, blockCount=1, accesses=7, hits=6, hitRatio=85.71%, , cachingAccesses=7, cachingHits=6, cachingHitsRatio=85.71%, evictions=269, evicted=0, evictedPerRun=0.0
2015-11-08 14:32:12,426 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=783.05 KB, freeSize=742.74 MB, max=743.50 MB, blockCount=1, accesses=8, hits=7, hitRatio=87.50%, , cachingAccesses=8, cachingHits=7, cachingHitsRatio=87.50%, evictions=299, evicted=0, evictedPerRun=0.0
2015-11-08 14:37:12,426 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=783.05 KB, freeSize=742.74 MB, max=743.50 MB, blockCount=1, accesses=9, hits=8, hitRatio=88.89%, , cachingAccesses=9, cachingHits=8, cachingHitsRatio=88.89%, evictions=329, evicted=0, evictedPerRun=0.0
2015-11-08 14:42:12,426 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=783.05 KB, freeSize=742.74 MB, max=743.50 MB, blockCount=1, accesses=10, hits=9, hitRatio=90.00%, , cachingAccesses=10, cachingHits=9, cachingHitsRatio=90.00%, evictions=359, evicted=0, evictedPerRun=0.0
2015-11-08 14:42:13,121 INFO  [regionserver/master/192.168.1.101:0.logRoller] wal.FSHLog: Rolled WAL /home/hadoop/HBase/HFiles/WALs/master,47972,1446961332176/master%2C47972%2C1446961332176.default.1446961333052 with entries=3, filesize=576 B; new WAL /home/hadoop/HBase/HFiles/WALs/master,47972,1446961332176/master%2C47972%2C1446961332176.default.1446964933108
2015-11-08 14:42:18,380 INFO  [RS_OPEN_META-master:47972-0-MetaLogRoller] wal.FSHLog: Rolled WAL /home/hadoop/HBase/HFiles/WALs/master,47972,1446961332176/master%2C47972%2C1446961332176..meta.1446961338337.meta with entries=5, filesize=1.10 KB; new WAL /home/hadoop/HBase/HFiles/WALs/master,47972,1446961332176/master%2C47972%2C1446961332176..meta.1446964938367.meta
2015-11-08 14:42:18,381 INFO  [RS_OPEN_META-master:47972-0-MetaLogRoller] wal.FSHLog: Archiving file:/home/hadoop/HBase/HFiles/WALs/master,47972,1446961332176/master%2C47972%2C1446961332176..meta.1446961338337.meta to file:/home/hadoop/HBase/HFiles/oldWALs/master%2C47972%2C1446961332176..meta.1446961338337.meta
2015-11-08 14:42:23,078 INFO  [master,47972,1446961332176_ChoreService_1] regionserver.HRegionServer: master,47972,1446961332176-MemstoreFlusherChore requesting flush for region hbase:namespace,,1446961338615.c2d378c38e3567a6b4af7755173aa9bc. after a delay of 4017
2015-11-08 14:42:27,096 INFO  [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for hbase:namespace,,1446961338615.c2d378c38e3567a6b4af7755173aa9bc., current region memstore size 344 B, and 1/1 column families' memstores are being flushed.
2015-11-08 14:42:27,124 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8, memsize=344, hasBloomFilter=true, into tmp file file:/home/hadoop/HBase/HFiles/data/hbase/namespace/c2d378c38e3567a6b4af7755173aa9bc/.tmp/6f84f49e8c304bf4a75255af3729c7b9
2015-11-08 14:42:27,129 INFO  [MemStoreFlusher.0] regionserver.HStore: Added file:/home/hadoop/HBase/HFiles/data/hbase/namespace/c2d378c38e3567a6b4af7755173aa9bc/info/6f84f49e8c304bf4a75255af3729c7b9, entries=2, sequenceid=8, filesize=4.9 K
2015-11-08 14:42:27,129 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~344 B/344, currentsize=0 B/0 for region hbase:namespace,,1446961338615.c2d378c38e3567a6b4af7755173aa9bc. in 33ms, sequenceid=8, compaction requested=false
2015-11-08 14:47:12,426 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=783.05 KB, freeSize=742.74 MB, max=743.50 MB, blockCount=1, accesses=11, hits=10, hitRatio=90.91%, , cachingAccesses=11, cachingHits=10, cachingHitsRatio=90.91%, evictions=389, evicted=0, evictedPerRun=0.0
2015-11-08 14:52:12,426 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=783.05 KB, freeSize=742.74 MB, max=743.50 MB, blockCount=1, accesses=12, hits=11, hitRatio=91.67%, , cachingAccesses=12, cachingHits=11, cachingHitsRatio=91.67%, evictions=419, evicted=0, evictedPerRun=0.0
2015-11-08 14:57:12,426 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=783.05 KB, freeSize=742.74 MB, max=743.50 MB, blockCount=1, accesses=13, hits=12, hitRatio=92.31%, , cachingAccesses=13, cachingHits=12, cachingHitsRatio=92.31%, evictions=449, evicted=0, evictedPerRun=0.0
2015-11-08 15:02:12,426 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=783.05 KB, freeSize=742.74 MB, max=743.50 MB, blockCount=1, accesses=14, hits=13, hitRatio=92.86%, , cachingAccesses=14, cachingHits=13, cachingHitsRatio=92.86%, evictions=479, evicted=0, evictedPerRun=0.0
2015-11-08 15:07:12,426 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=783.05 KB, freeSize=742.74 MB, max=743.50 MB, blockCount=1, accesses=15, hits=14, hitRatio=93.33%, , cachingAccesses=15, cachingHits=14, cachingHitsRatio=93.33%, evictions=509, evicted=0, evictedPerRun=0.0
2015-11-08 15:12:12,426 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=783.05 KB, freeSize=742.74 MB, max=743.50 MB, blockCount=1, accesses=16, hits=15, hitRatio=93.75%, , cachingAccesses=16, cachingHits=15, cachingHitsRatio=93.75%, evictions=539, evicted=0, evictedPerRun=0.0
2015-11-08 15:17:12,426 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=783.05 KB, freeSize=742.74 MB, max=743.50 MB, blockCount=1, accesses=17, hits=16, hitRatio=94.12%, , cachingAccesses=17, cachingHits=16, cachingHitsRatio=94.12%, evictions=569, evicted=0, evictedPerRun=0.0
2015-11-08 15:22:12,426 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=783.05 KB, freeSize=742.74 MB, max=743.50 MB, blockCount=1, accesses=18, hits=17, hitRatio=94.44%, , cachingAccesses=18, cachingHits=17, cachingHitsRatio=94.44%, evictions=599, evicted=0, evictedPerRun=0.0
2015-11-08 15:27:12,426 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=783.05 KB, freeSize=742.74 MB, max=743.50 MB, blockCount=1, accesses=19, hits=18, hitRatio=94.74%, , cachingAccesses=19, cachingHits=18, cachingHitsRatio=94.74%, evictions=629, evicted=0, evictedPerRun=0.0
2015-11-08 15:32:12,426 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=783.05 KB, freeSize=742.74 MB, max=743.50 MB, blockCount=1, accesses=20, hits=19, hitRatio=95.00%, , cachingAccesses=20, cachingHits=19, cachingHitsRatio=95.00%, evictions=659, evicted=0, evictedPerRun=0.0
2015-11-08 15:37:12,426 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=783.05 KB, freeSize=742.74 MB, max=743.50 MB, blockCount=1, accesses=21, hits=20, hitRatio=95.24%, , cachingAccesses=21, cachingHits=20, cachingHitsRatio=95.24%, evictions=689, evicted=0, evictedPerRun=0.0
2015-11-08 15:42:12,426 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=783.05 KB, freeSize=742.74 MB, max=743.50 MB, blockCount=1, accesses=22, hits=21, hitRatio=95.45%, , cachingAccesses=22, cachingHits=21, cachingHitsRatio=95.45%, evictions=719, evicted=0, evictedPerRun=0.0
2015-11-08 15:42:13,160 INFO  [regionserver/master/192.168.1.101:0.logRoller] wal.FSHLog: Rolled WAL /home/hadoop/HBase/HFiles/WALs/master,47972,1446961332176/master%2C47972%2C1446961332176.default.1446964933108 with entries=2, filesize=615 B; new WAL /home/hadoop/HBase/HFiles/WALs/master,47972,1446961332176/master%2C47972%2C1446961332176.default.1446968533151
2015-11-08 15:42:13,161 INFO  [regionserver/master/192.168.1.101:0.logRoller] wal.FSHLog: Archiving file:/home/hadoop/HBase/HFiles/WALs/master,47972,1446961332176/master%2C47972%2C1446961332176.default.1446961333052 to file:/home/hadoop/HBase/HFiles/oldWALs/master%2C47972%2C1446961332176.default.1446961333052
2015-11-08 15:42:13,162 INFO  [regionserver/master/192.168.1.101:0.logRoller] wal.FSHLog: Archiving file:/home/hadoop/HBase/HFiles/WALs/master,47972,1446961332176/master%2C47972%2C1446961332176.default.1446964933108 to file:/home/hadoop/HBase/HFiles/oldWALs/master%2C47972%2C1446961332176.default.1446964933108
2015-11-08 15:42:18,422 INFO  [RS_OPEN_META-master:47972-0-MetaLogRoller] wal.FSHLog: Rolled WAL /home/hadoop/HBase/HFiles/WALs/master,47972,1446961332176/master%2C47972%2C1446961332176..meta.1446964938367.meta with entries=0, filesize=91 B; new WAL /home/hadoop/HBase/HFiles/WALs/master,47972,1446961332176/master%2C47972%2C1446961332176..meta.1446968538412.meta
2015-11-08 15:42:18,422 INFO  [RS_OPEN_META-master:47972-0-MetaLogRoller] wal.FSHLog: Archiving file:/home/hadoop/HBase/HFiles/WALs/master,47972,1446961332176/master%2C47972%2C1446961332176..meta.1446964938367.meta to file:/home/hadoop/HBase/HFiles/oldWALs/master%2C47972%2C1446961332176..meta.1446964938367.meta
Sun Nov  8 15:42:40 CST 2015 Stopping hbase (via master)
2015-11-08 15:42:42,303 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:60937
2015-11-08 15:42:42,306 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.ZooKeeperServer: Client attempting to establish new session at /127.0.0.1:60937
2015-11-08 15:42:42,329 INFO  [SyncThread:0] server.ZooKeeperServer: Established session 0x150e59db7b40007 with negotiated timeout 40000 for client /127.0.0.1:60937
2015-11-08 15:42:43,115 INFO  [B.defaultRpcServer.handler=4,queue=1,port=34688] master.MasterRpcServices: Client=hadoop/null shutdown
2015-11-08 15:42:43,115 INFO  [B.defaultRpcServer.handler=4,queue=1,port=34688] regionserver.HRegionServer: STOPPED: Cluster shutdown requested
2015-11-08 15:42:43,115 INFO  [M:0;master:34688] regionserver.HRegionServer: Stopping infoServer
2015-11-08 15:42:43,117 INFO  [M:0;master:34688] mortbay.log: Stopped SelectChannelConnector@0.0.0.0:16010
2015-11-08 15:42:43,217 INFO  [M:0;master:34688] procedure2.ProcedureExecutor: Stopping the procedure executor
2015-11-08 15:42:43,217 INFO  [M:0;master:34688] wal.WALProcedureStore: Stopping the WAL Procedure Store
2015-11-08 15:42:43,218 INFO  [M:0;master:34688] regionserver.HRegionServer: stopping server master,34688,1446961331067
2015-11-08 15:42:43,218 INFO  [M:0;master:34688] client.ConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x150e59db7b40002
2015-11-08 15:42:43,218 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Processed session termination for sessionid: 0x150e59db7b40002
2015-11-08 15:42:43,228 INFO  [M:0;master:34688] zookeeper.ZooKeeper: Session: 0x150e59db7b40002 closed
2015-11-08 15:42:43,229 INFO  [M:0;master:34688-EventThread] zookeeper.ClientCnxn: EventThread shut down
2015-11-08 15:42:43,229 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxn: Closed socket connection for client /127.0.0.1:60466 which had sessionid 0x150e59db7b40002
2015-11-08 15:42:43,329 INFO  [M:0;master:34688] regionserver.HRegionServer: stopping server master,34688,1446961331067; all regions closed.
2015-11-08 15:42:43,329 INFO  [M:0;master:34688] hbase.ChoreService: Chore service for: master,34688,1446961331067 had [[ScheduledChore: Name: master,34688,1446961331067-ClusterStatusChore Period: 60000 Unit: MILLISECONDS], [ScheduledChore: Name: master,34688,1446961331067-BalancerChore Period: 300000 Unit: MILLISECONDS], [ScheduledChore: Name: LogsCleaner Period: 60000 Unit: MILLISECONDS], [ScheduledChore: Name: HFileCleaner Period: 60000 Unit: MILLISECONDS], [ScheduledChore: Name: CatalogJanitor-master:34688 Period: 300000 Unit: MILLISECONDS]] on shutdown
2015-11-08 15:42:43,330 INFO  [M:0;master:34688] master.ServerManager: Waiting on regionserver(s) to go down master,47972,1446961332176
2015-11-08 15:42:43,450 WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxn: caught end of stream exception
EndOfStreamException: Unable to read additional data from client sessionid 0x150e59db7b40007, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
2015-11-08 15:42:43,453 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxn: Closed socket connection for client /127.0.0.1:60937 which had sessionid 0x150e59db7b40007
2015-11-08 15:42:43,526 INFO  [master,34688,1446961331067_splitLogManager__ChoreService_1] master.SplitLogManager$TimeoutMonitor: Chore: SplitLogManager Timeout Monitor was stopped
2015-11-08 15:42:44,287 INFO  [RS:0;master:47972] regionserver.HRegionServer: Closing user regions
2015-11-08 15:42:44,292 INFO  [StoreCloserThread-hbase:namespace,,1446961338615.c2d378c38e3567a6b4af7755173aa9bc.-1] regionserver.HStore: Closed info
2015-11-08 15:42:44,308 INFO  [RS_CLOSE_REGION-master:47972-0] regionserver.HRegion: Closed hbase:namespace,,1446961338615.c2d378c38e3567a6b4af7755173aa9bc.
2015-11-08 15:42:44,336 INFO  [M:0;master:34688] master.ServerManager: Waiting on regionserver(s) to go down master,47972,1446961332176
2015-11-08 15:42:45,343 INFO  [M:0;master:34688] master.ServerManager: Waiting on regionserver(s) to go down master,47972,1446961332176
2015-11-08 15:42:46,349 INFO  [M:0;master:34688] master.ServerManager: Waiting on regionserver(s) to go down master,47972,1446961332176
2015-11-08 15:42:47,355 INFO  [M:0;master:34688] master.ServerManager: Waiting on regionserver(s) to go down master,47972,1446961332176
2015-11-08 15:42:48,362 INFO  [M:0;master:34688] master.ServerManager: Waiting on regionserver(s) to go down master,47972,1446961332176
2015-11-08 15:42:49,368 INFO  [M:0;master:34688] master.ServerManager: Waiting on regionserver(s) to go down master,47972,1446961332176
2015-11-08 15:42:50,292 INFO  [RS:0;master:47972] regionserver.HRegionServer: STOPPED: Stopped; only catalog regions remaining online
2015-11-08 15:42:50,292 INFO  [RS:0;master:47972] regionserver.SplitLogWorker: Sending interrupt to stop the worker thread
2015-11-08 15:42:50,293 INFO  [RS:0;master:47972] regionserver.HRegionServer: Stopping infoServer
2015-11-08 15:42:50,293 INFO  [SplitLogWorker-master:47972] regionserver.SplitLogWorker: SplitLogWorker interrupted. Exiting. 
2015-11-08 15:42:50,293 INFO  [SplitLogWorker-master:47972] regionserver.SplitLogWorker: SplitLogWorker master,47972,1446961332176 exiting
2015-11-08 15:42:50,294 INFO  [RS:0;master:47972] mortbay.log: Stopped SelectChannelConnector@0.0.0.0:0
2015-11-08 15:42:50,374 INFO  [M:0;master:34688] master.ServerManager: Waiting on regionserver(s) to go down master,47972,1446961332176
2015-11-08 15:42:50,394 INFO  [RS:0;master:47972] regionserver.HeapMemoryManager: Stoping HeapMemoryTuner chore.
2015-11-08 15:42:50,394 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: MemStoreFlusher.1 exiting
2015-11-08 15:42:50,394 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: MemStoreFlusher.0 exiting
2015-11-08 15:42:50,394 INFO  [RS:0;master:47972] snapshot.RegionServerSnapshotManager: Stopping RegionServerSnapshotManager gracefully.
2015-11-08 15:42:50,395 INFO  [RS:0;master:47972] flush.RegionServerFlushTableProcedureManager: Stopping region server flush procedure manager gracefully.
2015-11-08 15:42:50,395 INFO  [RS:0;master:47972] regionserver.HRegionServer: stopping server master,47972,1446961332176
2015-11-08 15:42:50,395 INFO  [RS:0;master:47972] client.ConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x150e59db7b40003
2015-11-08 15:42:50,395 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Processed session termination for sessionid: 0x150e59db7b40003
2015-11-08 15:42:50,412 INFO  [RS:0;master:47972] zookeeper.ZooKeeper: Session: 0x150e59db7b40003 closed
2015-11-08 15:42:50,412 INFO  [RS:0;master:47972] regionserver.CompactSplitThread: Waiting for Split Thread to finish...
2015-11-08 15:42:50,418 INFO  [RS:0;master:47972-EventThread] zookeeper.ClientCnxn: EventThread shut down
2015-11-08 15:42:50,418 INFO  [RS:0;master:47972] regionserver.CompactSplitThread: Waiting for Merge Thread to finish...
2015-11-08 15:42:50,418 INFO  [RS:0;master:47972] regionserver.CompactSplitThread: Waiting for Large Compaction Thread to finish...
2015-11-08 15:42:50,418 INFO  [RS:0;master:47972] regionserver.CompactSplitThread: Waiting for Small Compaction Thread to finish...
2015-11-08 15:42:50,419 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxn: Closed socket connection for client /127.0.0.1:60467 which had sessionid 0x150e59db7b40003
2015-11-08 15:42:50,419 INFO  [RS:0;master:47972] regionserver.HRegionServer: Waiting on 1 regions to close
2015-11-08 15:42:50,420 INFO  [StoreCloserThread-hbase:meta,,1.1588230740-1] regionserver.HStore: Closed info
2015-11-08 15:42:50,430 INFO  [RS_CLOSE_META-master:47972-0] regionserver.HRegion: Closed hbase:meta,,1.1588230740
2015-11-08 15:42:50,619 INFO  [RS:0;master:47972] regionserver.HRegionServer: stopping server master,47972,1446961332176; all regions closed.
2015-11-08 15:42:50,621 INFO  [RS:0;master:47972] wal.FSHLog: Closed WAL: FSHLog master%2C47972%2C1446961332176..meta:.meta(num 1446968538412)
2015-11-08 15:42:50,622 INFO  [RS:0;master:47972] wal.FSHLog: Closed WAL: FSHLog master%2C47972%2C1446961332176.default:(num 1446968533151)
2015-11-08 15:42:50,722 INFO  [RS:0;master:47972] regionserver.Leases: RS:0;master:47972 closing leases
2015-11-08 15:42:50,722 INFO  [RS:0;master:47972] regionserver.Leases: RS:0;master:47972 closed leases
2015-11-08 15:42:50,723 INFO  [RS:0;master:47972] hbase.ChoreService: Chore service for: master,47972,1446961332176 had [[ScheduledChore: Name: MovedRegionsCleaner for region master,47972,1446961332176 Period: 120000 Unit: MILLISECONDS], [ScheduledChore: Name: master,47972,1446961332176-MemstoreFlusherChore Period: 10000 Unit: MILLISECONDS]] on shutdown
2015-11-08 15:42:51,381 INFO  [M:0;master:34688] master.ServerManager: Waiting on regionserver(s) to go down master,47972,1446961332176
2015-11-08 15:42:52,387 INFO  [M:0;master:34688] master.ServerManager: Waiting on regionserver(s) to go down master,47972,1446961332176
2015-11-08 15:42:53,140 INFO  [regionserver/master/192.168.1.101:0.leaseChecker] regionserver.Leases: regionserver/master/192.168.1.101:0.leaseChecker closing leases
2015-11-08 15:42:53,140 INFO  [regionserver/master/192.168.1.101:0.leaseChecker] regionserver.Leases: regionserver/master/192.168.1.101:0.leaseChecker closed leases
2015-11-08 15:42:53,163 INFO  [regionserver/master/192.168.1.101:0.logRoller] regionserver.LogRoller: LogRoller exiting.
2015-11-08 15:42:53,393 INFO  [M:0;master:34688] master.ServerManager: Waiting on regionserver(s) to go down master,47972,1446961332176
2015-11-08 15:42:54,400 INFO  [M:0;master:34688] master.ServerManager: Waiting on regionserver(s) to go down master,47972,1446961332176
2015-11-08 15:42:55,406 INFO  [M:0;master:34688] master.ServerManager: Waiting on regionserver(s) to go down master,47972,1446961332176
2015-11-08 15:42:56,413 INFO  [M:0;master:34688] master.ServerManager: Waiting on regionserver(s) to go down master,47972,1446961332176
2015-11-08 15:42:57,419 INFO  [M:0;master:34688] master.ServerManager: Waiting on regionserver(s) to go down master,47972,1446961332176
2015-11-08 15:42:58,423 INFO  [RS_OPEN_META-master:47972-0-MetaLogRoller] regionserver.LogRoller: LogRoller exiting.
2015-11-08 15:42:58,425 INFO  [M:0;master:34688] master.ServerManager: Waiting on regionserver(s) to go down master,47972,1446961332176
2015-11-08 15:42:58,470 INFO  [RS:0;master:47972] client.ConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x150e59db7b40006
2015-11-08 15:42:58,470 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Processed session termination for sessionid: 0x150e59db7b40006
2015-11-08 15:42:58,478 INFO  [RS:0;master:47972] zookeeper.ZooKeeper: Session: 0x150e59db7b40006 closed
2015-11-08 15:42:58,478 INFO  [RS:0;master:47972-EventThread] zookeeper.ClientCnxn: EventThread shut down
2015-11-08 15:42:58,478 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxn: Closed socket connection for client /127.0.0.1:60470 which had sessionid 0x150e59db7b40006
2015-11-08 15:42:58,478 INFO  [RS:0;master:47972] ipc.RpcServer: Stopping server on 47972
2015-11-08 15:42:58,478 INFO  [RpcServer.listener,port=47972] ipc.RpcServer: RpcServer.listener,port=47972: stopping
2015-11-08 15:42:58,480 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopped
2015-11-08 15:42:58,480 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopping
2015-11-08 15:42:58,486 INFO  [main-EventThread] zookeeper.RegionServerTracker: RegionServer ephemeral node deleted, processing expiration [master,47972,1446961332176]
2015-11-08 15:42:58,487 INFO  [main-EventThread] master.ServerManager: Cluster shutdown set; master,47972,1446961332176 expired; onlineServers=0
2015-11-08 15:42:58,487 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Processed session termination for sessionid: 0x150e59db7b40001
2015-11-08 15:42:58,495 INFO  [RS:0;master:47972] zookeeper.ZooKeeper: Session: 0x150e59db7b40001 closed
2015-11-08 15:42:58,495 INFO  [main-EventThread] zookeeper.ClientCnxn: EventThread shut down
2015-11-08 15:42:58,495 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxn: Closed socket connection for client /127.0.0.1:60465 which had sessionid 0x150e59db7b40001
2015-11-08 15:42:58,495 INFO  [RS:0;master:47972] regionserver.HRegionServer: stopping server master,47972,1446961332176; zookeeper connection closed.
2015-11-08 15:42:58,495 INFO  [RS:0;master:47972] regionserver.HRegionServer: RS:0;master:47972 exiting
2015-11-08 15:42:58,524 INFO  [M:0;master:34688] client.ConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x150e59db7b40004
2015-11-08 15:42:58,525 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Processed session termination for sessionid: 0x150e59db7b40004
2015-11-08 15:42:58,545 INFO  [M:0;master:34688] zookeeper.ZooKeeper: Session: 0x150e59db7b40004 closed
2015-11-08 15:42:58,545 INFO  [master:34688.activeMasterManager-EventThread] zookeeper.ClientCnxn: EventThread shut down
2015-11-08 15:42:58,545 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxn: Closed socket connection for client /127.0.0.1:60468 which had sessionid 0x150e59db7b40004
2015-11-08 15:42:58,545 INFO  [M:0;master:34688] hbase.ChoreService: Chore service for: master,34688,1446961331067_splitLogManager_ had [] on shutdown
2015-11-08 15:42:58,545 INFO  [M:0;master:34688] flush.MasterFlushTableProcedureManager: stop: server shutting down.
2015-11-08 15:42:58,545 INFO  [M:0;master:34688] ipc.RpcServer: Stopping server on 34688
2015-11-08 15:42:58,545 INFO  [RpcServer.listener,port=34688] ipc.RpcServer: RpcServer.listener,port=34688: stopping
2015-11-08 15:42:58,547 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopped
2015-11-08 15:42:58,547 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopping
2015-11-08 15:42:58,550 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Got user-level KeeperException when processing sessionid:0x150e59db7b40000 type:delete cxid:0x2cd zxid:0x53 txntype:-1 reqpath:n/a Error Path:/hbase/rs/master,34688,1446961331067 Error:KeeperErrorCode = NoNode for /hbase/rs/master,34688,1446961331067
2015-11-08 15:42:58,553 INFO  [M:0;master:34688] zookeeper.RecoverableZooKeeper: Node /hbase/rs/master,34688,1446961331067 already deleted, retry=false
2015-11-08 15:42:58,553 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Processed session termination for sessionid: 0x150e59db7b40000
2015-11-08 15:42:58,561 INFO  [main-EventThread] zookeeper.ClientCnxn: EventThread shut down
2015-11-08 15:42:58,561 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxn: Closed socket connection for client /127.0.0.1:60464 which had sessionid 0x150e59db7b40000
2015-11-08 15:42:58,561 INFO  [M:0;master:34688] zookeeper.ZooKeeper: Session: 0x150e59db7b40000 closed
2015-11-08 15:42:58,562 INFO  [M:0;master:34688] regionserver.HRegionServer: stopping server master,34688,1446961331067; zookeeper connection closed.
2015-11-08 15:42:58,562 INFO  [M:0;master:34688] regionserver.HRegionServer: M:0;master:34688 exiting
2015-11-08 15:42:58,562 INFO  [M:0;master:34688] server.NIOServerCnxn: Closed socket connection for client /127.0.0.1:60469 which had sessionid 0x150e59db7b40005
2015-11-08 15:42:58,562 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxnFactory: NIOServerCnxn factory exited run method
2015-11-08 15:42:58,562 INFO  [M:0;master:34688] server.ZooKeeperServer: shutting down
2015-11-08 15:42:58,562 INFO  [M:0;master:34688] server.SessionTrackerImpl: Shutting down
2015-11-08 15:42:58,562 INFO  [M:0;master:34688] server.PrepRequestProcessor: Shutting down
2015-11-08 15:42:58,562 INFO  [master:34688.activeMasterManager-SendThread(localhost:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x150e59db7b40005, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-08 15:42:58,563 INFO  [M:0;master:34688] server.SyncRequestProcessor: Shutting down
2015-11-08 15:42:58,563 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: PrepRequestProcessor exited loop!
2015-11-08 15:42:58,563 INFO  [SyncThread:0] server.SyncRequestProcessor: SyncRequestProcessor exited!
2015-11-08 15:42:58,563 INFO  [M:0;master:34688] server.FinalRequestProcessor: shutdown of request processor complete
2015-11-08 15:42:58,565 INFO  [M:0;master:34688] zookeeper.MiniZooKeeperCluster: Shutdown MiniZK cluster with all ZK servers
2015-11-08 15:43:00,000 INFO  [SessionTracker] server.SessionTrackerImpl: SessionTrackerImpl exited loop!
2015-11-08 15:43:00,002 INFO  [Thread-6] regionserver.ShutdownHook: Shutdown hook starting; hbase.shutdown.hook=true; fsShutdownHook=org.apache.hadoop.fs.FileSystem$Cache$ClientFinalizer@165d6360
2015-11-08 15:43:00,002 INFO  [Thread-6] regionserver.ShutdownHook: Starting fs shutdown hook thread.
2015-11-08 15:43:00,003 INFO  [Thread-6] regionserver.ShutdownHook: Shutdown hook finished.
Sun Nov  8 15:45:45 CST 2015 Starting master on master
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 30141
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 10240
cpu time               (seconds, -t) unlimited
max user processes              (-u) 1024
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2015-11-08 15:45:45,586 INFO  [main] util.VersionInfo: HBase 1.1.2
2015-11-08 15:45:45,586 INFO  [main] util.VersionInfo: Source code repository git://hw11397.local/Volumes/hbase-1.1.2RC2/hbase revision=cc2b70cf03e3378800661ec5cab11eb43fafe0fc
2015-11-08 15:45:45,586 INFO  [main] util.VersionInfo: Compiled by ndimiduk on Wed Aug 26 20:11:27 PDT 2015
2015-11-08 15:45:45,586 INFO  [main] util.VersionInfo: From source with checksum 73da41f3d1b867b7aba6166c77fafc17
2015-11-08 15:45:45,901 INFO  [main] util.ServerCommandLine: env:TERM=xterm
2015-11-08 15:45:45,902 INFO  [main] util.ServerCommandLine: env:HADOOP_COMMON_LIB_NATIVE_DIR=/opt/hadoop/lib/native
2015-11-08 15:45:45,902 INFO  [main] util.ServerCommandLine: env:IMSETTINGS_MODULE=none
2015-11-08 15:45:45,902 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/opt/java
2015-11-08 15:45:45,902 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/opt/hbase/bin/..
2015-11-08 15:45:45,902 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2015-11-08 15:45:45,902 INFO  [main] util.ServerCommandLine: env:SESSION_MANAGER=local/unix:@/tmp/.ICE-unix/2995,unix/unix:/tmp/.ICE-unix/2995
2015-11-08 15:45:45,902 INFO  [main] util.ServerCommandLine: env:IMSETTINGS_INTEGRATE_DESKTOP=yes
2015-11-08 15:45:45,902 INFO  [main] util.ServerCommandLine: env:GNOME_DESKTOP_SESSION_ID=this-is-deprecated
2015-11-08 15:45:45,902 INFO  [main] util.ServerCommandLine: env:MAIL=/var/spool/mail/hadoop
2015-11-08 15:45:45,902 INFO  [main] util.ServerCommandLine: env:XDG_SESSION_COOKIE=ab8c9d4f5491283c7c300d7800000013-1446958848.52338-1725977001
2015-11-08 15:45:45,902 INFO  [main] util.ServerCommandLine: env:GDMSESSION=gnome
2015-11-08 15:45:45,902 INFO  [main] util.ServerCommandLine: env:HOSTNAME=master
2015-11-08 15:45:45,902 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/tmp/hbase-hadoop-master.znode
2015-11-08 15:45:45,902 INFO  [main] util.ServerCommandLine: env:PWD=/opt/hbase/bin
2015-11-08 15:45:45,902 INFO  [main] util.ServerCommandLine: env:HBASE_MASTER_OPTS= -XX:PermSize=128m -XX:MaxPermSize=128m
2015-11-08 15:45:45,902 INFO  [main] util.ServerCommandLine: env:CVS_RSH=ssh
2015-11-08 15:45:45,902 INFO  [main] util.ServerCommandLine: env:JAVA_LIBRARY_PATH=/opt/hadoop/lib/native::/opt/hadoop/lib/native:
2015-11-08 15:45:45,902 INFO  [main] util.ServerCommandLine: env:G_BROKEN_FILENAMES=1
2015-11-08 15:45:45,902 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2015-11-08 15:45:45,902 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2015-11-08 15:45:45,902 INFO  [main] util.ServerCommandLine: env:NLSPATH=/usr/dt/lib/nls/msg/%L/%N.cat
2015-11-08 15:45:45,903 INFO  [main] util.ServerCommandLine: env:GNOME_KEYRING_SOCKET=/tmp/keyring-IruJ62/socket
2015-11-08 15:45:45,903 INFO  [main] util.ServerCommandLine: env:GDM_KEYBOARD_LAYOUT=us
2015-11-08 15:45:45,903 INFO  [main] util.ServerCommandLine: env:HBASE_REGIONSERVER_OPTS= -XX:PermSize=128m -XX:MaxPermSize=128m
2015-11-08 15:45:45,903 INFO  [main] util.ServerCommandLine: env:HISTSIZE=1000
2015-11-08 15:45:45,903 INFO  [main] util.ServerCommandLine: env:PATH=/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin:/sbin:/opt/java//bin:/opt/java/jre/bin:/opt/hadoop/bin:/home/hadoop/bin
2015-11-08 15:45:45,903 INFO  [main] util.ServerCommandLine: env:QTLIB=/usr/lib64/qt-3.3/lib
2015-11-08 15:45:45,903 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2015-11-08 15:45:45,903 INFO  [main] util.ServerCommandLine: env:GDM_LANG=en_US.UTF-8
2015-11-08 15:45:45,903 INFO  [main] util.ServerCommandLine: env:XAUTHORITY=/var/run/gdm/auth-for-hadoop-akmkFp/database
2015-11-08 15:45:45,903 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/tmp/hbase-hadoop-master.autorestart
2015-11-08 15:45:45,903 INFO  [main] util.ServerCommandLine: env:USERNAME=hadoop
2015-11-08 15:45:45,903 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-hadoop-master-master.log
2015-11-08 15:45:45,903 INFO  [main] util.ServerCommandLine: env:SSH_ASKPASS=/usr/libexec/openssh/gnome-ssh-askpass
2015-11-08 15:45:45,903 INFO  [main] util.ServerCommandLine: env:SHLVL=5
2015-11-08 15:45:45,903 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/opt/hbase/bin/../logs
2015-11-08 15:45:45,903 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-XX:+UseConcMarkSweepGC   -XX:PermSize=128m -XX:MaxPermSize=128m -Dhbase.log.dir=/opt/hbase/bin/../logs -Dhbase.log.file=hbase-hadoop-master-master.log -Dhbase.home.dir=/opt/hbase/bin/.. -Dhbase.id.str=hadoop -Dhbase.root.logger=INFO,RFA -Djava.library.path=/opt/hadoop/lib/native::/opt/hadoop/lib/native: -Dhbase.security.logger=INFO,RFAS
2015-11-08 15:45:45,903 INFO  [main] util.ServerCommandLine: env:XFILESEARCHPATH=/usr/dt/app-defaults/%L/Dt
2015-11-08 15:45:45,904 INFO  [main] util.ServerCommandLine: env:COLORTERM=gnome-terminal
2015-11-08 15:45:45,904 INFO  [main] util.ServerCommandLine: env:QT_IM_MODULE=xim
2015-11-08 15:45:45,904 INFO  [main] util.ServerCommandLine: env:WINDOWID=20979824
2015-11-08 15:45:45,904 INFO  [main] util.ServerCommandLine: env:LOGNAME=hadoop
2015-11-08 15:45:45,904 INFO  [main] util.ServerCommandLine: env:QTDIR=/usr/lib64/qt-3.3
2015-11-08 15:45:45,904 INFO  [main] util.ServerCommandLine: env:XMODIFIERS=@im=none
2015-11-08 15:45:45,904 INFO  [main] util.ServerCommandLine: env:SSH_AUTH_SOCK=/tmp/keyring-IruJ62/socket.ssh
2015-11-08 15:45:45,904 INFO  [main] util.ServerCommandLine: env:HADOOP_HOME=/opt/hadoop
2015-11-08 15:45:45,904 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=:/opt/hadoop/lib/native::/opt/hadoop/lib/native:
2015-11-08 15:45:45,904 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2015-11-08 15:45:45,904 INFO  [main] util.ServerCommandLine: env:HADOOP_OPTS=-Djava.library.path=/opt/hadoop/lib/native
2015-11-08 15:45:45,904 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2015-11-08 15:45:45,904 INFO  [main] util.ServerCommandLine: env:DBUS_SESSION_BUS_ADDRESS=unix:abstract=/tmp/dbus-uqNe1cANDo,guid=eca351d0636069d92d6d2f1900000495
2015-11-08 15:45:45,904 INFO  [main] util.ServerCommandLine: env:GNOME_KEYRING_PID=2985
2015-11-08 15:45:45,904 INFO  [main] util.ServerCommandLine: env:GTK_RC_FILES=/etc/gtk/gtkrc:/home/hadoop/.gtkrc-1.2-gnome2
2015-11-08 15:45:45,904 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2015-11-08 15:45:45,905 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/opt/hbase/bin/../conf:/opt/java/lib/tools.jar:/opt/hbase/bin/..:/opt/hbase/bin/../lib/activation-1.1.jar:/opt/hbase/bin/../lib/aopalliance-1.0.jar:/opt/hbase/bin/../lib/apacheds-i18n-2.0.0-M15.jar:/opt/hbase/bin/../lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hbase/bin/../lib/api-asn1-api-1.0.0-M20.jar:/opt/hbase/bin/../lib/api-util-1.0.0-M20.jar:/opt/hbase/bin/../lib/asm-3.1.jar:/opt/hbase/bin/../lib/avro-1.7.4.jar:/opt/hbase/bin/../lib/commons-beanutils-1.7.0.jar:/opt/hbase/bin/../lib/commons-beanutils-core-1.8.0.jar:/opt/hbase/bin/../lib/commons-cli-1.2.jar:/opt/hbase/bin/../lib/commons-codec-1.9.jar:/opt/hbase/bin/../lib/commons-collections-3.2.1.jar:/opt/hbase/bin/../lib/commons-compress-1.4.1.jar:/opt/hbase/bin/../lib/commons-configuration-1.6.jar:/opt/hbase/bin/../lib/commons-daemon-1.0.13.jar:/opt/hbase/bin/../lib/commons-digester-1.8.jar:/opt/hbase/bin/../lib/commons-el-1.0.jar:/opt/hbase/bin/../lib/commons-httpclient-3.1.jar:/opt/hbase/bin/../lib/commons-io-2.4.jar:/opt/hbase/bin/../lib/commons-lang-2.6.jar:/opt/hbase/bin/../lib/commons-logging-1.2.jar:/opt/hbase/bin/../lib/commons-math-2.2.jar:/opt/hbase/bin/../lib/commons-math3-3.1.1.jar:/opt/hbase/bin/../lib/commons-net-3.1.jar:/opt/hbase/bin/../lib/disruptor-3.3.0.jar:/opt/hbase/bin/../lib/findbugs-annotations-1.3.9-1.jar:/opt/hbase/bin/../lib/guava-12.0.1.jar:/opt/hbase/bin/../lib/guice-3.0.jar:/opt/hbase/bin/../lib/guice-servlet-3.0.jar:/opt/hbase/bin/../lib/hadoop-annotations-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-auth-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-client-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-common-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-hdfs-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-app-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-common-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-core-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-jobclient-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-shuffle-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-api-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-client-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-common-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-server-common-2.5.1.jar:/opt/hbase/bin/../lib/hbase-annotations-1.1.2.jar:/opt/hbase/bin/../lib/hbase-annotations-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-client-1.1.2.jar:/opt/hbase/bin/../lib/hbase-common-1.1.2.jar:/opt/hbase/bin/../lib/hbase-common-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-examples-1.1.2.jar:/opt/hbase/bin/../lib/hbase-hadoop2-compat-1.1.2.jar:/opt/hbase/bin/../lib/hbase-hadoop-compat-1.1.2.jar:/opt/hbase/bin/../lib/hbase-it-1.1.2.jar:/opt/hbase/bin/../lib/hbase-it-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-prefix-tree-1.1.2.jar:/opt/hbase/bin/../lib/hbase-procedure-1.1.2.jar:/opt/hbase/bin/../lib/hbase-protocol-1.1.2.jar:/opt/hbase/bin/../lib/hbase-resource-bundle-1.1.2.jar:/opt/hbase/bin/../lib/hbase-rest-1.1.2.jar:/opt/hbase/bin/../lib/hbase-server-1.1.2.jar:/opt/hbase/bin/../lib/hbase-server-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-shell-1.1.2.jar:/opt/hbase/bin/../lib/hbase-thrift-1.1.2.jar:/opt/hbase/bin/../lib/htrace-core-3.1.0-incubating.jar:/opt/hbase/bin/../lib/httpclient-4.2.5.jar:/opt/hbase/bin/../lib/httpcore-4.1.3.jar:/opt/hbase/bin/../lib/jackson-core-asl-1.9.13.jar:/opt/hbase/bin/../lib/jackson-jaxrs-1.9.13.jar:/opt/hbase/bin/../lib/jackson-mapper-asl-1.9.13.jar:/opt/hbase/bin/../lib/jackson-xc-1.9.13.jar:/opt/hbase/bin/../lib/jamon-runtime-2.3.1.jar:/opt/hbase/bin/../lib/jasper-compiler-5.5.23.jar:/opt/hbase/bin/../lib/jasper-runtime-5.5.23.jar:/opt/hbase/bin/../lib/javax.inject-1.jar:/opt/hbase/bin/../lib/java-xmlbuilder-0.4.jar:/opt/hbase/bin/../lib/jaxb-api-2.2.2.jar:/opt/hbase/bin/../lib/jaxb-impl-2.2.3-1.jar:/opt/hbase/bin/../lib/jcodings-1.0.8.jar:/opt/hbase/bin/../lib/jersey-client-1.9.jar:/opt/hbase/bin/../lib/jersey-core-1.9.jar:/opt/hbase/bin/../lib/jersey-guice-1.9.jar:/opt/hbase/bin/../lib/jersey-json-1.9.jar:/opt/hbase/bin/../lib/jersey-server-1.9.jar:/opt/hbase/bin/../lib/jets3t-0.9.0.jar:/opt/hbase/bin/../lib/jettison-1.3.3.jar:/opt/hbase/bin/../lib/jetty-6.1.26.jar:/opt/hbase/bin/../lib/jetty-sslengine-6.1.26.jar:/opt/hbase/bin/../lib/jetty-util-6.1.26.jar:/opt/hbase/bin/../lib/joni-2.1.2.jar:/opt/hbase/bin/../lib/jruby-complete-1.6.8.jar:/opt/hbase/bin/../lib/jsch-0.1.42.jar:/opt/hbase/bin/../lib/jsp-2.1-6.1.14.jar:/opt/hbase/bin/../lib/jsp-api-2.1-6.1.14.jar:/opt/hbase/bin/../lib/jsr305-1.3.9.jar:/opt/hbase/bin/../lib/junit-4.11.jar:/opt/hbase/bin/../lib/leveldbjni-all-1.8.jar:/opt/hbase/bin/../lib/libthrift-0.9.0.jar:/opt/hbase/bin/../lib/log4j-1.2.17.jar:/opt/hbase/bin/../lib/metrics-core-2.2.0.jar:/opt/hbase/bin/../lib/netty-3.2.4.Final.jar:/opt/hbase/bin/../lib/netty-all-4.0.23.Final.jar:/opt/hbase/bin/../lib/paranamer-2.3.jar:/opt/hbase/bin/../lib/protobuf-java-2.5.0.jar:/opt/hbase/bin/../lib/servlet-api-2.5-6.1.14.jar:/opt/hbase/bin/../lib/servlet-api-2.5.jar:/opt/hbase/bin/../lib/slf4j-api-1.7.7.jar:/opt/hbase/bin/../lib/slf4j-log4j12-1.7.5.jar:/opt/hbase/bin/../lib/snappy-java-1.0.4.1.jar:/opt/hbase/bin/../lib/spymemcached-2.11.6.jar:/opt/hbase/bin/../lib/xmlenc-0.52.jar:/opt/hbase/bin/../lib/xz-1.0.jar:/opt/hbase/bin/../lib/zookeeper-3.4.6.jar:/opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/contrib/capacity-scheduler/*.jar
2015-11-08 15:45:45,905 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2015-11-08 15:45:45,905 INFO  [main] util.ServerCommandLine: env:JRE_HOME=/opt/java/jre
2015-11-08 15:45:45,905 INFO  [main] util.ServerCommandLine: env:DESKTOP_SESSION=gnome
2015-11-08 15:45:45,905 INFO  [main] util.ServerCommandLine: env:QTINC=/usr/lib64/qt-3.3/include
2015-11-08 15:45:45,905 INFO  [main] util.ServerCommandLine: env:DISPLAY=192.168.1.100:2.0
2015-11-08 15:45:45,905 INFO  [main] util.ServerCommandLine: env:USER=hadoop
2015-11-08 15:45:45,905 INFO  [main] util.ServerCommandLine: env:HISTCONTROL=ignoredups
2015-11-08 15:45:45,906 INFO  [main] util.ServerCommandLine: env:HOME=/home/hadoop
2015-11-08 15:45:45,906 INFO  [main] util.ServerCommandLine: env:LESSOPEN=||/usr/bin/lesspipe.sh %s
2015-11-08 15:45:45,906 INFO  [main] util.ServerCommandLine: env:LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arj=01;31:*.taz=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lz=01;31:*.xz=01;31:*.bz2=01;31:*.tbz=01;31:*.tbz2=01;31:*.bz=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.rar=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
2015-11-08 15:45:45,906 INFO  [main] util.ServerCommandLine: env:ORBIT_SOCKETDIR=/tmp/orbit-hadoop
2015-11-08 15:45:45,906 INFO  [main] util.ServerCommandLine: env:LANG=en_US.UTF-8
2015-11-08 15:45:45,906 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-hadoop-master-master
2015-11-08 15:45:45,906 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=hadoop
2015-11-08 15:45:45,907 INFO  [main] util.ServerCommandLine: vmName=Java HotSpot(TM) 64-Bit Server VM, vmVendor=Oracle Corporation, vmVersion=24.79-b02
2015-11-08 15:45:45,907 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_master, -XX:OnOutOfMemoryError=kill -9 %p, -XX:+UseConcMarkSweepGC, -XX:PermSize=128m, -XX:MaxPermSize=128m, -Dhbase.log.dir=/opt/hbase/bin/../logs, -Dhbase.log.file=hbase-hadoop-master-master.log, -Dhbase.home.dir=/opt/hbase/bin/.., -Dhbase.id.str=hadoop, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=/opt/hadoop/lib/native::/opt/hadoop/lib/native:, -Dhbase.security.logger=INFO,RFAS]
2015-11-08 15:45:46,340 WARN  [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-11-08 15:45:46,617 INFO  [main] regionserver.RSRpcServices: master/master/192.168.1.101:16000 server-side HConnection retries=350
2015-11-08 15:45:46,771 INFO  [main] ipc.SimpleRpcScheduler: Using deadline as user call queue, count=3
2015-11-08 15:45:46,787 INFO  [main] ipc.RpcServer: master/master/192.168.1.101:16000: started 10 reader(s).
2015-11-08 15:45:46,842 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2015-11-08 15:45:46,900 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-11-08 15:45:46,900 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2015-11-08 15:45:47,742 INFO  [main] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2015-11-08 15:45:48,003 INFO  [main] zookeeper.RecoverableZooKeeper: Process identifier=master:16000 connecting to ZooKeeper ensemble=localhost:2181
2015-11-08 15:45:48,012 INFO  [main] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2015-11-08 15:45:48,012 INFO  [main] zookeeper.ZooKeeper: Client environment:host.name=master
2015-11-08 15:45:48,012 INFO  [main] zookeeper.ZooKeeper: Client environment:java.version=1.7.0_79
2015-11-08 15:45:48,012 INFO  [main] zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
2015-11-08 15:45:48,012 INFO  [main] zookeeper.ZooKeeper: Client environment:java.home=/opt/java/jre
2015-11-08 15:45:48,012 INFO  [main] zookeeper.ZooKeeper: Client environment:java.class.path=/opt/hbase/bin/../conf:/opt/java/lib/tools.jar:/opt/hbase/bin/..:/opt/hbase/bin/../lib/activation-1.1.jar:/opt/hbase/bin/../lib/aopalliance-1.0.jar:/opt/hbase/bin/../lib/apacheds-i18n-2.0.0-M15.jar:/opt/hbase/bin/../lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hbase/bin/../lib/api-asn1-api-1.0.0-M20.jar:/opt/hbase/bin/../lib/api-util-1.0.0-M20.jar:/opt/hbase/bin/../lib/asm-3.1.jar:/opt/hbase/bin/../lib/avro-1.7.4.jar:/opt/hbase/bin/../lib/commons-beanutils-1.7.0.jar:/opt/hbase/bin/../lib/commons-beanutils-core-1.8.0.jar:/opt/hbase/bin/../lib/commons-cli-1.2.jar:/opt/hbase/bin/../lib/commons-codec-1.9.jar:/opt/hbase/bin/../lib/commons-collections-3.2.1.jar:/opt/hbase/bin/../lib/commons-compress-1.4.1.jar:/opt/hbase/bin/../lib/commons-configuration-1.6.jar:/opt/hbase/bin/../lib/commons-daemon-1.0.13.jar:/opt/hbase/bin/../lib/commons-digester-1.8.jar:/opt/hbase/bin/../lib/commons-el-1.0.jar:/opt/hbase/bin/../lib/commons-httpclient-3.1.jar:/opt/hbase/bin/../lib/commons-io-2.4.jar:/opt/hbase/bin/../lib/commons-lang-2.6.jar:/opt/hbase/bin/../lib/commons-logging-1.2.jar:/opt/hbase/bin/../lib/commons-math-2.2.jar:/opt/hbase/bin/../lib/commons-math3-3.1.1.jar:/opt/hbase/bin/../lib/commons-net-3.1.jar:/opt/hbase/bin/../lib/disruptor-3.3.0.jar:/opt/hbase/bin/../lib/findbugs-annotations-1.3.9-1.jar:/opt/hbase/bin/../lib/guava-12.0.1.jar:/opt/hbase/bin/../lib/guice-3.0.jar:/opt/hbase/bin/../lib/guice-servlet-3.0.jar:/opt/hbase/bin/../lib/hadoop-annotations-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-auth-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-client-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-common-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-hdfs-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-app-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-common-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-core-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-jobclient-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-shuffle-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-api-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-client-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-common-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-server-common-2.5.1.jar:/opt/hbase/bin/../lib/hbase-annotations-1.1.2.jar:/opt/hbase/bin/../lib/hbase-annotations-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-client-1.1.2.jar:/opt/hbase/bin/../lib/hbase-common-1.1.2.jar:/opt/hbase/bin/../lib/hbase-common-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-examples-1.1.2.jar:/opt/hbase/bin/../lib/hbase-hadoop2-compat-1.1.2.jar:/opt/hbase/bin/../lib/hbase-hadoop-compat-1.1.2.jar:/opt/hbase/bin/../lib/hbase-it-1.1.2.jar:/opt/hbase/bin/../lib/hbase-it-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-prefix-tree-1.1.2.jar:/opt/hbase/bin/../lib/hbase-procedure-1.1.2.jar:/opt/hbase/bin/../lib/hbase-protocol-1.1.2.jar:/opt/hbase/bin/../lib/hbase-resource-bundle-1.1.2.jar:/opt/hbase/bin/../lib/hbase-rest-1.1.2.jar:/opt/hbase/bin/../lib/hbase-server-1.1.2.jar:/opt/hbase/bin/../lib/hbase-server-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-shell-1.1.2.jar:/opt/hbase/bin/../lib/hbase-thrift-1.1.2.jar:/opt/hbase/bin/../lib/htrace-core-3.1.0-incubating.jar:/opt/hbase/bin/../lib/httpclient-4.2.5.jar:/opt/hbase/bin/../lib/httpcore-4.1.3.jar:/opt/hbase/bin/../lib/jackson-core-asl-1.9.13.jar:/opt/hbase/bin/../lib/jackson-jaxrs-1.9.13.jar:/opt/hbase/bin/../lib/jackson-mapper-asl-1.9.13.jar:/opt/hbase/bin/../lib/jackson-xc-1.9.13.jar:/opt/hbase/bin/../lib/jamon-runtime-2.3.1.jar:/opt/hbase/bin/../lib/jasper-compiler-5.5.23.jar:/opt/hbase/bin/../lib/jasper-runtime-5.5.23.jar:/opt/hbase/bin/../lib/javax.inject-1.jar:/opt/hbase/bin/../lib/java-xmlbuilder-0.4.jar:/opt/hbase/bin/../lib/jaxb-api-2.2.2.jar:/opt/hbase/bin/../lib/jaxb-impl-2.2.3-1.jar:/opt/hbase/bin/../lib/jcodings-1.0.8.jar:/opt/hbase/bin/../lib/jersey-client-1.9.jar:/opt/hbase/bin/../lib/jersey-core-1.9.jar:/opt/hbase/bin/../lib/jersey-guice-1.9.jar:/opt/hbase/bin/../lib/jersey-json-1.9.jar:/opt/hbase/bin/../lib/jersey-server-1.9.jar:/opt/hbase/bin/../lib/jets3t-0.9.0.jar:/opt/hbase/bin/../lib/jettison-1.3.3.jar:/opt/hbase/bin/../lib/jetty-6.1.26.jar:/opt/hbase/bin/../lib/jetty-sslengine-6.1.26.jar:/opt/hbase/bin/../lib/jetty-util-6.1.26.jar:/opt/hbase/bin/../lib/joni-2.1.2.jar:/opt/hbase/bin/../lib/jruby-complete-1.6.8.jar:/opt/hbase/bin/../lib/jsch-0.1.42.jar:/opt/hbase/bin/../lib/jsp-2.1-6.1.14.jar:/opt/hbase/bin/../lib/jsp-api-2.1-6.1.14.jar:/opt/hbase/bin/../lib/jsr305-1.3.9.jar:/opt/hbase/bin/../lib/junit-4.11.jar:/opt/hbase/bin/../lib/leveldbjni-all-1.8.jar:/opt/hbase/bin/../lib/libthrift-0.9.0.jar:/opt/hbase/bin/../lib/log4j-1.2.17.jar:/opt/hbase/bin/../lib/metrics-core-2.2.0.jar:/opt/hbase/bin/../lib/netty-3.2.4.Final.jar:/opt/hbase/bin/../lib/netty-all-4.0.23.Final.jar:/opt/hbase/bin/../lib/paranamer-2.3.jar:/opt/hbase/bin/../lib/protobuf-java-2.5.0.jar:/opt/hbase/bin/../lib/servlet-api-2.5-6.1.14.jar:/opt/hbase/bin/../lib/servlet-api-2.5.jar:/opt/hbase/bin/../lib/slf4j-api-1.7.7.jar:/opt/hbase/bin/../lib/slf4j-log4j12-1.7.5.jar:/opt/hbase/bin/../lib/snappy-java-1.0.4.1.jar:/opt/hbase/bin/../lib/spymemcached-2.11.6.jar:/opt/hbase/bin/../lib/xmlenc-0.52.jar:/opt/hbase/bin/../lib/xz-1.0.jar:/opt/hbase/bin/../lib/zookeeper-3.4.6.jar:/opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-auth-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/opt/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/opt/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop/share/hadoop/common/lib/curator-framework-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/opt/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/opt/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop/share/hadoop/common/lib/curator-client-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/opt/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-annotations-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/opt/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop/share/hadoop/common/lib/htrace-core-3.0.4.jar:/opt/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop/share/hadoop/common/hadoop-common-2.6.0-tests.jar:/opt/hadoop/share/hadoop/common/hadoop-common-2.6.0.jar:/opt/hadoop/share/hadoop/common/hadoop-nfs-2.6.0.jar:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/opt/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.0-tests.jar:/opt/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jline-0.9.94.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-tests.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar
2015-11-08 15:45:48,012 INFO  [main] zookeeper.ZooKeeper: Client environment:java.library.path=/opt/hadoop/lib/native::/opt/hadoop/lib/native:
2015-11-08 15:45:48,013 INFO  [main] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2015-11-08 15:45:48,013 INFO  [main] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2015-11-08 15:45:48,013 INFO  [main] zookeeper.ZooKeeper: Client environment:os.name=Linux
2015-11-08 15:45:48,013 INFO  [main] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2015-11-08 15:45:48,013 INFO  [main] zookeeper.ZooKeeper: Client environment:os.version=2.6.32-573.el6.x86_64
2015-11-08 15:45:48,013 INFO  [main] zookeeper.ZooKeeper: Client environment:user.name=hadoop
2015-11-08 15:45:48,013 INFO  [main] zookeeper.ZooKeeper: Client environment:user.home=/home/hadoop
2015-11-08 15:45:48,013 INFO  [main] zookeeper.ZooKeeper: Client environment:user.dir=/opt/hbase/bin
2015-11-08 15:45:48,014 INFO  [main] zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=master:160000x0, quorum=localhost:2181, baseZNode=/hbase
2015-11-08 15:45:48,040 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 15:45:48,054 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
2015-11-08 15:45:48,129 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x150e60edafb0000, negotiated timeout = 90000
2015-11-08 15:45:48,239 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2015-11-08 15:45:48,239 INFO  [RpcServer.listener,port=16000] ipc.RpcServer: RpcServer.listener,port=16000: starting
2015-11-08 15:45:48,312 INFO  [main] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-11-08 15:45:48,318 INFO  [main] http.HttpRequestLog: Http request log for http.requests.master is not defined
2015-11-08 15:45:48,334 INFO  [main] http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.hbase.http.HttpServer$QuotingInputFilter)
2015-11-08 15:45:48,337 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context master
2015-11-08 15:45:48,338 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-11-08 15:45:48,338 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-11-08 15:45:48,360 INFO  [main] http.HttpServer: Jetty bound to port 16010
2015-11-08 15:45:48,360 INFO  [main] mortbay.log: jetty-6.1.26
2015-11-08 15:45:48,986 INFO  [main] mortbay.log: Started SelectChannelConnector@0.0.0.0:16010
2015-11-08 15:45:48,990 INFO  [main] master.HMaster: hbase.rootdir=hdfs://192.168.1.101:9000/hbase, hbase.cluster.distributed=true
2015-11-08 15:45:49,005 INFO  [main] master.HMaster: Adding backup master ZNode /hbase/backup-masters/master,16000,1446968746915
2015-11-08 15:45:49,156 INFO  [master:16000.activeMasterManager] master.ActiveMasterManager: Deleting ZNode for /hbase/backup-masters/master,16000,1446968746915 from backup master directory
2015-11-08 15:45:49,166 INFO  [master:16000.activeMasterManager] master.ActiveMasterManager: Registered Active Master=master,16000,1446968746915
2015-11-08 15:45:49,265 INFO  [master/master/192.168.1.101:16000] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x5d0f75d6 connecting to ZooKeeper ensemble=localhost:2181
2015-11-08 15:45:49,265 INFO  [master/master/192.168.1.101:16000] zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=hconnection-0x5d0f75d60x0, quorum=localhost:2181, baseZNode=/hbase
2015-11-08 15:45:49,277 INFO  [master/master/192.168.1.101:16000-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 15:45:49,277 INFO  [master/master/192.168.1.101:16000-SendThread(localhost:2181)] zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
2015-11-08 15:45:49,282 INFO  [master/master/192.168.1.101:16000-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x150e60edafb0001, negotiated timeout = 90000
2015-11-08 15:45:49,286 INFO  [master/master/192.168.1.101:16000] client.ZooKeeperRegistry: ClusterId read in ZooKeeper is null
2015-11-08 15:45:49,290 FATAL [master:16000.activeMasterManager] master.HMaster: Failed to become active master
java.net.ConnectException: Call From master/192.168.1.101 to master:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.setSafeMode(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.setSafeMode(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.setSafeMode(ClientNamenodeProtocolTranslatorPB.java:602)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.setSafeMode(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.setSafeMode(DFSClient.java:2264)
	at org.apache.hadoop.hdfs.DistributedFileSystem.setSafeMode(DistributedFileSystem.java:986)
	at org.apache.hadoop.hdfs.DistributedFileSystem.setSafeMode(DistributedFileSystem.java:970)
	at org.apache.hadoop.hbase.util.FSUtils.isInSafeMode(FSUtils.java:524)
	at org.apache.hadoop.hbase.util.FSUtils.waitOnSafeMode(FSUtils.java:970)
	at org.apache.hadoop.hbase.master.MasterFileSystem.checkRootDir(MasterFileSystem.java:417)
	at org.apache.hadoop.hbase.master.MasterFileSystem.createInitialFileSystemLayout(MasterFileSystem.java:146)
	at org.apache.hadoop.hbase.master.MasterFileSystem.<init>(MasterFileSystem.java:126)
	at org.apache.hadoop.hbase.master.HMaster.finishActiveMasterInitialization(HMaster.java:649)
	at org.apache.hadoop.hbase.master.HMaster.access$500(HMaster.java:182)
	at org.apache.hadoop.hbase.master.HMaster$1.run(HMaster.java:1646)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 29 more
2015-11-08 15:45:49,293 FATAL [master:16000.activeMasterManager] master.HMaster: Unhandled exception. Starting shutdown.
java.net.ConnectException: Call From master/192.168.1.101 to master:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.setSafeMode(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.setSafeMode(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.setSafeMode(ClientNamenodeProtocolTranslatorPB.java:602)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.setSafeMode(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.setSafeMode(DFSClient.java:2264)
	at org.apache.hadoop.hdfs.DistributedFileSystem.setSafeMode(DistributedFileSystem.java:986)
	at org.apache.hadoop.hdfs.DistributedFileSystem.setSafeMode(DistributedFileSystem.java:970)
	at org.apache.hadoop.hbase.util.FSUtils.isInSafeMode(FSUtils.java:524)
	at org.apache.hadoop.hbase.util.FSUtils.waitOnSafeMode(FSUtils.java:970)
	at org.apache.hadoop.hbase.master.MasterFileSystem.checkRootDir(MasterFileSystem.java:417)
	at org.apache.hadoop.hbase.master.MasterFileSystem.createInitialFileSystemLayout(MasterFileSystem.java:146)
	at org.apache.hadoop.hbase.master.MasterFileSystem.<init>(MasterFileSystem.java:126)
	at org.apache.hadoop.hbase.master.HMaster.finishActiveMasterInitialization(HMaster.java:649)
	at org.apache.hadoop.hbase.master.HMaster.access$500(HMaster.java:182)
	at org.apache.hadoop.hbase.master.HMaster$1.run(HMaster.java:1646)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 29 more
2015-11-08 15:45:49,303 INFO  [master:16000.activeMasterManager] regionserver.HRegionServer: STOPPED: Unhandled exception. Starting shutdown.
2015-11-08 15:45:52,317 INFO  [master/master/192.168.1.101:16000] ipc.RpcServer: Stopping server on 16000
2015-11-08 15:45:52,318 INFO  [RpcServer.listener,port=16000] ipc.RpcServer: RpcServer.listener,port=16000: stopping
2015-11-08 15:45:52,318 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopped
2015-11-08 15:45:52,318 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopping
2015-11-08 15:45:52,319 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: Stopping infoServer
2015-11-08 15:45:52,322 INFO  [master/master/192.168.1.101:16000] mortbay.log: Stopped SelectChannelConnector@0.0.0.0:16010
2015-11-08 15:45:52,423 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: stopping server master,16000,1446968746915
2015-11-08 15:45:52,423 INFO  [master/master/192.168.1.101:16000] client.ConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x150e60edafb0001
2015-11-08 15:45:52,432 INFO  [master/master/192.168.1.101:16000] zookeeper.ZooKeeper: Session: 0x150e60edafb0001 closed
2015-11-08 15:45:52,432 INFO  [master/master/192.168.1.101:16000-EventThread] zookeeper.ClientCnxn: EventThread shut down
2015-11-08 15:45:52,435 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: stopping server master,16000,1446968746915; all regions closed.
2015-11-08 15:45:52,436 INFO  [master/master/192.168.1.101:16000] hbase.ChoreService: Chore service for: master,16000,1446968746915 had [] on shutdown
2015-11-08 15:45:52,449 INFO  [master/master/192.168.1.101:16000] ipc.RpcServer: Stopping server on 16000
2015-11-08 15:45:52,462 INFO  [master/master/192.168.1.101:16000] zookeeper.RecoverableZooKeeper: Node /hbase/rs/master,16000,1446968746915 already deleted, retry=false
2015-11-08 15:45:52,474 INFO  [master/master/192.168.1.101:16000] zookeeper.ZooKeeper: Session: 0x150e60edafb0000 closed
2015-11-08 15:45:52,474 INFO  [main-EventThread] zookeeper.ClientCnxn: EventThread shut down
2015-11-08 15:45:52,474 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: stopping server master,16000,1446968746915; zookeeper connection closed.
2015-11-08 15:45:52,474 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: master/master/192.168.1.101:16000 exiting
Sun Nov  8 15:45:56 CST 2015 Stopping hbase (via master)
Sun Nov  8 15:54:19 CST 2015 Starting master on master
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 30141
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 10240
cpu time               (seconds, -t) unlimited
max user processes              (-u) 1024
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2015-11-08 15:54:19,813 INFO  [main] util.VersionInfo: HBase 1.1.2
2015-11-08 15:54:19,814 INFO  [main] util.VersionInfo: Source code repository git://hw11397.local/Volumes/hbase-1.1.2RC2/hbase revision=cc2b70cf03e3378800661ec5cab11eb43fafe0fc
2015-11-08 15:54:19,814 INFO  [main] util.VersionInfo: Compiled by ndimiduk on Wed Aug 26 20:11:27 PDT 2015
2015-11-08 15:54:19,814 INFO  [main] util.VersionInfo: From source with checksum 73da41f3d1b867b7aba6166c77fafc17
2015-11-08 15:54:20,205 INFO  [main] util.ServerCommandLine: env:TERM=xterm
2015-11-08 15:54:20,205 INFO  [main] util.ServerCommandLine: env:HADOOP_COMMON_LIB_NATIVE_DIR=/opt/hadoop/lib/native
2015-11-08 15:54:20,205 INFO  [main] util.ServerCommandLine: env:IMSETTINGS_MODULE=none
2015-11-08 15:54:20,205 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/opt/java
2015-11-08 15:54:20,206 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/opt/hbase/bin/..
2015-11-08 15:54:20,206 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2015-11-08 15:54:20,206 INFO  [main] util.ServerCommandLine: env:SESSION_MANAGER=local/unix:@/tmp/.ICE-unix/2995,unix/unix:/tmp/.ICE-unix/2995
2015-11-08 15:54:20,206 INFO  [main] util.ServerCommandLine: env:IMSETTINGS_INTEGRATE_DESKTOP=yes
2015-11-08 15:54:20,206 INFO  [main] util.ServerCommandLine: env:GNOME_DESKTOP_SESSION_ID=this-is-deprecated
2015-11-08 15:54:20,206 INFO  [main] util.ServerCommandLine: env:MAIL=/var/spool/mail/hadoop
2015-11-08 15:54:20,206 INFO  [main] util.ServerCommandLine: env:XDG_SESSION_COOKIE=ab8c9d4f5491283c7c300d7800000013-1446958848.52338-1725977001
2015-11-08 15:54:20,206 INFO  [main] util.ServerCommandLine: env:GDMSESSION=gnome
2015-11-08 15:54:20,206 INFO  [main] util.ServerCommandLine: env:HOSTNAME=master
2015-11-08 15:54:20,206 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/tmp/hbase-hadoop-master.znode
2015-11-08 15:54:20,206 INFO  [main] util.ServerCommandLine: env:PWD=/opt/hbase/bin
2015-11-08 15:54:20,206 INFO  [main] util.ServerCommandLine: env:HBASE_MASTER_OPTS= -XX:PermSize=128m -XX:MaxPermSize=128m
2015-11-08 15:54:20,206 INFO  [main] util.ServerCommandLine: env:CVS_RSH=ssh
2015-11-08 15:54:20,206 INFO  [main] util.ServerCommandLine: env:JAVA_LIBRARY_PATH=/opt/hadoop/lib/native::/opt/hadoop/lib/native:
2015-11-08 15:54:20,206 INFO  [main] util.ServerCommandLine: env:G_BROKEN_FILENAMES=1
2015-11-08 15:54:20,206 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2015-11-08 15:54:20,206 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2015-11-08 15:54:20,206 INFO  [main] util.ServerCommandLine: env:NLSPATH=/usr/dt/lib/nls/msg/%L/%N.cat
2015-11-08 15:54:20,206 INFO  [main] util.ServerCommandLine: env:GNOME_KEYRING_SOCKET=/tmp/keyring-IruJ62/socket
2015-11-08 15:54:20,206 INFO  [main] util.ServerCommandLine: env:GDM_KEYBOARD_LAYOUT=us
2015-11-08 15:54:20,206 INFO  [main] util.ServerCommandLine: env:HBASE_REGIONSERVER_OPTS= -XX:PermSize=128m -XX:MaxPermSize=128m
2015-11-08 15:54:20,207 INFO  [main] util.ServerCommandLine: env:HISTSIZE=1000
2015-11-08 15:54:20,207 INFO  [main] util.ServerCommandLine: env:PATH=/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin:/sbin:/opt/java//bin:/opt/java/jre/bin:/opt/hadoop/bin:/home/hadoop/bin
2015-11-08 15:54:20,207 INFO  [main] util.ServerCommandLine: env:QTLIB=/usr/lib64/qt-3.3/lib
2015-11-08 15:54:20,207 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2015-11-08 15:54:20,207 INFO  [main] util.ServerCommandLine: env:GDM_LANG=en_US.UTF-8
2015-11-08 15:54:20,207 INFO  [main] util.ServerCommandLine: env:XAUTHORITY=/var/run/gdm/auth-for-hadoop-akmkFp/database
2015-11-08 15:54:20,207 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/tmp/hbase-hadoop-master.autorestart
2015-11-08 15:54:20,207 INFO  [main] util.ServerCommandLine: env:USERNAME=hadoop
2015-11-08 15:54:20,207 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-hadoop-master-master.log
2015-11-08 15:54:20,207 INFO  [main] util.ServerCommandLine: env:SSH_ASKPASS=/usr/libexec/openssh/gnome-ssh-askpass
2015-11-08 15:54:20,207 INFO  [main] util.ServerCommandLine: env:SHLVL=5
2015-11-08 15:54:20,207 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/opt/hbase/bin/../logs
2015-11-08 15:54:20,207 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-XX:+UseConcMarkSweepGC   -XX:PermSize=128m -XX:MaxPermSize=128m -Dhbase.log.dir=/opt/hbase/bin/../logs -Dhbase.log.file=hbase-hadoop-master-master.log -Dhbase.home.dir=/opt/hbase/bin/.. -Dhbase.id.str=hadoop -Dhbase.root.logger=INFO,RFA -Djava.library.path=/opt/hadoop/lib/native::/opt/hadoop/lib/native: -Dhbase.security.logger=INFO,RFAS
2015-11-08 15:54:20,207 INFO  [main] util.ServerCommandLine: env:XFILESEARCHPATH=/usr/dt/app-defaults/%L/Dt
2015-11-08 15:54:20,207 INFO  [main] util.ServerCommandLine: env:COLORTERM=gnome-terminal
2015-11-08 15:54:20,207 INFO  [main] util.ServerCommandLine: env:QT_IM_MODULE=xim
2015-11-08 15:54:20,207 INFO  [main] util.ServerCommandLine: env:WINDOWID=20979824
2015-11-08 15:54:20,207 INFO  [main] util.ServerCommandLine: env:LOGNAME=hadoop
2015-11-08 15:54:20,208 INFO  [main] util.ServerCommandLine: env:QTDIR=/usr/lib64/qt-3.3
2015-11-08 15:54:20,208 INFO  [main] util.ServerCommandLine: env:XMODIFIERS=@im=none
2015-11-08 15:54:20,208 INFO  [main] util.ServerCommandLine: env:SSH_AUTH_SOCK=/tmp/keyring-IruJ62/socket.ssh
2015-11-08 15:54:20,208 INFO  [main] util.ServerCommandLine: env:HADOOP_HOME=/opt/hadoop
2015-11-08 15:54:20,208 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=:/opt/hadoop/lib/native::/opt/hadoop/lib/native:
2015-11-08 15:54:20,208 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2015-11-08 15:54:20,208 INFO  [main] util.ServerCommandLine: env:HADOOP_OPTS=-Djava.library.path=/opt/hadoop/lib/native
2015-11-08 15:54:20,208 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2015-11-08 15:54:20,208 INFO  [main] util.ServerCommandLine: env:DBUS_SESSION_BUS_ADDRESS=unix:abstract=/tmp/dbus-uqNe1cANDo,guid=eca351d0636069d92d6d2f1900000495
2015-11-08 15:54:20,208 INFO  [main] util.ServerCommandLine: env:GNOME_KEYRING_PID=2985
2015-11-08 15:54:20,208 INFO  [main] util.ServerCommandLine: env:GTK_RC_FILES=/etc/gtk/gtkrc:/home/hadoop/.gtkrc-1.2-gnome2
2015-11-08 15:54:20,208 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2015-11-08 15:54:20,209 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/opt/hbase/bin/../conf:/opt/java/lib/tools.jar:/opt/hbase/bin/..:/opt/hbase/bin/../lib/activation-1.1.jar:/opt/hbase/bin/../lib/aopalliance-1.0.jar:/opt/hbase/bin/../lib/apacheds-i18n-2.0.0-M15.jar:/opt/hbase/bin/../lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hbase/bin/../lib/api-asn1-api-1.0.0-M20.jar:/opt/hbase/bin/../lib/api-util-1.0.0-M20.jar:/opt/hbase/bin/../lib/asm-3.1.jar:/opt/hbase/bin/../lib/avro-1.7.4.jar:/opt/hbase/bin/../lib/commons-beanutils-1.7.0.jar:/opt/hbase/bin/../lib/commons-beanutils-core-1.8.0.jar:/opt/hbase/bin/../lib/commons-cli-1.2.jar:/opt/hbase/bin/../lib/commons-codec-1.9.jar:/opt/hbase/bin/../lib/commons-collections-3.2.1.jar:/opt/hbase/bin/../lib/commons-compress-1.4.1.jar:/opt/hbase/bin/../lib/commons-configuration-1.6.jar:/opt/hbase/bin/../lib/commons-daemon-1.0.13.jar:/opt/hbase/bin/../lib/commons-digester-1.8.jar:/opt/hbase/bin/../lib/commons-el-1.0.jar:/opt/hbase/bin/../lib/commons-httpclient-3.1.jar:/opt/hbase/bin/../lib/commons-io-2.4.jar:/opt/hbase/bin/../lib/commons-lang-2.6.jar:/opt/hbase/bin/../lib/commons-logging-1.2.jar:/opt/hbase/bin/../lib/commons-math-2.2.jar:/opt/hbase/bin/../lib/commons-math3-3.1.1.jar:/opt/hbase/bin/../lib/commons-net-3.1.jar:/opt/hbase/bin/../lib/disruptor-3.3.0.jar:/opt/hbase/bin/../lib/findbugs-annotations-1.3.9-1.jar:/opt/hbase/bin/../lib/guava-12.0.1.jar:/opt/hbase/bin/../lib/guice-3.0.jar:/opt/hbase/bin/../lib/guice-servlet-3.0.jar:/opt/hbase/bin/../lib/hadoop-annotations-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-auth-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-client-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-common-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-hdfs-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-app-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-common-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-core-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-jobclient-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-shuffle-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-api-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-client-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-common-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-server-common-2.5.1.jar:/opt/hbase/bin/../lib/hbase-annotations-1.1.2.jar:/opt/hbase/bin/../lib/hbase-annotations-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-client-1.1.2.jar:/opt/hbase/bin/../lib/hbase-common-1.1.2.jar:/opt/hbase/bin/../lib/hbase-common-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-examples-1.1.2.jar:/opt/hbase/bin/../lib/hbase-hadoop2-compat-1.1.2.jar:/opt/hbase/bin/../lib/hbase-hadoop-compat-1.1.2.jar:/opt/hbase/bin/../lib/hbase-it-1.1.2.jar:/opt/hbase/bin/../lib/hbase-it-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-prefix-tree-1.1.2.jar:/opt/hbase/bin/../lib/hbase-procedure-1.1.2.jar:/opt/hbase/bin/../lib/hbase-protocol-1.1.2.jar:/opt/hbase/bin/../lib/hbase-resource-bundle-1.1.2.jar:/opt/hbase/bin/../lib/hbase-rest-1.1.2.jar:/opt/hbase/bin/../lib/hbase-server-1.1.2.jar:/opt/hbase/bin/../lib/hbase-server-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-shell-1.1.2.jar:/opt/hbase/bin/../lib/hbase-thrift-1.1.2.jar:/opt/hbase/bin/../lib/htrace-core-3.1.0-incubating.jar:/opt/hbase/bin/../lib/httpclient-4.2.5.jar:/opt/hbase/bin/../lib/httpcore-4.1.3.jar:/opt/hbase/bin/../lib/jackson-core-asl-1.9.13.jar:/opt/hbase/bin/../lib/jackson-jaxrs-1.9.13.jar:/opt/hbase/bin/../lib/jackson-mapper-asl-1.9.13.jar:/opt/hbase/bin/../lib/jackson-xc-1.9.13.jar:/opt/hbase/bin/../lib/jamon-runtime-2.3.1.jar:/opt/hbase/bin/../lib/jasper-compiler-5.5.23.jar:/opt/hbase/bin/../lib/jasper-runtime-5.5.23.jar:/opt/hbase/bin/../lib/javax.inject-1.jar:/opt/hbase/bin/../lib/java-xmlbuilder-0.4.jar:/opt/hbase/bin/../lib/jaxb-api-2.2.2.jar:/opt/hbase/bin/../lib/jaxb-impl-2.2.3-1.jar:/opt/hbase/bin/../lib/jcodings-1.0.8.jar:/opt/hbase/bin/../lib/jersey-client-1.9.jar:/opt/hbase/bin/../lib/jersey-core-1.9.jar:/opt/hbase/bin/../lib/jersey-guice-1.9.jar:/opt/hbase/bin/../lib/jersey-json-1.9.jar:/opt/hbase/bin/../lib/jersey-server-1.9.jar:/opt/hbase/bin/../lib/jets3t-0.9.0.jar:/opt/hbase/bin/../lib/jettison-1.3.3.jar:/opt/hbase/bin/../lib/jetty-6.1.26.jar:/opt/hbase/bin/../lib/jetty-sslengine-6.1.26.jar:/opt/hbase/bin/../lib/jetty-util-6.1.26.jar:/opt/hbase/bin/../lib/joni-2.1.2.jar:/opt/hbase/bin/../lib/jruby-complete-1.6.8.jar:/opt/hbase/bin/../lib/jsch-0.1.42.jar:/opt/hbase/bin/../lib/jsp-2.1-6.1.14.jar:/opt/hbase/bin/../lib/jsp-api-2.1-6.1.14.jar:/opt/hbase/bin/../lib/jsr305-1.3.9.jar:/opt/hbase/bin/../lib/junit-4.11.jar:/opt/hbase/bin/../lib/leveldbjni-all-1.8.jar:/opt/hbase/bin/../lib/libthrift-0.9.0.jar:/opt/hbase/bin/../lib/log4j-1.2.17.jar:/opt/hbase/bin/../lib/metrics-core-2.2.0.jar:/opt/hbase/bin/../lib/netty-3.2.4.Final.jar:/opt/hbase/bin/../lib/netty-all-4.0.23.Final.jar:/opt/hbase/bin/../lib/paranamer-2.3.jar:/opt/hbase/bin/../lib/protobuf-java-2.5.0.jar:/opt/hbase/bin/../lib/servlet-api-2.5-6.1.14.jar:/opt/hbase/bin/../lib/servlet-api-2.5.jar:/opt/hbase/bin/../lib/slf4j-api-1.7.7.jar:/opt/hbase/bin/../lib/slf4j-log4j12-1.7.5.jar:/opt/hbase/bin/../lib/snappy-java-1.0.4.1.jar:/opt/hbase/bin/../lib/spymemcached-2.11.6.jar:/opt/hbase/bin/../lib/xmlenc-0.52.jar:/opt/hbase/bin/../lib/xz-1.0.jar:/opt/hbase/bin/../lib/zookeeper-3.4.6.jar:/opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/contrib/capacity-scheduler/*.jar
2015-11-08 15:54:20,209 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2015-11-08 15:54:20,209 INFO  [main] util.ServerCommandLine: env:JRE_HOME=/opt/java/jre
2015-11-08 15:54:20,209 INFO  [main] util.ServerCommandLine: env:DESKTOP_SESSION=gnome
2015-11-08 15:54:20,209 INFO  [main] util.ServerCommandLine: env:QTINC=/usr/lib64/qt-3.3/include
2015-11-08 15:54:20,209 INFO  [main] util.ServerCommandLine: env:DISPLAY=192.168.1.100:2.0
2015-11-08 15:54:20,209 INFO  [main] util.ServerCommandLine: env:USER=hadoop
2015-11-08 15:54:20,209 INFO  [main] util.ServerCommandLine: env:HISTCONTROL=ignoredups
2015-11-08 15:54:20,209 INFO  [main] util.ServerCommandLine: env:HOME=/home/hadoop
2015-11-08 15:54:20,209 INFO  [main] util.ServerCommandLine: env:LESSOPEN=||/usr/bin/lesspipe.sh %s
2015-11-08 15:54:20,210 INFO  [main] util.ServerCommandLine: env:LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arj=01;31:*.taz=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lz=01;31:*.xz=01;31:*.bz2=01;31:*.tbz=01;31:*.tbz2=01;31:*.bz=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.rar=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
2015-11-08 15:54:20,210 INFO  [main] util.ServerCommandLine: env:ORBIT_SOCKETDIR=/tmp/orbit-hadoop
2015-11-08 15:54:20,210 INFO  [main] util.ServerCommandLine: env:LANG=en_US.UTF-8
2015-11-08 15:54:20,210 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-hadoop-master-master
2015-11-08 15:54:20,210 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=hadoop
2015-11-08 15:54:20,211 INFO  [main] util.ServerCommandLine: vmName=Java HotSpot(TM) 64-Bit Server VM, vmVendor=Oracle Corporation, vmVersion=24.79-b02
2015-11-08 15:54:20,211 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_master, -XX:OnOutOfMemoryError=kill -9 %p, -XX:+UseConcMarkSweepGC, -XX:PermSize=128m, -XX:MaxPermSize=128m, -Dhbase.log.dir=/opt/hbase/bin/../logs, -Dhbase.log.file=hbase-hadoop-master-master.log, -Dhbase.home.dir=/opt/hbase/bin/.., -Dhbase.id.str=hadoop, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=/opt/hadoop/lib/native::/opt/hadoop/lib/native:, -Dhbase.security.logger=INFO,RFAS]
2015-11-08 15:54:20,665 WARN  [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-11-08 15:54:20,848 INFO  [main] regionserver.RSRpcServices: master/master/192.168.1.101:16000 server-side HConnection retries=350
2015-11-08 15:54:20,979 INFO  [main] ipc.SimpleRpcScheduler: Using deadline as user call queue, count=3
2015-11-08 15:54:20,993 INFO  [main] ipc.RpcServer: master/master/192.168.1.101:16000: started 10 reader(s).
2015-11-08 15:54:21,039 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2015-11-08 15:54:21,092 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-11-08 15:54:21,092 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2015-11-08 15:54:21,619 INFO  [main] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2015-11-08 15:54:21,793 INFO  [main] zookeeper.RecoverableZooKeeper: Process identifier=master:16000 connecting to ZooKeeper ensemble=localhost:2181
2015-11-08 15:54:21,802 INFO  [main] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2015-11-08 15:54:21,802 INFO  [main] zookeeper.ZooKeeper: Client environment:host.name=master
2015-11-08 15:54:21,802 INFO  [main] zookeeper.ZooKeeper: Client environment:java.version=1.7.0_79
2015-11-08 15:54:21,802 INFO  [main] zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
2015-11-08 15:54:21,802 INFO  [main] zookeeper.ZooKeeper: Client environment:java.home=/opt/java/jre
2015-11-08 15:54:21,802 INFO  [main] zookeeper.ZooKeeper: Client environment:java.class.path=/opt/hbase/bin/../conf:/opt/java/lib/tools.jar:/opt/hbase/bin/..:/opt/hbase/bin/../lib/activation-1.1.jar:/opt/hbase/bin/../lib/aopalliance-1.0.jar:/opt/hbase/bin/../lib/apacheds-i18n-2.0.0-M15.jar:/opt/hbase/bin/../lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hbase/bin/../lib/api-asn1-api-1.0.0-M20.jar:/opt/hbase/bin/../lib/api-util-1.0.0-M20.jar:/opt/hbase/bin/../lib/asm-3.1.jar:/opt/hbase/bin/../lib/avro-1.7.4.jar:/opt/hbase/bin/../lib/commons-beanutils-1.7.0.jar:/opt/hbase/bin/../lib/commons-beanutils-core-1.8.0.jar:/opt/hbase/bin/../lib/commons-cli-1.2.jar:/opt/hbase/bin/../lib/commons-codec-1.9.jar:/opt/hbase/bin/../lib/commons-collections-3.2.1.jar:/opt/hbase/bin/../lib/commons-compress-1.4.1.jar:/opt/hbase/bin/../lib/commons-configuration-1.6.jar:/opt/hbase/bin/../lib/commons-daemon-1.0.13.jar:/opt/hbase/bin/../lib/commons-digester-1.8.jar:/opt/hbase/bin/../lib/commons-el-1.0.jar:/opt/hbase/bin/../lib/commons-httpclient-3.1.jar:/opt/hbase/bin/../lib/commons-io-2.4.jar:/opt/hbase/bin/../lib/commons-lang-2.6.jar:/opt/hbase/bin/../lib/commons-logging-1.2.jar:/opt/hbase/bin/../lib/commons-math-2.2.jar:/opt/hbase/bin/../lib/commons-math3-3.1.1.jar:/opt/hbase/bin/../lib/commons-net-3.1.jar:/opt/hbase/bin/../lib/disruptor-3.3.0.jar:/opt/hbase/bin/../lib/findbugs-annotations-1.3.9-1.jar:/opt/hbase/bin/../lib/guava-12.0.1.jar:/opt/hbase/bin/../lib/guice-3.0.jar:/opt/hbase/bin/../lib/guice-servlet-3.0.jar:/opt/hbase/bin/../lib/hadoop-annotations-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-auth-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-client-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-common-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-hdfs-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-app-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-common-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-core-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-jobclient-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-shuffle-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-api-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-client-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-common-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-server-common-2.5.1.jar:/opt/hbase/bin/../lib/hbase-annotations-1.1.2.jar:/opt/hbase/bin/../lib/hbase-annotations-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-client-1.1.2.jar:/opt/hbase/bin/../lib/hbase-common-1.1.2.jar:/opt/hbase/bin/../lib/hbase-common-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-examples-1.1.2.jar:/opt/hbase/bin/../lib/hbase-hadoop2-compat-1.1.2.jar:/opt/hbase/bin/../lib/hbase-hadoop-compat-1.1.2.jar:/opt/hbase/bin/../lib/hbase-it-1.1.2.jar:/opt/hbase/bin/../lib/hbase-it-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-prefix-tree-1.1.2.jar:/opt/hbase/bin/../lib/hbase-procedure-1.1.2.jar:/opt/hbase/bin/../lib/hbase-protocol-1.1.2.jar:/opt/hbase/bin/../lib/hbase-resource-bundle-1.1.2.jar:/opt/hbase/bin/../lib/hbase-rest-1.1.2.jar:/opt/hbase/bin/../lib/hbase-server-1.1.2.jar:/opt/hbase/bin/../lib/hbase-server-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-shell-1.1.2.jar:/opt/hbase/bin/../lib/hbase-thrift-1.1.2.jar:/opt/hbase/bin/../lib/htrace-core-3.1.0-incubating.jar:/opt/hbase/bin/../lib/httpclient-4.2.5.jar:/opt/hbase/bin/../lib/httpcore-4.1.3.jar:/opt/hbase/bin/../lib/jackson-core-asl-1.9.13.jar:/opt/hbase/bin/../lib/jackson-jaxrs-1.9.13.jar:/opt/hbase/bin/../lib/jackson-mapper-asl-1.9.13.jar:/opt/hbase/bin/../lib/jackson-xc-1.9.13.jar:/opt/hbase/bin/../lib/jamon-runtime-2.3.1.jar:/opt/hbase/bin/../lib/jasper-compiler-5.5.23.jar:/opt/hbase/bin/../lib/jasper-runtime-5.5.23.jar:/opt/hbase/bin/../lib/javax.inject-1.jar:/opt/hbase/bin/../lib/java-xmlbuilder-0.4.jar:/opt/hbase/bin/../lib/jaxb-api-2.2.2.jar:/opt/hbase/bin/../lib/jaxb-impl-2.2.3-1.jar:/opt/hbase/bin/../lib/jcodings-1.0.8.jar:/opt/hbase/bin/../lib/jersey-client-1.9.jar:/opt/hbase/bin/../lib/jersey-core-1.9.jar:/opt/hbase/bin/../lib/jersey-guice-1.9.jar:/opt/hbase/bin/../lib/jersey-json-1.9.jar:/opt/hbase/bin/../lib/jersey-server-1.9.jar:/opt/hbase/bin/../lib/jets3t-0.9.0.jar:/opt/hbase/bin/../lib/jettison-1.3.3.jar:/opt/hbase/bin/../lib/jetty-6.1.26.jar:/opt/hbase/bin/../lib/jetty-sslengine-6.1.26.jar:/opt/hbase/bin/../lib/jetty-util-6.1.26.jar:/opt/hbase/bin/../lib/joni-2.1.2.jar:/opt/hbase/bin/../lib/jruby-complete-1.6.8.jar:/opt/hbase/bin/../lib/jsch-0.1.42.jar:/opt/hbase/bin/../lib/jsp-2.1-6.1.14.jar:/opt/hbase/bin/../lib/jsp-api-2.1-6.1.14.jar:/opt/hbase/bin/../lib/jsr305-1.3.9.jar:/opt/hbase/bin/../lib/junit-4.11.jar:/opt/hbase/bin/../lib/leveldbjni-all-1.8.jar:/opt/hbase/bin/../lib/libthrift-0.9.0.jar:/opt/hbase/bin/../lib/log4j-1.2.17.jar:/opt/hbase/bin/../lib/metrics-core-2.2.0.jar:/opt/hbase/bin/../lib/netty-3.2.4.Final.jar:/opt/hbase/bin/../lib/netty-all-4.0.23.Final.jar:/opt/hbase/bin/../lib/paranamer-2.3.jar:/opt/hbase/bin/../lib/protobuf-java-2.5.0.jar:/opt/hbase/bin/../lib/servlet-api-2.5-6.1.14.jar:/opt/hbase/bin/../lib/servlet-api-2.5.jar:/opt/hbase/bin/../lib/slf4j-api-1.7.7.jar:/opt/hbase/bin/../lib/slf4j-log4j12-1.7.5.jar:/opt/hbase/bin/../lib/snappy-java-1.0.4.1.jar:/opt/hbase/bin/../lib/spymemcached-2.11.6.jar:/opt/hbase/bin/../lib/xmlenc-0.52.jar:/opt/hbase/bin/../lib/xz-1.0.jar:/opt/hbase/bin/../lib/zookeeper-3.4.6.jar:/opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-auth-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/opt/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/opt/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop/share/hadoop/common/lib/curator-framework-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/opt/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/opt/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop/share/hadoop/common/lib/curator-client-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/opt/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-annotations-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/opt/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop/share/hadoop/common/lib/htrace-core-3.0.4.jar:/opt/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop/share/hadoop/common/hadoop-common-2.6.0-tests.jar:/opt/hadoop/share/hadoop/common/hadoop-common-2.6.0.jar:/opt/hadoop/share/hadoop/common/hadoop-nfs-2.6.0.jar:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/opt/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.0-tests.jar:/opt/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jline-0.9.94.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-tests.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar
2015-11-08 15:54:21,802 INFO  [main] zookeeper.ZooKeeper: Client environment:java.library.path=/opt/hadoop/lib/native::/opt/hadoop/lib/native:
2015-11-08 15:54:21,802 INFO  [main] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2015-11-08 15:54:21,802 INFO  [main] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2015-11-08 15:54:21,802 INFO  [main] zookeeper.ZooKeeper: Client environment:os.name=Linux
2015-11-08 15:54:21,802 INFO  [main] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2015-11-08 15:54:21,802 INFO  [main] zookeeper.ZooKeeper: Client environment:os.version=2.6.32-573.el6.x86_64
2015-11-08 15:54:21,802 INFO  [main] zookeeper.ZooKeeper: Client environment:user.name=hadoop
2015-11-08 15:54:21,802 INFO  [main] zookeeper.ZooKeeper: Client environment:user.home=/home/hadoop
2015-11-08 15:54:21,802 INFO  [main] zookeeper.ZooKeeper: Client environment:user.dir=/opt/hbase/bin
2015-11-08 15:54:21,803 INFO  [main] zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=master:160000x0, quorum=localhost:2181, baseZNode=/hbase
2015-11-08 15:54:21,826 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 15:54:21,828 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
2015-11-08 15:54:21,904 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x150e616b3060000, negotiated timeout = 90000
2015-11-08 15:54:21,973 INFO  [RpcServer.listener,port=16000] ipc.RpcServer: RpcServer.listener,port=16000: starting
2015-11-08 15:54:21,973 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2015-11-08 15:54:22,024 INFO  [main] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-11-08 15:54:22,027 INFO  [main] http.HttpRequestLog: Http request log for http.requests.master is not defined
2015-11-08 15:54:22,036 INFO  [main] http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.hbase.http.HttpServer$QuotingInputFilter)
2015-11-08 15:54:22,039 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context master
2015-11-08 15:54:22,039 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-11-08 15:54:22,039 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-11-08 15:54:22,052 INFO  [main] http.HttpServer: Jetty bound to port 16010
2015-11-08 15:54:22,052 INFO  [main] mortbay.log: jetty-6.1.26
2015-11-08 15:54:22,327 INFO  [main] mortbay.log: Started SelectChannelConnector@0.0.0.0:16010
2015-11-08 15:54:22,330 INFO  [main] master.HMaster: hbase.rootdir=hdfs://192.168.1.101:9000/hbase, hbase.cluster.distributed=true
2015-11-08 15:54:22,341 INFO  [main] master.HMaster: Adding backup master ZNode /hbase/backup-masters/master,16000,1446969261106
2015-11-08 15:54:22,451 INFO  [master:16000.activeMasterManager] master.ActiveMasterManager: Deleting ZNode for /hbase/backup-masters/master,16000,1446969261106 from backup master directory
2015-11-08 15:54:22,461 INFO  [master:16000.activeMasterManager] master.ActiveMasterManager: Registered Active Master=master,16000,1446969261106
2015-11-08 15:54:22,507 INFO  [master/master/192.168.1.101:16000] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x2e9f560 connecting to ZooKeeper ensemble=localhost:2181
2015-11-08 15:54:22,508 INFO  [master/master/192.168.1.101:16000] zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=hconnection-0x2e9f5600x0, quorum=localhost:2181, baseZNode=/hbase
2015-11-08 15:54:22,510 INFO  [master/master/192.168.1.101:16000-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 15:54:22,510 INFO  [master/master/192.168.1.101:16000-SendThread(localhost:2181)] zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
2015-11-08 15:54:22,518 INFO  [master/master/192.168.1.101:16000-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x150e616b3060001, negotiated timeout = 90000
2015-11-08 15:54:22,519 INFO  [master/master/192.168.1.101:16000] client.ZooKeeperRegistry: ClusterId read in ZooKeeper is null
2015-11-08 15:54:23,816 INFO  [master:16000.activeMasterManager] util.FSUtils: Created version file at hdfs://192.168.1.101:9000/hbase with version=8
2015-11-08 15:54:24,019 INFO  [master:16000.activeMasterManager] master.MasterFileSystem: BOOTSTRAP: creating hbase:meta region
2015-11-08 15:54:24,021 INFO  [master:16000.activeMasterManager] regionserver.HRegion: creating HRegion hbase:meta HTD == 'hbase:meta', {TABLE_ATTRIBUTES => {IS_META => 'true', coprocessor$1 => '|org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint|536870911|'}, {NAME => 'info', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'NONE', REPLICATION_SCOPE => '0', COMPRESSION => 'NONE', VERSIONS => '10', TTL => 'FOREVER', MIN_VERSIONS => '0', KEEP_DELETED_CELLS => 'FALSE', BLOCKSIZE => '8192', IN_MEMORY => 'false', BLOCKCACHE => 'false'} RootDir = hdfs://192.168.1.101:9000/hbase Table name == hbase:meta
2015-11-08 15:54:24,121 INFO  [master:16000.activeMasterManager] wal.WALFactory: Instantiating WALProvider of type class org.apache.hadoop.hbase.wal.DefaultWALProvider
2015-11-08 15:54:24,166 INFO  [master:16000.activeMasterManager] wal.FSHLog: WAL configuration: blocksize=128 MB, rollsize=121.60 MB, prefix=hregion-18406537.default, suffix=, logDir=hdfs://192.168.1.101:9000/hbase/WALs/hregion-18406537, archiveDir=hdfs://192.168.1.101:9000/hbase/oldWALs
2015-11-08 15:54:24,245 INFO  [master:16000.activeMasterManager] wal.FSHLog: Slow sync cost: 57 ms, current pipeline: []
2015-11-08 15:54:24,247 INFO  [master:16000.activeMasterManager] wal.FSHLog: New WAL /hbase/WALs/hregion-18406537/hregion-18406537.default.1446969264166
2015-11-08 15:54:24,326 INFO  [StoreOpener-1588230740-1] hfile.CacheConfig: Allocating LruBlockCache size=743.50 MB, blockSize=64 KB
2015-11-08 15:54:24,336 INFO  [StoreOpener-1588230740-1] hfile.CacheConfig: blockCache=LruBlockCache{blockCount=0, currentSize=800720, freeSize=778815536, maxSize=779616256, heapSize=800720, minSize=740635456, minFactor=0.95, multiSize=370317728, multiFactor=0.5, singleSize=185158864, singleFactor=0.25}, cacheDataOnRead=false, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheDataCompressed=false, prefetchOnOpen=false
2015-11-08 15:54:24,344 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; major period 604800000, major jitter 0.500000, min locality to compact 0.000000
2015-11-08 15:54:24,409 INFO  [master:16000.activeMasterManager] regionserver.HRegion: Onlined 1588230740; next sequenceid=2
2015-11-08 15:54:24,411 INFO  [StoreCloserThread-hbase:meta,,1.1588230740-1] regionserver.HStore: Closed info
2015-11-08 15:54:24,412 INFO  [master:16000.activeMasterManager] regionserver.HRegion: Closed hbase:meta,,1.1588230740
2015-11-08 15:54:24,459 INFO  [master:16000.activeMasterManager] wal.FSHLog: Closed WAL: FSHLog hregion-18406537.default:(num 1446969264166)
2015-11-08 15:54:24,586 INFO  [master:16000.activeMasterManager] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2015-11-08 15:54:24,600 INFO  [master:16000.activeMasterManager] coordination.SplitLogManagerCoordination: Found 0 orphan tasks and 0 rescan nodes
2015-11-08 15:54:24,625 INFO  [master:16000.activeMasterManager] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x250daad connecting to ZooKeeper ensemble=localhost:2181
2015-11-08 15:54:24,626 INFO  [master:16000.activeMasterManager] zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=hconnection-0x250daad0x0, quorum=localhost:2181, baseZNode=/hbase
2015-11-08 15:54:24,628 INFO  [master:16000.activeMasterManager-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 15:54:24,629 INFO  [master:16000.activeMasterManager-SendThread(localhost:2181)] zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
2015-11-08 15:54:24,635 INFO  [master:16000.activeMasterManager-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x150e616b3060002, negotiated timeout = 90000
2015-11-08 15:54:24,655 INFO  [master:16000.activeMasterManager] balancer.StochasticLoadBalancer: loading config
2015-11-08 15:54:24,703 INFO  [master:16000.activeMasterManager] master.HMaster: Server active/primary master=master,16000,1446969261106, sessionid=0x150e616b3060000, setting cluster-up flag (Was=false)
2015-11-08 15:54:24,705 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: ClusterId : 18e4235c-98ec-4147-8ac4-00cf10508c80
2015-11-08 15:54:24,760 INFO  [master:16000.activeMasterManager] procedure.ZKProcedureUtil: Clearing all procedure znodes: /hbase/online-snapshot/acquired /hbase/online-snapshot/reached /hbase/online-snapshot/abort
2015-11-08 15:54:24,835 INFO  [master:16000.activeMasterManager] procedure.ZKProcedureUtil: Clearing all procedure znodes: /hbase/flush-table-proc/acquired /hbase/flush-table-proc/reached /hbase/flush-table-proc/abort
2015-11-08 15:54:24,868 INFO  [master:16000.activeMasterManager] master.MasterCoprocessorHost: System coprocessor loading is enabled
2015-11-08 15:54:24,881 INFO  [master:16000.activeMasterManager] procedure2.ProcedureExecutor: Starting procedure executor threads=5
2015-11-08 15:54:24,882 INFO  [master:16000.activeMasterManager] wal.WALProcedureStore: Starting WAL Procedure Store lease recovery
2015-11-08 15:54:24,884 WARN  [master:16000.activeMasterManager] wal.WALProcedureStore: Log directory not found: File hdfs://192.168.1.101:9000/hbase/MasterProcWALs does not exist.
2015-11-08 15:54:24,895 INFO  [master:16000.activeMasterManager] wal.WALProcedureStore: Lease acquired for flushLogId: 1
2015-11-08 15:54:24,900 INFO  [master:16000.activeMasterManager] zookeeper.RecoverableZooKeeper: Process identifier=replicationLogCleaner connecting to ZooKeeper ensemble=localhost:2181
2015-11-08 15:54:24,900 INFO  [master:16000.activeMasterManager] zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=replicationLogCleaner0x0, quorum=localhost:2181, baseZNode=/hbase
2015-11-08 15:54:24,902 INFO  [master:16000.activeMasterManager-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 15:54:24,902 INFO  [master:16000.activeMasterManager-SendThread(localhost:2181)] zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
2015-11-08 15:54:24,910 INFO  [master:16000.activeMasterManager-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x150e616b3060003, negotiated timeout = 90000
2015-11-08 15:54:24,942 INFO  [master:16000.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 0 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2015-11-08 15:54:25,129 INFO  [PriorityRpcServer.handler=1,queue=1,port=16000] master.ServerManager: Registering server=master,16020,1446968748212
2015-11-08 15:54:25,142 INFO  [master:16000.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 1, slept for 200 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2015-11-08 15:54:26,645 INFO  [master:16000.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 1, slept for 1703 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2015-11-08 15:54:28,148 INFO  [master:16000.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 1, slept for 3206 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2015-11-08 15:54:29,451 INFO  [master:16000.activeMasterManager] master.ServerManager: Finished waiting for region servers count to settle; checked in 1, slept for 4509 ms, expecting minimum of 1, maximum of 2147483647, master is running
2015-11-08 15:54:29,465 INFO  [master:16000.activeMasterManager] master.MasterFileSystem: Log folder hdfs://192.168.1.101:9000/hbase/WALs/master,16020,1446968748212 belongs to an existing region server
2015-11-08 15:54:30,287 INFO  [master:16000.activeMasterManager] zookeeper.MetaTableLocator: Deleting hbase:meta region location in ZooKeeper
2015-11-08 15:54:30,301 INFO  [master:16000.activeMasterManager] zookeeper.RecoverableZooKeeper: Node /hbase/meta-region-server already deleted, retry=false
2015-11-08 15:54:30,327 INFO  [master:16000.activeMasterManager] zookeeper.ZKTableStateManager: Moving table hbase:meta state from null to ENABLED
2015-11-08 15:54:30,352 INFO  [master:16000.activeMasterManager] master.AssignmentManager: Assigning hbase:meta,,1.1588230740 to master,16020,1446968748212
2015-11-08 15:54:30,353 INFO  [master:16000.activeMasterManager] master.RegionStates: Transition {1588230740 state=OFFLINE, ts=1446969270306, server=null} to {1588230740 state=PENDING_OPEN, ts=1446969270353, server=master,16020,1446968748212}
2015-11-08 15:54:30,444 INFO  [master:16000.activeMasterManager] master.ServerManager: AssignmentManager hasn't finished failover cleanup; waiting
2015-11-08 15:54:30,477 INFO  [AM.ZK.Worker-pool3-t1] master.RegionStates: Transition {1588230740 state=PENDING_OPEN, ts=1446969270353, server=master,16020,1446968748212} to {1588230740 state=OPENING, ts=1446969270477, server=master,16020,1446968748212}
2015-11-08 15:54:30,834 INFO  [AM.ZK.Worker-pool3-t2] master.RegionStates: Transition {1588230740 state=OPENING, ts=1446969270477, server=master,16020,1446968748212} to {1588230740 state=OPEN, ts=1446969270833, server=master,16020,1446968748212}
2015-11-08 15:54:30,835 INFO  [AM.ZK.Worker-pool3-t2] coordination.ZkOpenRegionCoordination: Handling OPENED of 1588230740 from master,16000,1446969261106; deleting unassigned node
2015-11-08 15:54:30,845 INFO  [master:16000.activeMasterManager] master.HMaster: hbase:meta with replicaId 0 assigned=1, rit=false, location=master,16020,1446968748212
2015-11-08 15:54:30,949 INFO  [master:16000.activeMasterManager] hbase.MetaMigrationConvertingToPB: hbase:meta doesn't have any entries to update.
2015-11-08 15:54:30,950 INFO  [master:16000.activeMasterManager] hbase.MetaMigrationConvertingToPB: META already up-to date with PB serialization
2015-11-08 15:54:30,976 INFO  [master:16000.activeMasterManager] master.AssignmentManager: Clean cluster startup. Assigning user regions
2015-11-08 15:54:30,978 INFO  [master:16000.activeMasterManager] master.AssignmentManager: Joined the cluster in 28ms, failover=false
2015-11-08 15:54:30,987 INFO  [master:16000.activeMasterManager] master.TableNamespaceManager: Namespace table not found. Creating...
2015-11-08 15:54:31,540 INFO  [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion: creating HRegion hbase:namespace HTD == 'hbase:namespace', {NAME => 'info', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', COMPRESSION => 'NONE', VERSIONS => '10', TTL => 'FOREVER', MIN_VERSIONS => '0', CACHE_DATA_IN_L1 => 'true', KEEP_DELETED_CELLS => 'FALSE', BLOCKSIZE => '8192', IN_MEMORY => 'true', BLOCKCACHE => 'true'} RootDir = hdfs://192.168.1.101:9000/hbase/.tmp Table name == hbase:namespace
2015-11-08 15:54:31,610 INFO  [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion: Closed hbase:namespace,,1446969270988.6f3d653b8b106cc2df931825f52d6dec.
2015-11-08 15:54:31,896 INFO  [ProcedureExecutorThread-0] hbase.MetaTableAccessor: Added 1
2015-11-08 15:54:32,038 INFO  [ProcedureExecutorThread-0] zookeeper.ZKTableStateManager: Moving table hbase:namespace state from null to ENABLING
2015-11-08 15:54:32,060 INFO  [ProcedureExecutorThread-0] master.AssignmentManager: Assigning 1 region(s) to master,16020,1446968748212
2015-11-08 15:54:32,078 INFO  [ProcedureExecutorThread-0] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=OFFLINE, ts=1446969272063, server=null} to {6f3d653b8b106cc2df931825f52d6dec state=PENDING_OPEN, ts=1446969272078, server=master,16020,1446968748212}
2015-11-08 15:54:32,132 INFO  [ProcedureExecutorThread-0] zookeeper.ZKTableStateManager: Moving table hbase:namespace state from ENABLING to ENABLED
2015-11-08 15:54:32,144 INFO  [AM.ZK.Worker-pool3-t5] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=PENDING_OPEN, ts=1446969272078, server=master,16020,1446968748212} to {6f3d653b8b106cc2df931825f52d6dec state=OPENING, ts=1446969272144, server=master,16020,1446968748212}
2015-11-08 15:54:32,278 INFO  [AM.ZK.Worker-pool3-t6] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=OPENING, ts=1446969272144, server=master,16020,1446968748212} to {6f3d653b8b106cc2df931825f52d6dec state=OPEN, ts=1446969272278, server=master,16020,1446968748212}
2015-11-08 15:54:32,510 INFO  [master:16000.activeMasterManager] master.HMaster: Master has completed initialization
2015-11-08 15:54:32,518 INFO  [master:16000.activeMasterManager] quotas.MasterQuotaManager: Quota support disabled
Sun Nov  8 15:54:53 CST 2015 Stopping hbase (via master)
2015-11-08 15:54:55,565 INFO  [B.defaultRpcServer.handler=1,queue=1,port=16000] master.MasterRpcServices: Client=hadoop/null shutdown
2015-11-08 15:54:55,565 INFO  [B.defaultRpcServer.handler=1,queue=1,port=16000] regionserver.HRegionServer: STOPPED: Cluster shutdown requested
2015-11-08 15:54:55,565 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: Stopping infoServer
2015-11-08 15:54:55,566 INFO  [master/master/192.168.1.101:16000] mortbay.log: Stopped SelectChannelConnector@0.0.0.0:16010
2015-11-08 15:54:55,601 INFO  [master,16000,1446969261106_splitLogManager__ChoreService_1] master.SplitLogManager$TimeoutMonitor: Chore: SplitLogManager Timeout Monitor was stopped
2015-11-08 15:54:55,667 INFO  [master/master/192.168.1.101:16000] procedure2.ProcedureExecutor: Stopping the procedure executor
2015-11-08 15:54:55,667 INFO  [master/master/192.168.1.101:16000] wal.WALProcedureStore: Stopping the WAL Procedure Store
2015-11-08 15:54:55,733 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: stopping server master,16000,1446969261106
2015-11-08 15:54:55,736 INFO  [master/master/192.168.1.101:16000] client.ConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x150e616b3060001
2015-11-08 15:54:55,750 INFO  [master/master/192.168.1.101:16000] zookeeper.ZooKeeper: Session: 0x150e616b3060001 closed
2015-11-08 15:54:55,750 INFO  [master/master/192.168.1.101:16000-EventThread] zookeeper.ClientCnxn: EventThread shut down
2015-11-08 15:54:55,855 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: stopping server master,16000,1446969261106; all regions closed.
2015-11-08 15:54:55,857 INFO  [master/master/192.168.1.101:16000] hbase.ChoreService: Chore service for: master,16000,1446969261106 had [[ScheduledChore: Name: master,16000,1446969261106-BalancerChore Period: 300000 Unit: MILLISECONDS], [ScheduledChore: Name: master,16000,1446969261106-ClusterStatusChore Period: 60000 Unit: MILLISECONDS], [ScheduledChore: Name: LogsCleaner Period: 60000 Unit: MILLISECONDS], [ScheduledChore: Name: CatalogJanitor-master:16000 Period: 300000 Unit: MILLISECONDS], [ScheduledChore: Name: HFileCleaner Period: 60000 Unit: MILLISECONDS]] on shutdown
2015-11-08 15:54:55,858 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down master,16020,1446968748212
2015-11-08 15:54:56,869 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down master,16020,1446968748212
2015-11-08 15:54:57,879 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down master,16020,1446968748212
2015-11-08 15:54:58,889 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down master,16020,1446968748212
2015-11-08 15:54:59,899 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down master,16020,1446968748212
2015-11-08 15:55:00,909 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down master,16020,1446968748212
2015-11-08 15:55:01,919 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down master,16020,1446968748212
2015-11-08 15:55:02,930 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down master,16020,1446968748212
2015-11-08 15:55:03,940 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down master,16020,1446968748212
2015-11-08 15:55:04,950 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down master,16020,1446968748212
2015-11-08 15:55:05,960 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down master,16020,1446968748212
2015-11-08 15:55:06,150 INFO  [main-EventThread] zookeeper.RegionServerTracker: RegionServer ephemeral node deleted, processing expiration [master,16020,1446968748212]
2015-11-08 15:55:06,151 INFO  [main-EventThread] master.ServerManager: Cluster shutdown set; master,16020,1446968748212 expired; onlineServers=0
2015-11-08 15:55:06,167 INFO  [master/master/192.168.1.101:16000] client.ConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x150e616b3060002
2015-11-08 15:55:06,175 INFO  [master/master/192.168.1.101:16000] zookeeper.ZooKeeper: Session: 0x150e616b3060002 closed
2015-11-08 15:55:06,175 INFO  [master:16000.activeMasterManager-EventThread] zookeeper.ClientCnxn: EventThread shut down
2015-11-08 15:55:06,275 INFO  [master/master/192.168.1.101:16000] hbase.ChoreService: Chore service for: master,16000,1446969261106_splitLogManager_ had [] on shutdown
2015-11-08 15:55:06,276 INFO  [master/master/192.168.1.101:16000] flush.MasterFlushTableProcedureManager: stop: server shutting down.
2015-11-08 15:55:06,276 INFO  [master/master/192.168.1.101:16000] ipc.RpcServer: Stopping server on 16000
2015-11-08 15:55:06,276 INFO  [RpcServer.listener,port=16000] ipc.RpcServer: RpcServer.listener,port=16000: stopping
2015-11-08 15:55:06,277 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopped
2015-11-08 15:55:06,277 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopping
2015-11-08 15:55:06,300 INFO  [master/master/192.168.1.101:16000] zookeeper.RecoverableZooKeeper: Node /hbase/rs/master,16000,1446969261106 already deleted, retry=false
2015-11-08 15:55:06,308 INFO  [master/master/192.168.1.101:16000] zookeeper.ZooKeeper: Session: 0x150e616b3060000 closed
2015-11-08 15:55:06,308 INFO  [main-EventThread] zookeeper.ClientCnxn: EventThread shut down
2015-11-08 15:55:06,308 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: stopping server master,16000,1446969261106; zookeeper connection closed.
2015-11-08 15:55:06,308 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: master/master/192.168.1.101:16000 exiting
Sun Nov  8 15:55:24 CST 2015 Starting master on master
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 30141
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 10240
cpu time               (seconds, -t) unlimited
max user processes              (-u) 1024
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2015-11-08 15:55:25,542 INFO  [main] util.VersionInfo: HBase 1.1.2
2015-11-08 15:55:25,542 INFO  [main] util.VersionInfo: Source code repository git://hw11397.local/Volumes/hbase-1.1.2RC2/hbase revision=cc2b70cf03e3378800661ec5cab11eb43fafe0fc
2015-11-08 15:55:25,542 INFO  [main] util.VersionInfo: Compiled by ndimiduk on Wed Aug 26 20:11:27 PDT 2015
2015-11-08 15:55:25,542 INFO  [main] util.VersionInfo: From source with checksum 73da41f3d1b867b7aba6166c77fafc17
2015-11-08 15:55:25,949 INFO  [main] util.ServerCommandLine: env:TERM=xterm
2015-11-08 15:55:25,949 INFO  [main] util.ServerCommandLine: env:HADOOP_COMMON_LIB_NATIVE_DIR=/opt/hadoop/lib/native
2015-11-08 15:55:25,949 INFO  [main] util.ServerCommandLine: env:IMSETTINGS_MODULE=none
2015-11-08 15:55:25,949 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/opt/java
2015-11-08 15:55:25,949 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/opt/hbase/bin/..
2015-11-08 15:55:25,949 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2015-11-08 15:55:25,949 INFO  [main] util.ServerCommandLine: env:SESSION_MANAGER=local/unix:@/tmp/.ICE-unix/2995,unix/unix:/tmp/.ICE-unix/2995
2015-11-08 15:55:25,949 INFO  [main] util.ServerCommandLine: env:IMSETTINGS_INTEGRATE_DESKTOP=yes
2015-11-08 15:55:25,949 INFO  [main] util.ServerCommandLine: env:GNOME_DESKTOP_SESSION_ID=this-is-deprecated
2015-11-08 15:55:25,949 INFO  [main] util.ServerCommandLine: env:MAIL=/var/spool/mail/hadoop
2015-11-08 15:55:25,950 INFO  [main] util.ServerCommandLine: env:XDG_SESSION_COOKIE=ab8c9d4f5491283c7c300d7800000013-1446958848.52338-1725977001
2015-11-08 15:55:25,950 INFO  [main] util.ServerCommandLine: env:GDMSESSION=gnome
2015-11-08 15:55:25,950 INFO  [main] util.ServerCommandLine: env:HOSTNAME=master
2015-11-08 15:55:25,950 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/tmp/hbase-hadoop-master.znode
2015-11-08 15:55:25,950 INFO  [main] util.ServerCommandLine: env:PWD=/opt/hbase/bin
2015-11-08 15:55:25,950 INFO  [main] util.ServerCommandLine: env:HBASE_MASTER_OPTS= -XX:PermSize=128m -XX:MaxPermSize=128m
2015-11-08 15:55:25,950 INFO  [main] util.ServerCommandLine: env:CVS_RSH=ssh
2015-11-08 15:55:25,950 INFO  [main] util.ServerCommandLine: env:JAVA_LIBRARY_PATH=/opt/hadoop/lib/native::/opt/hadoop/lib/native:
2015-11-08 15:55:25,950 INFO  [main] util.ServerCommandLine: env:G_BROKEN_FILENAMES=1
2015-11-08 15:55:25,950 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2015-11-08 15:55:25,950 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2015-11-08 15:55:25,950 INFO  [main] util.ServerCommandLine: env:NLSPATH=/usr/dt/lib/nls/msg/%L/%N.cat
2015-11-08 15:55:25,950 INFO  [main] util.ServerCommandLine: env:GNOME_KEYRING_SOCKET=/tmp/keyring-IruJ62/socket
2015-11-08 15:55:25,950 INFO  [main] util.ServerCommandLine: env:GDM_KEYBOARD_LAYOUT=us
2015-11-08 15:55:25,950 INFO  [main] util.ServerCommandLine: env:HBASE_REGIONSERVER_OPTS= -XX:PermSize=128m -XX:MaxPermSize=128m
2015-11-08 15:55:25,950 INFO  [main] util.ServerCommandLine: env:HISTSIZE=1000
2015-11-08 15:55:25,950 INFO  [main] util.ServerCommandLine: env:PATH=/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin:/sbin:/opt/java//bin:/opt/java/jre/bin:/opt/hadoop/bin:/home/hadoop/bin
2015-11-08 15:55:25,950 INFO  [main] util.ServerCommandLine: env:QTLIB=/usr/lib64/qt-3.3/lib
2015-11-08 15:55:25,951 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2015-11-08 15:55:25,951 INFO  [main] util.ServerCommandLine: env:GDM_LANG=en_US.UTF-8
2015-11-08 15:55:25,951 INFO  [main] util.ServerCommandLine: env:XAUTHORITY=/var/run/gdm/auth-for-hadoop-akmkFp/database
2015-11-08 15:55:25,951 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/tmp/hbase-hadoop-master.autorestart
2015-11-08 15:55:25,951 INFO  [main] util.ServerCommandLine: env:USERNAME=hadoop
2015-11-08 15:55:25,951 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-hadoop-master-master.log
2015-11-08 15:55:25,951 INFO  [main] util.ServerCommandLine: env:SSH_ASKPASS=/usr/libexec/openssh/gnome-ssh-askpass
2015-11-08 15:55:25,951 INFO  [main] util.ServerCommandLine: env:SHLVL=5
2015-11-08 15:55:25,951 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/opt/hbase/bin/../logs
2015-11-08 15:55:25,951 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-XX:+UseConcMarkSweepGC   -XX:PermSize=128m -XX:MaxPermSize=128m -Dhbase.log.dir=/opt/hbase/bin/../logs -Dhbase.log.file=hbase-hadoop-master-master.log -Dhbase.home.dir=/opt/hbase/bin/.. -Dhbase.id.str=hadoop -Dhbase.root.logger=INFO,RFA -Djava.library.path=/opt/hadoop/lib/native::/opt/hadoop/lib/native: -Dhbase.security.logger=INFO,RFAS
2015-11-08 15:55:25,951 INFO  [main] util.ServerCommandLine: env:XFILESEARCHPATH=/usr/dt/app-defaults/%L/Dt
2015-11-08 15:55:25,951 INFO  [main] util.ServerCommandLine: env:COLORTERM=gnome-terminal
2015-11-08 15:55:25,951 INFO  [main] util.ServerCommandLine: env:QT_IM_MODULE=xim
2015-11-08 15:55:25,951 INFO  [main] util.ServerCommandLine: env:WINDOWID=20979824
2015-11-08 15:55:25,951 INFO  [main] util.ServerCommandLine: env:LOGNAME=hadoop
2015-11-08 15:55:25,951 INFO  [main] util.ServerCommandLine: env:QTDIR=/usr/lib64/qt-3.3
2015-11-08 15:55:25,952 INFO  [main] util.ServerCommandLine: env:XMODIFIERS=@im=none
2015-11-08 15:55:25,952 INFO  [main] util.ServerCommandLine: env:SSH_AUTH_SOCK=/tmp/keyring-IruJ62/socket.ssh
2015-11-08 15:55:25,952 INFO  [main] util.ServerCommandLine: env:HADOOP_HOME=/opt/hadoop
2015-11-08 15:55:25,952 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=:/opt/hadoop/lib/native::/opt/hadoop/lib/native:
2015-11-08 15:55:25,952 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2015-11-08 15:55:25,952 INFO  [main] util.ServerCommandLine: env:HADOOP_OPTS=-Djava.library.path=/opt/hadoop/lib/native
2015-11-08 15:55:25,952 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2015-11-08 15:55:25,952 INFO  [main] util.ServerCommandLine: env:DBUS_SESSION_BUS_ADDRESS=unix:abstract=/tmp/dbus-uqNe1cANDo,guid=eca351d0636069d92d6d2f1900000495
2015-11-08 15:55:25,952 INFO  [main] util.ServerCommandLine: env:GNOME_KEYRING_PID=2985
2015-11-08 15:55:25,952 INFO  [main] util.ServerCommandLine: env:GTK_RC_FILES=/etc/gtk/gtkrc:/home/hadoop/.gtkrc-1.2-gnome2
2015-11-08 15:55:25,952 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2015-11-08 15:55:25,953 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/opt/hbase/bin/../conf:/opt/java/lib/tools.jar:/opt/hbase/bin/..:/opt/hbase/bin/../lib/activation-1.1.jar:/opt/hbase/bin/../lib/aopalliance-1.0.jar:/opt/hbase/bin/../lib/apacheds-i18n-2.0.0-M15.jar:/opt/hbase/bin/../lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hbase/bin/../lib/api-asn1-api-1.0.0-M20.jar:/opt/hbase/bin/../lib/api-util-1.0.0-M20.jar:/opt/hbase/bin/../lib/asm-3.1.jar:/opt/hbase/bin/../lib/avro-1.7.4.jar:/opt/hbase/bin/../lib/commons-beanutils-1.7.0.jar:/opt/hbase/bin/../lib/commons-beanutils-core-1.8.0.jar:/opt/hbase/bin/../lib/commons-cli-1.2.jar:/opt/hbase/bin/../lib/commons-codec-1.9.jar:/opt/hbase/bin/../lib/commons-collections-3.2.1.jar:/opt/hbase/bin/../lib/commons-compress-1.4.1.jar:/opt/hbase/bin/../lib/commons-configuration-1.6.jar:/opt/hbase/bin/../lib/commons-daemon-1.0.13.jar:/opt/hbase/bin/../lib/commons-digester-1.8.jar:/opt/hbase/bin/../lib/commons-el-1.0.jar:/opt/hbase/bin/../lib/commons-httpclient-3.1.jar:/opt/hbase/bin/../lib/commons-io-2.4.jar:/opt/hbase/bin/../lib/commons-lang-2.6.jar:/opt/hbase/bin/../lib/commons-logging-1.2.jar:/opt/hbase/bin/../lib/commons-math-2.2.jar:/opt/hbase/bin/../lib/commons-math3-3.1.1.jar:/opt/hbase/bin/../lib/commons-net-3.1.jar:/opt/hbase/bin/../lib/disruptor-3.3.0.jar:/opt/hbase/bin/../lib/findbugs-annotations-1.3.9-1.jar:/opt/hbase/bin/../lib/guava-12.0.1.jar:/opt/hbase/bin/../lib/guice-3.0.jar:/opt/hbase/bin/../lib/guice-servlet-3.0.jar:/opt/hbase/bin/../lib/hadoop-annotations-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-auth-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-client-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-common-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-hdfs-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-app-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-common-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-core-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-jobclient-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-shuffle-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-api-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-client-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-common-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-server-common-2.5.1.jar:/opt/hbase/bin/../lib/hbase-annotations-1.1.2.jar:/opt/hbase/bin/../lib/hbase-annotations-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-client-1.1.2.jar:/opt/hbase/bin/../lib/hbase-common-1.1.2.jar:/opt/hbase/bin/../lib/hbase-common-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-examples-1.1.2.jar:/opt/hbase/bin/../lib/hbase-hadoop2-compat-1.1.2.jar:/opt/hbase/bin/../lib/hbase-hadoop-compat-1.1.2.jar:/opt/hbase/bin/../lib/hbase-it-1.1.2.jar:/opt/hbase/bin/../lib/hbase-it-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-prefix-tree-1.1.2.jar:/opt/hbase/bin/../lib/hbase-procedure-1.1.2.jar:/opt/hbase/bin/../lib/hbase-protocol-1.1.2.jar:/opt/hbase/bin/../lib/hbase-resource-bundle-1.1.2.jar:/opt/hbase/bin/../lib/hbase-rest-1.1.2.jar:/opt/hbase/bin/../lib/hbase-server-1.1.2.jar:/opt/hbase/bin/../lib/hbase-server-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-shell-1.1.2.jar:/opt/hbase/bin/../lib/hbase-thrift-1.1.2.jar:/opt/hbase/bin/../lib/htrace-core-3.1.0-incubating.jar:/opt/hbase/bin/../lib/httpclient-4.2.5.jar:/opt/hbase/bin/../lib/httpcore-4.1.3.jar:/opt/hbase/bin/../lib/jackson-core-asl-1.9.13.jar:/opt/hbase/bin/../lib/jackson-jaxrs-1.9.13.jar:/opt/hbase/bin/../lib/jackson-mapper-asl-1.9.13.jar:/opt/hbase/bin/../lib/jackson-xc-1.9.13.jar:/opt/hbase/bin/../lib/jamon-runtime-2.3.1.jar:/opt/hbase/bin/../lib/jasper-compiler-5.5.23.jar:/opt/hbase/bin/../lib/jasper-runtime-5.5.23.jar:/opt/hbase/bin/../lib/javax.inject-1.jar:/opt/hbase/bin/../lib/java-xmlbuilder-0.4.jar:/opt/hbase/bin/../lib/jaxb-api-2.2.2.jar:/opt/hbase/bin/../lib/jaxb-impl-2.2.3-1.jar:/opt/hbase/bin/../lib/jcodings-1.0.8.jar:/opt/hbase/bin/../lib/jersey-client-1.9.jar:/opt/hbase/bin/../lib/jersey-core-1.9.jar:/opt/hbase/bin/../lib/jersey-guice-1.9.jar:/opt/hbase/bin/../lib/jersey-json-1.9.jar:/opt/hbase/bin/../lib/jersey-server-1.9.jar:/opt/hbase/bin/../lib/jets3t-0.9.0.jar:/opt/hbase/bin/../lib/jettison-1.3.3.jar:/opt/hbase/bin/../lib/jetty-6.1.26.jar:/opt/hbase/bin/../lib/jetty-sslengine-6.1.26.jar:/opt/hbase/bin/../lib/jetty-util-6.1.26.jar:/opt/hbase/bin/../lib/joni-2.1.2.jar:/opt/hbase/bin/../lib/jruby-complete-1.6.8.jar:/opt/hbase/bin/../lib/jsch-0.1.42.jar:/opt/hbase/bin/../lib/jsp-2.1-6.1.14.jar:/opt/hbase/bin/../lib/jsp-api-2.1-6.1.14.jar:/opt/hbase/bin/../lib/jsr305-1.3.9.jar:/opt/hbase/bin/../lib/junit-4.11.jar:/opt/hbase/bin/../lib/leveldbjni-all-1.8.jar:/opt/hbase/bin/../lib/libthrift-0.9.0.jar:/opt/hbase/bin/../lib/log4j-1.2.17.jar:/opt/hbase/bin/../lib/metrics-core-2.2.0.jar:/opt/hbase/bin/../lib/netty-3.2.4.Final.jar:/opt/hbase/bin/../lib/netty-all-4.0.23.Final.jar:/opt/hbase/bin/../lib/paranamer-2.3.jar:/opt/hbase/bin/../lib/protobuf-java-2.5.0.jar:/opt/hbase/bin/../lib/servlet-api-2.5-6.1.14.jar:/opt/hbase/bin/../lib/servlet-api-2.5.jar:/opt/hbase/bin/../lib/slf4j-api-1.7.7.jar:/opt/hbase/bin/../lib/slf4j-log4j12-1.7.5.jar:/opt/hbase/bin/../lib/snappy-java-1.0.4.1.jar:/opt/hbase/bin/../lib/spymemcached-2.11.6.jar:/opt/hbase/bin/../lib/xmlenc-0.52.jar:/opt/hbase/bin/../lib/xz-1.0.jar:/opt/hbase/bin/../lib/zookeeper-3.4.6.jar:/opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/contrib/capacity-scheduler/*.jar
2015-11-08 15:55:25,953 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2015-11-08 15:55:25,953 INFO  [main] util.ServerCommandLine: env:JRE_HOME=/opt/java/jre
2015-11-08 15:55:25,954 INFO  [main] util.ServerCommandLine: env:DESKTOP_SESSION=gnome
2015-11-08 15:55:25,954 INFO  [main] util.ServerCommandLine: env:QTINC=/usr/lib64/qt-3.3/include
2015-11-08 15:55:25,954 INFO  [main] util.ServerCommandLine: env:DISPLAY=192.168.1.100:2.0
2015-11-08 15:55:25,954 INFO  [main] util.ServerCommandLine: env:USER=hadoop
2015-11-08 15:55:25,954 INFO  [main] util.ServerCommandLine: env:HISTCONTROL=ignoredups
2015-11-08 15:55:25,954 INFO  [main] util.ServerCommandLine: env:HOME=/home/hadoop
2015-11-08 15:55:25,954 INFO  [main] util.ServerCommandLine: env:LESSOPEN=||/usr/bin/lesspipe.sh %s
2015-11-08 15:55:25,954 INFO  [main] util.ServerCommandLine: env:LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arj=01;31:*.taz=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lz=01;31:*.xz=01;31:*.bz2=01;31:*.tbz=01;31:*.tbz2=01;31:*.bz=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.rar=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
2015-11-08 15:55:25,954 INFO  [main] util.ServerCommandLine: env:ORBIT_SOCKETDIR=/tmp/orbit-hadoop
2015-11-08 15:55:25,954 INFO  [main] util.ServerCommandLine: env:LANG=en_US.UTF-8
2015-11-08 15:55:25,954 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-hadoop-master-master
2015-11-08 15:55:25,954 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=hadoop
2015-11-08 15:55:25,956 INFO  [main] util.ServerCommandLine: vmName=Java HotSpot(TM) 64-Bit Server VM, vmVendor=Oracle Corporation, vmVersion=24.79-b02
2015-11-08 15:55:25,957 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_master, -XX:OnOutOfMemoryError=kill -9 %p, -XX:+UseConcMarkSweepGC, -XX:PermSize=128m, -XX:MaxPermSize=128m, -Dhbase.log.dir=/opt/hbase/bin/../logs, -Dhbase.log.file=hbase-hadoop-master-master.log, -Dhbase.home.dir=/opt/hbase/bin/.., -Dhbase.id.str=hadoop, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=/opt/hadoop/lib/native::/opt/hadoop/lib/native:, -Dhbase.security.logger=INFO,RFAS]
2015-11-08 15:55:26,392 WARN  [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-11-08 15:55:26,634 INFO  [main] regionserver.RSRpcServices: master/master/192.168.1.101:16000 server-side HConnection retries=350
2015-11-08 15:55:26,893 INFO  [main] ipc.SimpleRpcScheduler: Using deadline as user call queue, count=3
2015-11-08 15:55:26,919 INFO  [main] ipc.RpcServer: master/master/192.168.1.101:16000: started 10 reader(s).
2015-11-08 15:55:26,993 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2015-11-08 15:55:27,075 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-11-08 15:55:27,075 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2015-11-08 15:55:27,957 INFO  [main] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2015-11-08 15:55:28,187 INFO  [main] zookeeper.RecoverableZooKeeper: Process identifier=master:16000 connecting to ZooKeeper ensemble=localhost:2181
2015-11-08 15:55:28,193 INFO  [main] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2015-11-08 15:55:28,193 INFO  [main] zookeeper.ZooKeeper: Client environment:host.name=master
2015-11-08 15:55:28,193 INFO  [main] zookeeper.ZooKeeper: Client environment:java.version=1.7.0_79
2015-11-08 15:55:28,193 INFO  [main] zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
2015-11-08 15:55:28,193 INFO  [main] zookeeper.ZooKeeper: Client environment:java.home=/opt/java/jre
2015-11-08 15:55:28,193 INFO  [main] zookeeper.ZooKeeper: Client environment:java.class.path=/opt/hbase/bin/../conf:/opt/java/lib/tools.jar:/opt/hbase/bin/..:/opt/hbase/bin/../lib/activation-1.1.jar:/opt/hbase/bin/../lib/aopalliance-1.0.jar:/opt/hbase/bin/../lib/apacheds-i18n-2.0.0-M15.jar:/opt/hbase/bin/../lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hbase/bin/../lib/api-asn1-api-1.0.0-M20.jar:/opt/hbase/bin/../lib/api-util-1.0.0-M20.jar:/opt/hbase/bin/../lib/asm-3.1.jar:/opt/hbase/bin/../lib/avro-1.7.4.jar:/opt/hbase/bin/../lib/commons-beanutils-1.7.0.jar:/opt/hbase/bin/../lib/commons-beanutils-core-1.8.0.jar:/opt/hbase/bin/../lib/commons-cli-1.2.jar:/opt/hbase/bin/../lib/commons-codec-1.9.jar:/opt/hbase/bin/../lib/commons-collections-3.2.1.jar:/opt/hbase/bin/../lib/commons-compress-1.4.1.jar:/opt/hbase/bin/../lib/commons-configuration-1.6.jar:/opt/hbase/bin/../lib/commons-daemon-1.0.13.jar:/opt/hbase/bin/../lib/commons-digester-1.8.jar:/opt/hbase/bin/../lib/commons-el-1.0.jar:/opt/hbase/bin/../lib/commons-httpclient-3.1.jar:/opt/hbase/bin/../lib/commons-io-2.4.jar:/opt/hbase/bin/../lib/commons-lang-2.6.jar:/opt/hbase/bin/../lib/commons-logging-1.2.jar:/opt/hbase/bin/../lib/commons-math-2.2.jar:/opt/hbase/bin/../lib/commons-math3-3.1.1.jar:/opt/hbase/bin/../lib/commons-net-3.1.jar:/opt/hbase/bin/../lib/disruptor-3.3.0.jar:/opt/hbase/bin/../lib/findbugs-annotations-1.3.9-1.jar:/opt/hbase/bin/../lib/guava-12.0.1.jar:/opt/hbase/bin/../lib/guice-3.0.jar:/opt/hbase/bin/../lib/guice-servlet-3.0.jar:/opt/hbase/bin/../lib/hadoop-annotations-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-auth-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-client-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-common-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-hdfs-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-app-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-common-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-core-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-jobclient-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-shuffle-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-api-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-client-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-common-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-server-common-2.5.1.jar:/opt/hbase/bin/../lib/hbase-annotations-1.1.2.jar:/opt/hbase/bin/../lib/hbase-annotations-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-client-1.1.2.jar:/opt/hbase/bin/../lib/hbase-common-1.1.2.jar:/opt/hbase/bin/../lib/hbase-common-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-examples-1.1.2.jar:/opt/hbase/bin/../lib/hbase-hadoop2-compat-1.1.2.jar:/opt/hbase/bin/../lib/hbase-hadoop-compat-1.1.2.jar:/opt/hbase/bin/../lib/hbase-it-1.1.2.jar:/opt/hbase/bin/../lib/hbase-it-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-prefix-tree-1.1.2.jar:/opt/hbase/bin/../lib/hbase-procedure-1.1.2.jar:/opt/hbase/bin/../lib/hbase-protocol-1.1.2.jar:/opt/hbase/bin/../lib/hbase-resource-bundle-1.1.2.jar:/opt/hbase/bin/../lib/hbase-rest-1.1.2.jar:/opt/hbase/bin/../lib/hbase-server-1.1.2.jar:/opt/hbase/bin/../lib/hbase-server-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-shell-1.1.2.jar:/opt/hbase/bin/../lib/hbase-thrift-1.1.2.jar:/opt/hbase/bin/../lib/htrace-core-3.1.0-incubating.jar:/opt/hbase/bin/../lib/httpclient-4.2.5.jar:/opt/hbase/bin/../lib/httpcore-4.1.3.jar:/opt/hbase/bin/../lib/jackson-core-asl-1.9.13.jar:/opt/hbase/bin/../lib/jackson-jaxrs-1.9.13.jar:/opt/hbase/bin/../lib/jackson-mapper-asl-1.9.13.jar:/opt/hbase/bin/../lib/jackson-xc-1.9.13.jar:/opt/hbase/bin/../lib/jamon-runtime-2.3.1.jar:/opt/hbase/bin/../lib/jasper-compiler-5.5.23.jar:/opt/hbase/bin/../lib/jasper-runtime-5.5.23.jar:/opt/hbase/bin/../lib/javax.inject-1.jar:/opt/hbase/bin/../lib/java-xmlbuilder-0.4.jar:/opt/hbase/bin/../lib/jaxb-api-2.2.2.jar:/opt/hbase/bin/../lib/jaxb-impl-2.2.3-1.jar:/opt/hbase/bin/../lib/jcodings-1.0.8.jar:/opt/hbase/bin/../lib/jersey-client-1.9.jar:/opt/hbase/bin/../lib/jersey-core-1.9.jar:/opt/hbase/bin/../lib/jersey-guice-1.9.jar:/opt/hbase/bin/../lib/jersey-json-1.9.jar:/opt/hbase/bin/../lib/jersey-server-1.9.jar:/opt/hbase/bin/../lib/jets3t-0.9.0.jar:/opt/hbase/bin/../lib/jettison-1.3.3.jar:/opt/hbase/bin/../lib/jetty-6.1.26.jar:/opt/hbase/bin/../lib/jetty-sslengine-6.1.26.jar:/opt/hbase/bin/../lib/jetty-util-6.1.26.jar:/opt/hbase/bin/../lib/joni-2.1.2.jar:/opt/hbase/bin/../lib/jruby-complete-1.6.8.jar:/opt/hbase/bin/../lib/jsch-0.1.42.jar:/opt/hbase/bin/../lib/jsp-2.1-6.1.14.jar:/opt/hbase/bin/../lib/jsp-api-2.1-6.1.14.jar:/opt/hbase/bin/../lib/jsr305-1.3.9.jar:/opt/hbase/bin/../lib/junit-4.11.jar:/opt/hbase/bin/../lib/leveldbjni-all-1.8.jar:/opt/hbase/bin/../lib/libthrift-0.9.0.jar:/opt/hbase/bin/../lib/log4j-1.2.17.jar:/opt/hbase/bin/../lib/metrics-core-2.2.0.jar:/opt/hbase/bin/../lib/netty-3.2.4.Final.jar:/opt/hbase/bin/../lib/netty-all-4.0.23.Final.jar:/opt/hbase/bin/../lib/paranamer-2.3.jar:/opt/hbase/bin/../lib/protobuf-java-2.5.0.jar:/opt/hbase/bin/../lib/servlet-api-2.5-6.1.14.jar:/opt/hbase/bin/../lib/servlet-api-2.5.jar:/opt/hbase/bin/../lib/slf4j-api-1.7.7.jar:/opt/hbase/bin/../lib/slf4j-log4j12-1.7.5.jar:/opt/hbase/bin/../lib/snappy-java-1.0.4.1.jar:/opt/hbase/bin/../lib/spymemcached-2.11.6.jar:/opt/hbase/bin/../lib/xmlenc-0.52.jar:/opt/hbase/bin/../lib/xz-1.0.jar:/opt/hbase/bin/../lib/zookeeper-3.4.6.jar:/opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-auth-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/opt/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/opt/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop/share/hadoop/common/lib/curator-framework-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/opt/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/opt/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop/share/hadoop/common/lib/curator-client-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/opt/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-annotations-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/opt/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop/share/hadoop/common/lib/htrace-core-3.0.4.jar:/opt/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop/share/hadoop/common/hadoop-common-2.6.0-tests.jar:/opt/hadoop/share/hadoop/common/hadoop-common-2.6.0.jar:/opt/hadoop/share/hadoop/common/hadoop-nfs-2.6.0.jar:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/opt/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.0-tests.jar:/opt/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jline-0.9.94.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-tests.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar
2015-11-08 15:55:28,202 INFO  [main] zookeeper.ZooKeeper: Client environment:java.library.path=/opt/hadoop/lib/native::/opt/hadoop/lib/native:
2015-11-08 15:55:28,202 INFO  [main] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2015-11-08 15:55:28,202 INFO  [main] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2015-11-08 15:55:28,202 INFO  [main] zookeeper.ZooKeeper: Client environment:os.name=Linux
2015-11-08 15:55:28,202 INFO  [main] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2015-11-08 15:55:28,202 INFO  [main] zookeeper.ZooKeeper: Client environment:os.version=2.6.32-573.el6.x86_64
2015-11-08 15:55:28,202 INFO  [main] zookeeper.ZooKeeper: Client environment:user.name=hadoop
2015-11-08 15:55:28,202 INFO  [main] zookeeper.ZooKeeper: Client environment:user.home=/home/hadoop
2015-11-08 15:55:28,202 INFO  [main] zookeeper.ZooKeeper: Client environment:user.dir=/opt/hbase/bin
2015-11-08 15:55:28,203 INFO  [main] zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=master:160000x0, quorum=localhost:2181, baseZNode=/hbase
2015-11-08 15:55:28,225 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 15:55:28,228 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
2015-11-08 15:55:28,286 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x150e617b3fa0000, negotiated timeout = 90000
2015-11-08 15:55:28,353 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2015-11-08 15:55:28,363 INFO  [RpcServer.listener,port=16000] ipc.RpcServer: RpcServer.listener,port=16000: starting
2015-11-08 15:55:28,659 INFO  [main] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-11-08 15:55:28,665 INFO  [main] http.HttpRequestLog: Http request log for http.requests.master is not defined
2015-11-08 15:55:28,681 INFO  [main] http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.hbase.http.HttpServer$QuotingInputFilter)
2015-11-08 15:55:28,684 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context master
2015-11-08 15:55:28,684 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-11-08 15:55:28,684 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-11-08 15:55:28,708 INFO  [main] http.HttpServer: Jetty bound to port 16010
2015-11-08 15:55:28,709 INFO  [main] mortbay.log: jetty-6.1.26
2015-11-08 15:55:29,222 INFO  [main] mortbay.log: Started SelectChannelConnector@0.0.0.0:16010
2015-11-08 15:55:29,228 INFO  [main] master.HMaster: hbase.rootdir=hdfs://192.168.1.101:9000/hbase, hbase.cluster.distributed=true
2015-11-08 15:55:29,251 INFO  [main] master.HMaster: Adding backup master ZNode /hbase/backup-masters/master,16000,1446969327099
2015-11-08 15:55:29,397 INFO  [master:16000.activeMasterManager] master.ActiveMasterManager: Deleting ZNode for /hbase/backup-masters/master,16000,1446969327099 from backup master directory
2015-11-08 15:55:29,406 INFO  [master:16000.activeMasterManager] master.ActiveMasterManager: Registered Active Master=master,16000,1446969327099
2015-11-08 15:55:29,533 INFO  [master/master/192.168.1.101:16000] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x63a9de47 connecting to ZooKeeper ensemble=localhost:2181
2015-11-08 15:55:29,533 INFO  [master/master/192.168.1.101:16000] zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=hconnection-0x63a9de470x0, quorum=localhost:2181, baseZNode=/hbase
2015-11-08 15:55:29,540 INFO  [master/master/192.168.1.101:16000-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 15:55:29,540 INFO  [master/master/192.168.1.101:16000-SendThread(localhost:2181)] zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
2015-11-08 15:55:29,555 INFO  [master/master/192.168.1.101:16000-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x150e617b3fa0002, negotiated timeout = 90000
2015-11-08 15:55:29,861 INFO  [master:16000.activeMasterManager] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2015-11-08 15:55:29,873 INFO  [master:16000.activeMasterManager] coordination.SplitLogManagerCoordination: Found 0 orphan tasks and 0 rescan nodes
2015-11-08 15:55:29,920 INFO  [master:16000.activeMasterManager] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x31d5b955 connecting to ZooKeeper ensemble=localhost:2181
2015-11-08 15:55:29,920 INFO  [master:16000.activeMasterManager] zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=hconnection-0x31d5b9550x0, quorum=localhost:2181, baseZNode=/hbase
2015-11-08 15:55:29,923 INFO  [master:16000.activeMasterManager-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 15:55:29,924 INFO  [master:16000.activeMasterManager-SendThread(localhost:2181)] zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
2015-11-08 15:55:29,935 INFO  [master:16000.activeMasterManager-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x150e617b3fa0003, negotiated timeout = 90000
2015-11-08 15:55:29,951 INFO  [master:16000.activeMasterManager] balancer.StochasticLoadBalancer: loading config
2015-11-08 15:55:30,014 INFO  [master:16000.activeMasterManager] master.HMaster: Server active/primary master=master,16000,1446969327099, sessionid=0x150e617b3fa0000, setting cluster-up flag (Was=false)
2015-11-08 15:55:30,015 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: ClusterId : 18e4235c-98ec-4147-8ac4-00cf10508c80
2015-11-08 15:55:30,039 INFO  [master:16000.activeMasterManager] procedure.ZKProcedureUtil: Clearing all procedure znodes: /hbase/online-snapshot/acquired /hbase/online-snapshot/reached /hbase/online-snapshot/abort
2015-11-08 15:55:30,064 INFO  [master:16000.activeMasterManager] procedure.ZKProcedureUtil: Clearing all procedure znodes: /hbase/flush-table-proc/acquired /hbase/flush-table-proc/reached /hbase/flush-table-proc/abort
2015-11-08 15:55:30,125 INFO  [master:16000.activeMasterManager] master.MasterCoprocessorHost: System coprocessor loading is enabled
2015-11-08 15:55:30,143 INFO  [master:16000.activeMasterManager] procedure2.ProcedureExecutor: Starting procedure executor threads=5
2015-11-08 15:55:30,144 INFO  [master:16000.activeMasterManager] wal.WALProcedureStore: Starting WAL Procedure Store lease recovery
2015-11-08 15:55:30,148 INFO  [master:16000.activeMasterManager] util.FSHDFSUtils: Recovering lease on dfs file hdfs://192.168.1.101:9000/hbase/MasterProcWALs/state-00000000000000000001.log
2015-11-08 15:55:30,159 INFO  [master:16000.activeMasterManager] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://192.168.1.101:9000/hbase/MasterProcWALs/state-00000000000000000001.log after 10ms
2015-11-08 15:55:30,232 INFO  [master:16000.activeMasterManager] wal.WALProcedureStore: Lease acquired for flushLogId: 2
2015-11-08 15:55:30,277 INFO  [master:16000.activeMasterManager] zookeeper.RecoverableZooKeeper: Process identifier=replicationLogCleaner connecting to ZooKeeper ensemble=localhost:2181
2015-11-08 15:55:30,278 INFO  [master:16000.activeMasterManager] zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=replicationLogCleaner0x0, quorum=localhost:2181, baseZNode=/hbase
2015-11-08 15:55:30,280 INFO  [master:16000.activeMasterManager-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 15:55:30,281 INFO  [master:16000.activeMasterManager-SendThread(localhost:2181)] zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
2015-11-08 15:55:30,288 INFO  [master:16000.activeMasterManager-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x150e617b3fa0005, negotiated timeout = 90000
2015-11-08 15:55:30,303 INFO  [master:16000.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 0 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2015-11-08 15:55:30,535 INFO  [PriorityRpcServer.handler=0,queue=0,port=16000] master.ServerManager: Registering server=master,16020,1446969328252
2015-11-08 15:55:30,553 INFO  [master:16000.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 1, slept for 250 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2015-11-08 15:55:32,056 INFO  [master:16000.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 1, slept for 1753 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2015-11-08 15:55:33,559 INFO  [master:16000.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 1, slept for 3256 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2015-11-08 15:55:34,812 INFO  [master:16000.activeMasterManager] master.ServerManager: Finished waiting for region servers count to settle; checked in 1, slept for 4509 ms, expecting minimum of 1, maximum of 2147483647, master is running
2015-11-08 15:55:34,825 INFO  [master:16000.activeMasterManager] master.MasterFileSystem: Log folder hdfs://192.168.1.101:9000/hbase/WALs/master,16020,1446969328252 belongs to an existing region server
2015-11-08 15:55:34,933 INFO  [master:16000.activeMasterManager] zookeeper.MetaTableLocator: Failed verification of hbase:meta,,1 at address=master,16020,1446968748212, exception=org.apache.hadoop.hbase.NotServingRegionException: Region hbase:meta,,1 is not online on master,16020,1446969328252
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2898)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.getRegion(RSRpcServices.java:947)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.getRegionInfo(RSRpcServices.java:1232)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$2.callBlockingMethod(AdminProtos.java:22233)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2114)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:101)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:130)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:107)
	at java.lang.Thread.run(Thread.java:745)

2015-11-08 15:55:34,951 INFO  [master:16000.activeMasterManager] master.SplitLogManager: dead splitlog workers [master,16020,1446968748212]
2015-11-08 15:55:34,956 INFO  [master:16000.activeMasterManager] master.SplitLogManager: hdfs://192.168.1.101:9000/hbase/WALs/master,16020,1446968748212-splitting is empty dir, no logs to split
2015-11-08 15:55:34,957 INFO  [master:16000.activeMasterManager] master.SplitLogManager: started splitting 0 logs in [hdfs://192.168.1.101:9000/hbase/WALs/master,16020,1446968748212-splitting] for [master,16020,1446968748212]
2015-11-08 15:55:34,965 INFO  [master:16000.activeMasterManager] master.SplitLogManager: finished splitting (more than or equal to) 0 bytes in 0 log files in [hdfs://192.168.1.101:9000/hbase/WALs/master,16020,1446968748212-splitting] in 8ms
2015-11-08 15:55:34,965 INFO  [master:16000.activeMasterManager] zookeeper.MetaTableLocator: Deleting hbase:meta region location in ZooKeeper
2015-11-08 15:55:34,997 INFO  [master:16000.activeMasterManager] master.AssignmentManager: Assigning hbase:meta,,1.1588230740 to master,16020,1446969328252
2015-11-08 15:55:34,997 INFO  [master:16000.activeMasterManager] master.RegionStates: Transition {1588230740 state=OFFLINE, ts=1446969334974, server=null} to {1588230740 state=PENDING_OPEN, ts=1446969334997, server=master,16020,1446969328252}
2015-11-08 15:55:35,036 INFO  [master:16000.activeMasterManager] master.ServerManager: AssignmentManager hasn't finished failover cleanup; waiting
2015-11-08 15:55:35,066 INFO  [AM.ZK.Worker-pool2-t1] master.RegionStates: Transition {1588230740 state=PENDING_OPEN, ts=1446969334997, server=master,16020,1446969328252} to {1588230740 state=OPENING, ts=1446969335066, server=master,16020,1446969328252}
2015-11-08 15:55:35,464 INFO  [AM.ZK.Worker-pool2-t2] master.RegionStates: Transition {1588230740 state=OPENING, ts=1446969335066, server=master,16020,1446969328252} to {1588230740 state=OPEN, ts=1446969335464, server=master,16020,1446969328252}
2015-11-08 15:55:35,467 INFO  [AM.ZK.Worker-pool2-t2] coordination.ZkOpenRegionCoordination: Handling OPENED of 1588230740 from master,16000,1446969327099; deleting unassigned node
2015-11-08 15:55:35,483 INFO  [master:16000.activeMasterManager] master.HMaster: hbase:meta with replicaId 0 assigned=1, rit=false, location=master,16020,1446969328252
2015-11-08 15:55:35,583 INFO  [master:16000.activeMasterManager] hbase.MetaMigrationConvertingToPB: META already up-to date with PB serialization
2015-11-08 15:55:35,602 INFO  [master:16000.activeMasterManager] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=OPEN, ts=1446969335601, server=master,16020,1446968748212} to {6f3d653b8b106cc2df931825f52d6dec state=OFFLINE, ts=1446969335601, server=master,16020,1446968748212}
2015-11-08 15:55:35,606 INFO  [master:16000.activeMasterManager] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=OFFLINE, ts=1446969335601, server=master,16020,1446968748212} to {6f3d653b8b106cc2df931825f52d6dec state=CLOSED, ts=1446969335606, server=master,16020,1446968748212}
2015-11-08 15:55:35,608 INFO  [master:16000.activeMasterManager] master.AssignmentManager: Clean cluster startup. Assigning user regions
2015-11-08 15:55:35,608 INFO  [master:16000.activeMasterManager] master.AssignmentManager: Assigning 1 region(s) to master,16020,1446969328252
2015-11-08 15:55:35,610 INFO  [master:16000.activeMasterManager] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=CLOSED, ts=1446969335606, server=master,16020,1446968748212} to {6f3d653b8b106cc2df931825f52d6dec state=OFFLINE, ts=1446969335610, server=master,16020,1446968748212}
2015-11-08 15:55:35,626 INFO  [master:16000.activeMasterManager] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=OFFLINE, ts=1446969335610, server=master,16020,1446968748212} to {6f3d653b8b106cc2df931825f52d6dec state=PENDING_OPEN, ts=1446969335626, server=master,16020,1446969328252}
2015-11-08 15:55:35,664 INFO  [AM.ZK.Worker-pool2-t5] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=PENDING_OPEN, ts=1446969335626, server=master,16020,1446969328252} to {6f3d653b8b106cc2df931825f52d6dec state=OPENING, ts=1446969335664, server=master,16020,1446969328252}
2015-11-08 15:55:35,666 INFO  [master:16000.activeMasterManager] master.AssignmentManager: Joined the cluster in 82ms, failover=false
2015-11-08 15:55:35,897 INFO  [AM.ZK.Worker-pool2-t6] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=OPENING, ts=1446969335664, server=master,16020,1446969328252} to {6f3d653b8b106cc2df931825f52d6dec state=OPEN, ts=1446969335897, server=master,16020,1446969328252}
2015-11-08 15:55:35,909 INFO  [AM.ZK.Worker-pool2-t8] master.RegionStates: Offlined 6f3d653b8b106cc2df931825f52d6dec from master,16020,1446968748212
2015-11-08 15:55:36,096 INFO  [master:16000.activeMasterManager] master.HMaster: Master has completed initialization
2015-11-08 15:55:36,106 INFO  [master:16000.activeMasterManager] quotas.MasterQuotaManager: Quota support disabled
Sun Nov  8 15:58:41 CST 2015 Stopping hbase (via master)
2015-11-08 15:58:43,368 INFO  [B.defaultRpcServer.handler=3,queue=0,port=16000] master.MasterRpcServices: Client=hadoop/null shutdown
2015-11-08 15:58:43,368 INFO  [B.defaultRpcServer.handler=3,queue=0,port=16000] regionserver.HRegionServer: STOPPED: Cluster shutdown requested
2015-11-08 15:58:43,368 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: Stopping infoServer
2015-11-08 15:58:43,370 INFO  [master/master/192.168.1.101:16000] mortbay.log: Stopped SelectChannelConnector@0.0.0.0:16010
2015-11-08 15:58:43,470 INFO  [master/master/192.168.1.101:16000] procedure2.ProcedureExecutor: Stopping the procedure executor
2015-11-08 15:58:43,470 INFO  [master/master/192.168.1.101:16000] wal.WALProcedureStore: Stopping the WAL Procedure Store
2015-11-08 15:58:43,636 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: stopping server master,16000,1446969327099
2015-11-08 15:58:43,636 INFO  [master/master/192.168.1.101:16000] client.ConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x150e617b3fa0002
2015-11-08 15:58:43,648 INFO  [master/master/192.168.1.101:16000-EventThread] zookeeper.ClientCnxn: EventThread shut down
2015-11-08 15:58:43,649 INFO  [master/master/192.168.1.101:16000] zookeeper.ZooKeeper: Session: 0x150e617b3fa0002 closed
2015-11-08 15:58:43,649 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: stopping server master,16000,1446969327099; all regions closed.
2015-11-08 15:58:43,649 INFO  [master/master/192.168.1.101:16000] hbase.ChoreService: Chore service for: master,16000,1446969327099 had [[ScheduledChore: Name: HFileCleaner Period: 60000 Unit: MILLISECONDS], [ScheduledChore: Name: CatalogJanitor-master:16000 Period: 300000 Unit: MILLISECONDS], [ScheduledChore: Name: master,16000,1446969327099-BalancerChore Period: 300000 Unit: MILLISECONDS], [ScheduledChore: Name: master,16000,1446969327099-ClusterStatusChore Period: 60000 Unit: MILLISECONDS], [ScheduledChore: Name: LogsCleaner Period: 60000 Unit: MILLISECONDS]] on shutdown
2015-11-08 15:58:43,650 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down master,16020,1446969328252
2015-11-08 15:58:43,874 INFO  [master,16000,1446969327099_splitLogManager__ChoreService_1] master.SplitLogManager$TimeoutMonitor: Chore: SplitLogManager Timeout Monitor was stopped
2015-11-08 15:58:44,660 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down master,16020,1446969328252
2015-11-08 15:58:45,673 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down master,16020,1446969328252
2015-11-08 15:58:46,683 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down master,16020,1446969328252
2015-11-08 15:58:47,693 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down master,16020,1446969328252
2015-11-08 15:58:48,703 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down master,16020,1446969328252
2015-11-08 15:58:49,713 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down master,16020,1446969328252
2015-11-08 15:58:50,723 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down master,16020,1446969328252
2015-11-08 15:58:51,733 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down master,16020,1446969328252
2015-11-08 15:58:52,751 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down master,16020,1446969328252
2015-11-08 15:58:53,760 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down master,16020,1446969328252
2015-11-08 15:58:54,769 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down master,16020,1446969328252
2015-11-08 15:58:55,779 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down master,16020,1446969328252
2015-11-08 15:58:56,381 INFO  [main-EventThread] zookeeper.RegionServerTracker: RegionServer ephemeral node deleted, processing expiration [master,16020,1446969328252]
2015-11-08 15:58:56,382 INFO  [main-EventThread] master.ServerManager: Cluster shutdown set; master,16020,1446969328252 expired; onlineServers=0
2015-11-08 15:58:56,399 INFO  [master/master/192.168.1.101:16000] client.ConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x150e617b3fa0003
2015-11-08 15:58:56,406 INFO  [master/master/192.168.1.101:16000] zookeeper.ZooKeeper: Session: 0x150e617b3fa0003 closed
2015-11-08 15:58:56,406 INFO  [master:16000.activeMasterManager-EventThread] zookeeper.ClientCnxn: EventThread shut down
2015-11-08 15:58:56,406 INFO  [master/master/192.168.1.101:16000] hbase.ChoreService: Chore service for: master,16000,1446969327099_splitLogManager_ had [] on shutdown
2015-11-08 15:58:56,407 INFO  [master/master/192.168.1.101:16000] flush.MasterFlushTableProcedureManager: stop: server shutting down.
2015-11-08 15:58:56,407 INFO  [master/master/192.168.1.101:16000] ipc.RpcServer: Stopping server on 16000
2015-11-08 15:58:56,407 INFO  [RpcServer.listener,port=16000] ipc.RpcServer: RpcServer.listener,port=16000: stopping
2015-11-08 15:58:56,408 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopped
2015-11-08 15:58:56,408 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopping
2015-11-08 15:58:56,414 INFO  [master/master/192.168.1.101:16000] zookeeper.RecoverableZooKeeper: Node /hbase/rs/master,16000,1446969327099 already deleted, retry=false
2015-11-08 15:58:56,423 INFO  [master/master/192.168.1.101:16000] zookeeper.ZooKeeper: Session: 0x150e617b3fa0000 closed
2015-11-08 15:58:56,423 INFO  [main-EventThread] zookeeper.ClientCnxn: EventThread shut down
2015-11-08 15:58:56,423 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: stopping server master,16000,1446969327099; zookeeper connection closed.
2015-11-08 15:58:56,423 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: master/master/192.168.1.101:16000 exiting
Sun Nov  8 16:02:40 CST 2015 Stopping hbase (via master)
Sun Nov  8 16:02:57 CST 2015 Starting master on master
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 30141
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 10240
cpu time               (seconds, -t) unlimited
max user processes              (-u) 1024
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2015-11-08 16:02:57,636 INFO  [main] util.VersionInfo: HBase 1.1.2
2015-11-08 16:02:57,636 INFO  [main] util.VersionInfo: Source code repository git://hw11397.local/Volumes/hbase-1.1.2RC2/hbase revision=cc2b70cf03e3378800661ec5cab11eb43fafe0fc
2015-11-08 16:02:57,636 INFO  [main] util.VersionInfo: Compiled by ndimiduk on Wed Aug 26 20:11:27 PDT 2015
2015-11-08 16:02:57,636 INFO  [main] util.VersionInfo: From source with checksum 73da41f3d1b867b7aba6166c77fafc17
2015-11-08 16:02:58,037 INFO  [main] util.ServerCommandLine: env:TERM=xterm
2015-11-08 16:02:58,037 INFO  [main] util.ServerCommandLine: env:HADOOP_COMMON_LIB_NATIVE_DIR=/opt/hadoop/lib/native
2015-11-08 16:02:58,037 INFO  [main] util.ServerCommandLine: env:IMSETTINGS_MODULE=none
2015-11-08 16:02:58,037 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/opt/java
2015-11-08 16:02:58,037 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/opt/hbase/bin/..
2015-11-08 16:02:58,037 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2015-11-08 16:02:58,037 INFO  [main] util.ServerCommandLine: env:SESSION_MANAGER=local/unix:@/tmp/.ICE-unix/2995,unix/unix:/tmp/.ICE-unix/2995
2015-11-08 16:02:58,037 INFO  [main] util.ServerCommandLine: env:IMSETTINGS_INTEGRATE_DESKTOP=yes
2015-11-08 16:02:58,038 INFO  [main] util.ServerCommandLine: env:GNOME_DESKTOP_SESSION_ID=this-is-deprecated
2015-11-08 16:02:58,038 INFO  [main] util.ServerCommandLine: env:MAIL=/var/spool/mail/hadoop
2015-11-08 16:02:58,038 INFO  [main] util.ServerCommandLine: env:XDG_SESSION_COOKIE=ab8c9d4f5491283c7c300d7800000013-1446958848.52338-1725977001
2015-11-08 16:02:58,038 INFO  [main] util.ServerCommandLine: env:GDMSESSION=gnome
2015-11-08 16:02:58,038 INFO  [main] util.ServerCommandLine: env:HOSTNAME=master
2015-11-08 16:02:58,038 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/tmp/hbase-hadoop-master.znode
2015-11-08 16:02:58,038 INFO  [main] util.ServerCommandLine: env:PWD=/opt/hbase/bin
2015-11-08 16:02:58,038 INFO  [main] util.ServerCommandLine: env:HBASE_MASTER_OPTS= -XX:PermSize=128m -XX:MaxPermSize=128m
2015-11-08 16:02:58,038 INFO  [main] util.ServerCommandLine: env:CVS_RSH=ssh
2015-11-08 16:02:58,038 INFO  [main] util.ServerCommandLine: env:JAVA_LIBRARY_PATH=/opt/hadoop/lib/native::/opt/hadoop/lib/native:
2015-11-08 16:02:58,038 INFO  [main] util.ServerCommandLine: env:G_BROKEN_FILENAMES=1
2015-11-08 16:02:58,038 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2015-11-08 16:02:58,038 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2015-11-08 16:02:58,038 INFO  [main] util.ServerCommandLine: env:NLSPATH=/usr/dt/lib/nls/msg/%L/%N.cat
2015-11-08 16:02:58,038 INFO  [main] util.ServerCommandLine: env:GNOME_KEYRING_SOCKET=/tmp/keyring-IruJ62/socket
2015-11-08 16:02:58,039 INFO  [main] util.ServerCommandLine: env:GDM_KEYBOARD_LAYOUT=us
2015-11-08 16:02:58,039 INFO  [main] util.ServerCommandLine: env:HBASE_REGIONSERVER_OPTS= -XX:PermSize=128m -XX:MaxPermSize=128m
2015-11-08 16:02:58,039 INFO  [main] util.ServerCommandLine: env:HISTSIZE=1000
2015-11-08 16:02:58,039 INFO  [main] util.ServerCommandLine: env:PATH=/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin:/sbin:/opt/java//bin:/opt/java/jre/bin:/opt/hadoop/bin:/home/hadoop/bin
2015-11-08 16:02:58,039 INFO  [main] util.ServerCommandLine: env:QTLIB=/usr/lib64/qt-3.3/lib
2015-11-08 16:02:58,039 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2015-11-08 16:02:58,039 INFO  [main] util.ServerCommandLine: env:GDM_LANG=en_US.UTF-8
2015-11-08 16:02:58,039 INFO  [main] util.ServerCommandLine: env:XAUTHORITY=/var/run/gdm/auth-for-hadoop-akmkFp/database
2015-11-08 16:02:58,039 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/tmp/hbase-hadoop-master.autorestart
2015-11-08 16:02:58,039 INFO  [main] util.ServerCommandLine: env:USERNAME=hadoop
2015-11-08 16:02:58,039 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-hadoop-master-master.log
2015-11-08 16:02:58,039 INFO  [main] util.ServerCommandLine: env:SSH_ASKPASS=/usr/libexec/openssh/gnome-ssh-askpass
2015-11-08 16:02:58,039 INFO  [main] util.ServerCommandLine: env:SHLVL=5
2015-11-08 16:02:58,040 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/opt/hbase/bin/../logs
2015-11-08 16:02:58,040 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-XX:+UseConcMarkSweepGC   -XX:PermSize=128m -XX:MaxPermSize=128m -Dhbase.log.dir=/opt/hbase/bin/../logs -Dhbase.log.file=hbase-hadoop-master-master.log -Dhbase.home.dir=/opt/hbase/bin/.. -Dhbase.id.str=hadoop -Dhbase.root.logger=INFO,RFA -Djava.library.path=/opt/hadoop/lib/native::/opt/hadoop/lib/native: -Dhbase.security.logger=INFO,RFAS
2015-11-08 16:02:58,040 INFO  [main] util.ServerCommandLine: env:XFILESEARCHPATH=/usr/dt/app-defaults/%L/Dt
2015-11-08 16:02:58,040 INFO  [main] util.ServerCommandLine: env:COLORTERM=gnome-terminal
2015-11-08 16:02:58,040 INFO  [main] util.ServerCommandLine: env:QT_IM_MODULE=xim
2015-11-08 16:02:58,040 INFO  [main] util.ServerCommandLine: env:WINDOWID=20979824
2015-11-08 16:02:58,040 INFO  [main] util.ServerCommandLine: env:LOGNAME=hadoop
2015-11-08 16:02:58,040 INFO  [main] util.ServerCommandLine: env:QTDIR=/usr/lib64/qt-3.3
2015-11-08 16:02:58,040 INFO  [main] util.ServerCommandLine: env:XMODIFIERS=@im=none
2015-11-08 16:02:58,040 INFO  [main] util.ServerCommandLine: env:SSH_AUTH_SOCK=/tmp/keyring-IruJ62/socket.ssh
2015-11-08 16:02:58,040 INFO  [main] util.ServerCommandLine: env:HADOOP_HOME=/opt/hadoop
2015-11-08 16:02:58,040 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=:/opt/hadoop/lib/native::/opt/hadoop/lib/native:
2015-11-08 16:02:58,040 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2015-11-08 16:02:58,041 INFO  [main] util.ServerCommandLine: env:HADOOP_OPTS=-Djava.library.path=/opt/hadoop/lib/native
2015-11-08 16:02:58,041 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2015-11-08 16:02:58,041 INFO  [main] util.ServerCommandLine: env:DBUS_SESSION_BUS_ADDRESS=unix:abstract=/tmp/dbus-uqNe1cANDo,guid=eca351d0636069d92d6d2f1900000495
2015-11-08 16:02:58,041 INFO  [main] util.ServerCommandLine: env:GNOME_KEYRING_PID=2985
2015-11-08 16:02:58,041 INFO  [main] util.ServerCommandLine: env:GTK_RC_FILES=/etc/gtk/gtkrc:/home/hadoop/.gtkrc-1.2-gnome2
2015-11-08 16:02:58,041 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2015-11-08 16:02:58,042 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/opt/hbase/bin/../conf:/opt/java/lib/tools.jar:/opt/hbase/bin/..:/opt/hbase/bin/../lib/activation-1.1.jar:/opt/hbase/bin/../lib/aopalliance-1.0.jar:/opt/hbase/bin/../lib/apacheds-i18n-2.0.0-M15.jar:/opt/hbase/bin/../lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hbase/bin/../lib/api-asn1-api-1.0.0-M20.jar:/opt/hbase/bin/../lib/api-util-1.0.0-M20.jar:/opt/hbase/bin/../lib/asm-3.1.jar:/opt/hbase/bin/../lib/avro-1.7.4.jar:/opt/hbase/bin/../lib/commons-beanutils-1.7.0.jar:/opt/hbase/bin/../lib/commons-beanutils-core-1.8.0.jar:/opt/hbase/bin/../lib/commons-cli-1.2.jar:/opt/hbase/bin/../lib/commons-codec-1.9.jar:/opt/hbase/bin/../lib/commons-collections-3.2.1.jar:/opt/hbase/bin/../lib/commons-compress-1.4.1.jar:/opt/hbase/bin/../lib/commons-configuration-1.6.jar:/opt/hbase/bin/../lib/commons-daemon-1.0.13.jar:/opt/hbase/bin/../lib/commons-digester-1.8.jar:/opt/hbase/bin/../lib/commons-el-1.0.jar:/opt/hbase/bin/../lib/commons-httpclient-3.1.jar:/opt/hbase/bin/../lib/commons-io-2.4.jar:/opt/hbase/bin/../lib/commons-lang-2.6.jar:/opt/hbase/bin/../lib/commons-logging-1.2.jar:/opt/hbase/bin/../lib/commons-math-2.2.jar:/opt/hbase/bin/../lib/commons-math3-3.1.1.jar:/opt/hbase/bin/../lib/commons-net-3.1.jar:/opt/hbase/bin/../lib/disruptor-3.3.0.jar:/opt/hbase/bin/../lib/findbugs-annotations-1.3.9-1.jar:/opt/hbase/bin/../lib/guava-12.0.1.jar:/opt/hbase/bin/../lib/guice-3.0.jar:/opt/hbase/bin/../lib/guice-servlet-3.0.jar:/opt/hbase/bin/../lib/hadoop-annotations-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-auth-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-client-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-common-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-hdfs-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-app-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-common-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-core-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-jobclient-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-shuffle-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-api-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-client-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-common-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-server-common-2.5.1.jar:/opt/hbase/bin/../lib/hbase-annotations-1.1.2.jar:/opt/hbase/bin/../lib/hbase-annotations-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-client-1.1.2.jar:/opt/hbase/bin/../lib/hbase-common-1.1.2.jar:/opt/hbase/bin/../lib/hbase-common-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-examples-1.1.2.jar:/opt/hbase/bin/../lib/hbase-hadoop2-compat-1.1.2.jar:/opt/hbase/bin/../lib/hbase-hadoop-compat-1.1.2.jar:/opt/hbase/bin/../lib/hbase-it-1.1.2.jar:/opt/hbase/bin/../lib/hbase-it-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-prefix-tree-1.1.2.jar:/opt/hbase/bin/../lib/hbase-procedure-1.1.2.jar:/opt/hbase/bin/../lib/hbase-protocol-1.1.2.jar:/opt/hbase/bin/../lib/hbase-resource-bundle-1.1.2.jar:/opt/hbase/bin/../lib/hbase-rest-1.1.2.jar:/opt/hbase/bin/../lib/hbase-server-1.1.2.jar:/opt/hbase/bin/../lib/hbase-server-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-shell-1.1.2.jar:/opt/hbase/bin/../lib/hbase-thrift-1.1.2.jar:/opt/hbase/bin/../lib/htrace-core-3.1.0-incubating.jar:/opt/hbase/bin/../lib/httpclient-4.2.5.jar:/opt/hbase/bin/../lib/httpcore-4.1.3.jar:/opt/hbase/bin/../lib/jackson-core-asl-1.9.13.jar:/opt/hbase/bin/../lib/jackson-jaxrs-1.9.13.jar:/opt/hbase/bin/../lib/jackson-mapper-asl-1.9.13.jar:/opt/hbase/bin/../lib/jackson-xc-1.9.13.jar:/opt/hbase/bin/../lib/jamon-runtime-2.3.1.jar:/opt/hbase/bin/../lib/jasper-compiler-5.5.23.jar:/opt/hbase/bin/../lib/jasper-runtime-5.5.23.jar:/opt/hbase/bin/../lib/javax.inject-1.jar:/opt/hbase/bin/../lib/java-xmlbuilder-0.4.jar:/opt/hbase/bin/../lib/jaxb-api-2.2.2.jar:/opt/hbase/bin/../lib/jaxb-impl-2.2.3-1.jar:/opt/hbase/bin/../lib/jcodings-1.0.8.jar:/opt/hbase/bin/../lib/jersey-client-1.9.jar:/opt/hbase/bin/../lib/jersey-core-1.9.jar:/opt/hbase/bin/../lib/jersey-guice-1.9.jar:/opt/hbase/bin/../lib/jersey-json-1.9.jar:/opt/hbase/bin/../lib/jersey-server-1.9.jar:/opt/hbase/bin/../lib/jets3t-0.9.0.jar:/opt/hbase/bin/../lib/jettison-1.3.3.jar:/opt/hbase/bin/../lib/jetty-6.1.26.jar:/opt/hbase/bin/../lib/jetty-sslengine-6.1.26.jar:/opt/hbase/bin/../lib/jetty-util-6.1.26.jar:/opt/hbase/bin/../lib/joni-2.1.2.jar:/opt/hbase/bin/../lib/jruby-complete-1.6.8.jar:/opt/hbase/bin/../lib/jsch-0.1.42.jar:/opt/hbase/bin/../lib/jsp-2.1-6.1.14.jar:/opt/hbase/bin/../lib/jsp-api-2.1-6.1.14.jar:/opt/hbase/bin/../lib/jsr305-1.3.9.jar:/opt/hbase/bin/../lib/junit-4.11.jar:/opt/hbase/bin/../lib/leveldbjni-all-1.8.jar:/opt/hbase/bin/../lib/libthrift-0.9.0.jar:/opt/hbase/bin/../lib/log4j-1.2.17.jar:/opt/hbase/bin/../lib/metrics-core-2.2.0.jar:/opt/hbase/bin/../lib/netty-3.2.4.Final.jar:/opt/hbase/bin/../lib/netty-all-4.0.23.Final.jar:/opt/hbase/bin/../lib/paranamer-2.3.jar:/opt/hbase/bin/../lib/protobuf-java-2.5.0.jar:/opt/hbase/bin/../lib/servlet-api-2.5-6.1.14.jar:/opt/hbase/bin/../lib/servlet-api-2.5.jar:/opt/hbase/bin/../lib/slf4j-api-1.7.7.jar:/opt/hbase/bin/../lib/slf4j-log4j12-1.7.5.jar:/opt/hbase/bin/../lib/snappy-java-1.0.4.1.jar:/opt/hbase/bin/../lib/spymemcached-2.11.6.jar:/opt/hbase/bin/../lib/xmlenc-0.52.jar:/opt/hbase/bin/../lib/xz-1.0.jar:/opt/hbase/bin/../lib/zookeeper-3.4.6.jar:/opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/contrib/capacity-scheduler/*.jar
2015-11-08 16:02:58,042 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2015-11-08 16:02:58,042 INFO  [main] util.ServerCommandLine: env:JRE_HOME=/opt/java/jre
2015-11-08 16:02:58,042 INFO  [main] util.ServerCommandLine: env:DESKTOP_SESSION=gnome
2015-11-08 16:02:58,042 INFO  [main] util.ServerCommandLine: env:QTINC=/usr/lib64/qt-3.3/include
2015-11-08 16:02:58,043 INFO  [main] util.ServerCommandLine: env:DISPLAY=192.168.1.100:2.0
2015-11-08 16:02:58,043 INFO  [main] util.ServerCommandLine: env:USER=hadoop
2015-11-08 16:02:58,043 INFO  [main] util.ServerCommandLine: env:HISTCONTROL=ignoredups
2015-11-08 16:02:58,043 INFO  [main] util.ServerCommandLine: env:HOME=/home/hadoop
2015-11-08 16:02:58,043 INFO  [main] util.ServerCommandLine: env:LESSOPEN=||/usr/bin/lesspipe.sh %s
2015-11-08 16:02:58,043 INFO  [main] util.ServerCommandLine: env:LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arj=01;31:*.taz=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lz=01;31:*.xz=01;31:*.bz2=01;31:*.tbz=01;31:*.tbz2=01;31:*.bz=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.rar=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
2015-11-08 16:02:58,043 INFO  [main] util.ServerCommandLine: env:ORBIT_SOCKETDIR=/tmp/orbit-hadoop
2015-11-08 16:02:58,043 INFO  [main] util.ServerCommandLine: env:LANG=en_US.UTF-8
2015-11-08 16:02:58,043 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-hadoop-master-master
2015-11-08 16:02:58,043 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=hadoop
2015-11-08 16:02:58,045 INFO  [main] util.ServerCommandLine: vmName=Java HotSpot(TM) 64-Bit Server VM, vmVendor=Oracle Corporation, vmVersion=24.79-b02
2015-11-08 16:02:58,046 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_master, -XX:OnOutOfMemoryError=kill -9 %p, -XX:+UseConcMarkSweepGC, -XX:PermSize=128m, -XX:MaxPermSize=128m, -Dhbase.log.dir=/opt/hbase/bin/../logs, -Dhbase.log.file=hbase-hadoop-master-master.log, -Dhbase.home.dir=/opt/hbase/bin/.., -Dhbase.id.str=hadoop, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=/opt/hadoop/lib/native::/opt/hadoop/lib/native:, -Dhbase.security.logger=INFO,RFAS]
2015-11-08 16:02:58,491 WARN  [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-11-08 16:02:58,781 INFO  [main] regionserver.RSRpcServices: master/master/192.168.1.101:16000 server-side HConnection retries=350
2015-11-08 16:02:59,014 INFO  [main] ipc.SimpleRpcScheduler: Using deadline as user call queue, count=3
2015-11-08 16:02:59,039 INFO  [main] ipc.RpcServer: master/master/192.168.1.101:16000: started 10 reader(s).
2015-11-08 16:02:59,095 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2015-11-08 16:02:59,154 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-11-08 16:02:59,154 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2015-11-08 16:03:00,296 INFO  [main] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2015-11-08 16:03:00,545 INFO  [main] zookeeper.RecoverableZooKeeper: Process identifier=master:16000 connecting to ZooKeeper ensemble=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181
2015-11-08 16:03:00,555 INFO  [main] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2015-11-08 16:03:00,555 INFO  [main] zookeeper.ZooKeeper: Client environment:host.name=master
2015-11-08 16:03:00,555 INFO  [main] zookeeper.ZooKeeper: Client environment:java.version=1.7.0_79
2015-11-08 16:03:00,555 INFO  [main] zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
2015-11-08 16:03:00,555 INFO  [main] zookeeper.ZooKeeper: Client environment:java.home=/opt/java/jre
2015-11-08 16:03:00,555 INFO  [main] zookeeper.ZooKeeper: Client environment:java.class.path=/opt/hbase/bin/../conf:/opt/java/lib/tools.jar:/opt/hbase/bin/..:/opt/hbase/bin/../lib/activation-1.1.jar:/opt/hbase/bin/../lib/aopalliance-1.0.jar:/opt/hbase/bin/../lib/apacheds-i18n-2.0.0-M15.jar:/opt/hbase/bin/../lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hbase/bin/../lib/api-asn1-api-1.0.0-M20.jar:/opt/hbase/bin/../lib/api-util-1.0.0-M20.jar:/opt/hbase/bin/../lib/asm-3.1.jar:/opt/hbase/bin/../lib/avro-1.7.4.jar:/opt/hbase/bin/../lib/commons-beanutils-1.7.0.jar:/opt/hbase/bin/../lib/commons-beanutils-core-1.8.0.jar:/opt/hbase/bin/../lib/commons-cli-1.2.jar:/opt/hbase/bin/../lib/commons-codec-1.9.jar:/opt/hbase/bin/../lib/commons-collections-3.2.1.jar:/opt/hbase/bin/../lib/commons-compress-1.4.1.jar:/opt/hbase/bin/../lib/commons-configuration-1.6.jar:/opt/hbase/bin/../lib/commons-daemon-1.0.13.jar:/opt/hbase/bin/../lib/commons-digester-1.8.jar:/opt/hbase/bin/../lib/commons-el-1.0.jar:/opt/hbase/bin/../lib/commons-httpclient-3.1.jar:/opt/hbase/bin/../lib/commons-io-2.4.jar:/opt/hbase/bin/../lib/commons-lang-2.6.jar:/opt/hbase/bin/../lib/commons-logging-1.2.jar:/opt/hbase/bin/../lib/commons-math-2.2.jar:/opt/hbase/bin/../lib/commons-math3-3.1.1.jar:/opt/hbase/bin/../lib/commons-net-3.1.jar:/opt/hbase/bin/../lib/disruptor-3.3.0.jar:/opt/hbase/bin/../lib/findbugs-annotations-1.3.9-1.jar:/opt/hbase/bin/../lib/guava-12.0.1.jar:/opt/hbase/bin/../lib/guice-3.0.jar:/opt/hbase/bin/../lib/guice-servlet-3.0.jar:/opt/hbase/bin/../lib/hadoop-annotations-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-auth-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-client-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-common-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-hdfs-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-app-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-common-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-core-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-jobclient-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-shuffle-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-api-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-client-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-common-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-server-common-2.5.1.jar:/opt/hbase/bin/../lib/hbase-annotations-1.1.2.jar:/opt/hbase/bin/../lib/hbase-annotations-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-client-1.1.2.jar:/opt/hbase/bin/../lib/hbase-common-1.1.2.jar:/opt/hbase/bin/../lib/hbase-common-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-examples-1.1.2.jar:/opt/hbase/bin/../lib/hbase-hadoop2-compat-1.1.2.jar:/opt/hbase/bin/../lib/hbase-hadoop-compat-1.1.2.jar:/opt/hbase/bin/../lib/hbase-it-1.1.2.jar:/opt/hbase/bin/../lib/hbase-it-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-prefix-tree-1.1.2.jar:/opt/hbase/bin/../lib/hbase-procedure-1.1.2.jar:/opt/hbase/bin/../lib/hbase-protocol-1.1.2.jar:/opt/hbase/bin/../lib/hbase-resource-bundle-1.1.2.jar:/opt/hbase/bin/../lib/hbase-rest-1.1.2.jar:/opt/hbase/bin/../lib/hbase-server-1.1.2.jar:/opt/hbase/bin/../lib/hbase-server-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-shell-1.1.2.jar:/opt/hbase/bin/../lib/hbase-thrift-1.1.2.jar:/opt/hbase/bin/../lib/htrace-core-3.1.0-incubating.jar:/opt/hbase/bin/../lib/httpclient-4.2.5.jar:/opt/hbase/bin/../lib/httpcore-4.1.3.jar:/opt/hbase/bin/../lib/jackson-core-asl-1.9.13.jar:/opt/hbase/bin/../lib/jackson-jaxrs-1.9.13.jar:/opt/hbase/bin/../lib/jackson-mapper-asl-1.9.13.jar:/opt/hbase/bin/../lib/jackson-xc-1.9.13.jar:/opt/hbase/bin/../lib/jamon-runtime-2.3.1.jar:/opt/hbase/bin/../lib/jasper-compiler-5.5.23.jar:/opt/hbase/bin/../lib/jasper-runtime-5.5.23.jar:/opt/hbase/bin/../lib/javax.inject-1.jar:/opt/hbase/bin/../lib/java-xmlbuilder-0.4.jar:/opt/hbase/bin/../lib/jaxb-api-2.2.2.jar:/opt/hbase/bin/../lib/jaxb-impl-2.2.3-1.jar:/opt/hbase/bin/../lib/jcodings-1.0.8.jar:/opt/hbase/bin/../lib/jersey-client-1.9.jar:/opt/hbase/bin/../lib/jersey-core-1.9.jar:/opt/hbase/bin/../lib/jersey-guice-1.9.jar:/opt/hbase/bin/../lib/jersey-json-1.9.jar:/opt/hbase/bin/../lib/jersey-server-1.9.jar:/opt/hbase/bin/../lib/jets3t-0.9.0.jar:/opt/hbase/bin/../lib/jettison-1.3.3.jar:/opt/hbase/bin/../lib/jetty-6.1.26.jar:/opt/hbase/bin/../lib/jetty-sslengine-6.1.26.jar:/opt/hbase/bin/../lib/jetty-util-6.1.26.jar:/opt/hbase/bin/../lib/joni-2.1.2.jar:/opt/hbase/bin/../lib/jruby-complete-1.6.8.jar:/opt/hbase/bin/../lib/jsch-0.1.42.jar:/opt/hbase/bin/../lib/jsp-2.1-6.1.14.jar:/opt/hbase/bin/../lib/jsp-api-2.1-6.1.14.jar:/opt/hbase/bin/../lib/jsr305-1.3.9.jar:/opt/hbase/bin/../lib/junit-4.11.jar:/opt/hbase/bin/../lib/leveldbjni-all-1.8.jar:/opt/hbase/bin/../lib/libthrift-0.9.0.jar:/opt/hbase/bin/../lib/log4j-1.2.17.jar:/opt/hbase/bin/../lib/metrics-core-2.2.0.jar:/opt/hbase/bin/../lib/netty-3.2.4.Final.jar:/opt/hbase/bin/../lib/netty-all-4.0.23.Final.jar:/opt/hbase/bin/../lib/paranamer-2.3.jar:/opt/hbase/bin/../lib/protobuf-java-2.5.0.jar:/opt/hbase/bin/../lib/servlet-api-2.5-6.1.14.jar:/opt/hbase/bin/../lib/servlet-api-2.5.jar:/opt/hbase/bin/../lib/slf4j-api-1.7.7.jar:/opt/hbase/bin/../lib/slf4j-log4j12-1.7.5.jar:/opt/hbase/bin/../lib/snappy-java-1.0.4.1.jar:/opt/hbase/bin/../lib/spymemcached-2.11.6.jar:/opt/hbase/bin/../lib/xmlenc-0.52.jar:/opt/hbase/bin/../lib/xz-1.0.jar:/opt/hbase/bin/../lib/zookeeper-3.4.6.jar:/opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-auth-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/opt/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/opt/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop/share/hadoop/common/lib/curator-framework-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/opt/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/opt/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop/share/hadoop/common/lib/curator-client-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/opt/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-annotations-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/opt/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop/share/hadoop/common/lib/htrace-core-3.0.4.jar:/opt/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop/share/hadoop/common/hadoop-common-2.6.0-tests.jar:/opt/hadoop/share/hadoop/common/hadoop-common-2.6.0.jar:/opt/hadoop/share/hadoop/common/hadoop-nfs-2.6.0.jar:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/opt/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.0-tests.jar:/opt/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jline-0.9.94.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-tests.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar
2015-11-08 16:03:00,555 INFO  [main] zookeeper.ZooKeeper: Client environment:java.library.path=/opt/hadoop/lib/native::/opt/hadoop/lib/native:
2015-11-08 16:03:00,555 INFO  [main] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2015-11-08 16:03:00,555 INFO  [main] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2015-11-08 16:03:00,555 INFO  [main] zookeeper.ZooKeeper: Client environment:os.name=Linux
2015-11-08 16:03:00,555 INFO  [main] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2015-11-08 16:03:00,555 INFO  [main] zookeeper.ZooKeeper: Client environment:os.version=2.6.32-573.el6.x86_64
2015-11-08 16:03:00,555 INFO  [main] zookeeper.ZooKeeper: Client environment:user.name=hadoop
2015-11-08 16:03:00,555 INFO  [main] zookeeper.ZooKeeper: Client environment:user.home=/home/hadoop
2015-11-08 16:03:00,555 INFO  [main] zookeeper.ZooKeeper: Client environment:user.dir=/opt/hbase/bin
2015-11-08 16:03:00,556 INFO  [main] zookeeper.ZooKeeper: Initiating client connection, connectString=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181 sessionTimeout=90000 watcher=master:160000x0, quorum=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181, baseZNode=/hbase
2015-11-08 16:03:00,572 INFO  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 16:03:00,575 INFO  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.106/192.168.1.106:2181, initiating session
2015-11-08 16:03:00,593 INFO  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.106/192.168.1.106:2181, sessionid = 0x250e396fa1b0001, negotiated timeout = 90000
2015-11-08 16:03:00,644 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2015-11-08 16:03:00,644 INFO  [RpcServer.listener,port=16000] ipc.RpcServer: RpcServer.listener,port=16000: starting
2015-11-08 16:03:00,723 INFO  [main] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-11-08 16:03:00,728 INFO  [main] http.HttpRequestLog: Http request log for http.requests.master is not defined
2015-11-08 16:03:00,744 INFO  [main] http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.hbase.http.HttpServer$QuotingInputFilter)
2015-11-08 16:03:00,747 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context master
2015-11-08 16:03:00,748 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-11-08 16:03:00,748 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-11-08 16:03:00,778 INFO  [main] http.HttpServer: Jetty bound to port 16010
2015-11-08 16:03:00,779 INFO  [main] mortbay.log: jetty-6.1.26
2015-11-08 16:03:01,357 INFO  [main] mortbay.log: Started SelectChannelConnector@0.0.0.0:16010
2015-11-08 16:03:01,360 INFO  [main] master.HMaster: hbase.rootdir=hdfs://192.168.1.101:9000/hbase, hbase.cluster.distributed=true
2015-11-08 16:03:01,372 INFO  [main] master.HMaster: Adding backup master ZNode /hbase/backup-masters/master,16000,1446969779177
2015-11-08 16:03:01,526 INFO  [master:16000.activeMasterManager] master.ActiveMasterManager: Deleting ZNode for /hbase/backup-masters/master,16000,1446969779177 from backup master directory
2015-11-08 16:03:01,539 INFO  [master:16000.activeMasterManager] master.ActiveMasterManager: Registered Active Master=master,16000,1446969779177
2015-11-08 16:03:01,643 INFO  [master/master/192.168.1.101:16000] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x5a7d55e7 connecting to ZooKeeper ensemble=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181
2015-11-08 16:03:01,643 INFO  [master/master/192.168.1.101:16000] zookeeper.ZooKeeper: Initiating client connection, connectString=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181 sessionTimeout=90000 watcher=hconnection-0x5a7d55e70x0, quorum=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181, baseZNode=/hbase
2015-11-08 16:03:01,655 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 16:03:01,661 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.102/192.168.1.102:2181, initiating session
2015-11-08 16:03:01,684 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.102/192.168.1.102:2181, sessionid = 0x150e61e9e520000, negotiated timeout = 90000
2015-11-08 16:03:02,064 INFO  [master:16000.activeMasterManager] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2015-11-08 16:03:02,081 INFO  [master:16000.activeMasterManager] coordination.SplitLogManagerCoordination: Found 0 orphan tasks and 0 rescan nodes
2015-11-08 16:03:02,124 INFO  [master:16000.activeMasterManager] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x2d62624e connecting to ZooKeeper ensemble=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181
2015-11-08 16:03:02,124 INFO  [master:16000.activeMasterManager] zookeeper.ZooKeeper: Initiating client connection, connectString=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181 sessionTimeout=90000 watcher=hconnection-0x2d62624e0x0, quorum=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181, baseZNode=/hbase
2015-11-08 16:03:02,124 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 16:03:02,125 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.102/192.168.1.102:2181, initiating session
2015-11-08 16:03:02,136 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.102/192.168.1.102:2181, sessionid = 0x150e61e9e520001, negotiated timeout = 90000
2015-11-08 16:03:02,156 INFO  [master:16000.activeMasterManager] balancer.StochasticLoadBalancer: loading config
2015-11-08 16:03:02,242 INFO  [master:16000.activeMasterManager] master.HMaster: Server active/primary master=master,16000,1446969779177, sessionid=0x250e396fa1b0001, setting cluster-up flag (Was=false)
2015-11-08 16:03:02,243 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: ClusterId : 18e4235c-98ec-4147-8ac4-00cf10508c80
2015-11-08 16:03:02,280 INFO  [master:16000.activeMasterManager] procedure.ZKProcedureUtil: Clearing all procedure znodes: /hbase/online-snapshot/acquired /hbase/online-snapshot/reached /hbase/online-snapshot/abort
2015-11-08 16:03:02,298 INFO  [master:16000.activeMasterManager] procedure.ZKProcedureUtil: Clearing all procedure znodes: /hbase/flush-table-proc/acquired /hbase/flush-table-proc/reached /hbase/flush-table-proc/abort
2015-11-08 16:03:02,328 INFO  [master:16000.activeMasterManager] master.MasterCoprocessorHost: System coprocessor loading is enabled
2015-11-08 16:03:02,344 INFO  [master:16000.activeMasterManager] procedure2.ProcedureExecutor: Starting procedure executor threads=5
2015-11-08 16:03:02,345 INFO  [master:16000.activeMasterManager] wal.WALProcedureStore: Starting WAL Procedure Store lease recovery
2015-11-08 16:03:02,350 INFO  [master:16000.activeMasterManager] util.FSHDFSUtils: Recovering lease on dfs file hdfs://192.168.1.101:9000/hbase/MasterProcWALs/state-00000000000000000001.log
2015-11-08 16:03:02,357 INFO  [master:16000.activeMasterManager] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://192.168.1.101:9000/hbase/MasterProcWALs/state-00000000000000000001.log after 6ms
2015-11-08 16:03:02,366 INFO  [master:16000.activeMasterManager] util.FSHDFSUtils: Recovering lease on dfs file hdfs://192.168.1.101:9000/hbase/MasterProcWALs/state-00000000000000000002.log
2015-11-08 16:03:02,367 INFO  [master:16000.activeMasterManager] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://192.168.1.101:9000/hbase/MasterProcWALs/state-00000000000000000002.log after 1ms
2015-11-08 16:03:02,429 INFO  [master:16000.activeMasterManager] wal.WALProcedureStore: Lease acquired for flushLogId: 3
2015-11-08 16:03:02,434 INFO  [master:16000.activeMasterManager] wal.ProcedureWALFormatReader: No active entry found in state log hdfs://192.168.1.101:9000/hbase/MasterProcWALs/state-00000000000000000002.log. removing it
2015-11-08 16:03:02,497 INFO  [master:16000.activeMasterManager] zookeeper.RecoverableZooKeeper: Process identifier=replicationLogCleaner connecting to ZooKeeper ensemble=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181
2015-11-08 16:03:02,497 INFO  [master:16000.activeMasterManager] zookeeper.ZooKeeper: Initiating client connection, connectString=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181 sessionTimeout=90000 watcher=replicationLogCleaner0x0, quorum=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181, baseZNode=/hbase
2015-11-08 16:03:02,505 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.101/192.168.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 16:03:02,505 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.101/192.168.1.101:2181, initiating session
2015-11-08 16:03:02,515 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.101/192.168.1.101:2181, sessionid = 0x50e61e9e6a0001, negotiated timeout = 90000
2015-11-08 16:03:02,532 INFO  [master:16000.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 0 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2015-11-08 16:03:03,015 INFO  [PriorityRpcServer.handler=0,queue=0,port=16000] master.ServerManager: Registering server=master,16020,1446969780781
2015-11-08 16:03:03,033 INFO  [master:16000.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 1, slept for 501 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2015-11-08 16:03:03,725 WARN  [PriorityRpcServer.handler=2,queue=0,port=16000] master.ServerManager: Server slave2,16020,1446927337154 has been rejected; Reported time is too far out of sync with master.  Time difference of 42444088ms > max allowed of 30000ms
2015-11-08 16:03:03,786 ERROR [PriorityRpcServer.handler=4,queue=0,port=16000] master.MasterRpcServices: Region server slave2,16020,1446927337154 reported a fatal error:
ABORTING region server slave2,16020,1446927337154: Unhandled: org.apache.hadoop.hbase.ClockOutOfSyncException: Server slave2,16020,1446927337154 has been rejected; Reported time is too far out of sync with master.  Time difference of 42444088ms > max allowed of 30000ms
	at org.apache.hadoop.hbase.master.ServerManager.checkClockSkew(ServerManager.java:388)
	at org.apache.hadoop.hbase.master.ServerManager.regionServerStartup(ServerManager.java:262)
	at org.apache.hadoop.hbase.master.MasterRpcServices.regionServerStartup(MasterRpcServices.java:318)
	at org.apache.hadoop.hbase.protobuf.generated.RegionServerStatusProtos$RegionServerStatusService$2.callBlockingMethod(RegionServerStatusProtos.java:8615)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2114)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:101)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:130)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:107)
	at java.lang.Thread.run(Thread.java:745)

Cause:
org.apache.hadoop.hbase.ClockOutOfSyncException: org.apache.hadoop.hbase.ClockOutOfSyncException: Server slave2,16020,1446927337154 has been rejected; Reported time is too far out of sync with master.  Time difference of 42444088ms > max allowed of 30000ms
	at org.apache.hadoop.hbase.master.ServerManager.checkClockSkew(ServerManager.java:388)
	at org.apache.hadoop.hbase.master.ServerManager.regionServerStartup(ServerManager.java:262)
	at org.apache.hadoop.hbase.master.MasterRpcServices.regionServerStartup(MasterRpcServices.java:318)
	at org.apache.hadoop.hbase.protobuf.generated.RegionServerStatusProtos$RegionServerStatusService$2.callBlockingMethod(RegionServerStatusProtos.java:8615)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2114)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:101)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:130)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:107)
	at java.lang.Thread.run(Thread.java:745)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:95)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.getRemoteException(ProtobufUtil.java:325)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.reportForDuty(HRegionServer.java:2272)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:894)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hadoop.hbase.ipc.RemoteWithExtrasException(org.apache.hadoop.hbase.ClockOutOfSyncException): org.apache.hadoop.hbase.ClockOutOfSyncException: Server slave2,16020,1446927337154 has been rejected; Reported time is too far out of sync with master.  Time difference of 42444088ms > max allowed of 30000ms
	at org.apache.hadoop.hbase.master.ServerManager.checkClockSkew(ServerManager.java:388)
	at org.apache.hadoop.hbase.master.ServerManager.regionServerStartup(ServerManager.java:262)
	at org.apache.hadoop.hbase.master.MasterRpcServices.regionServerStartup(MasterRpcServices.java:318)
	at org.apache.hadoop.hbase.protobuf.generated.RegionServerStatusProtos$RegionServerStatusService$2.callBlockingMethod(RegionServerStatusProtos.java:8615)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2114)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:101)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:130)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:107)
	at java.lang.Thread.run(Thread.java:745)

	at org.apache.hadoop.hbase.ipc.RpcClientImpl.call(RpcClientImpl.java:1248)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.callBlockingMethod(AbstractRpcClient.java:213)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$BlockingRpcChannelImplementation.callBlockingMethod(AbstractRpcClient.java:287)
	at org.apache.hadoop.hbase.protobuf.generated.RegionServerStatusProtos$RegionServerStatusService$BlockingStub.regionServerStartup(RegionServerStatusProtos.java:8982)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.reportForDuty(HRegionServer.java:2270)
	... 2 more

2015-11-08 16:03:04,078 INFO  [main-EventThread] zookeeper.RegionServerTracker: RegionServer ephemeral node deleted, processing expiration [slave2,16020,1446927337154]
2015-11-08 16:03:04,079 WARN  [main-EventThread] zookeeper.RegionServerTracker: slave2,16020,1446927337154 is not online or isn't known to the master.The latter could be caused by a DNS misconfiguration.
2015-11-08 16:03:04,094 INFO  [PriorityRpcServer.handler=1,queue=1,port=16000] master.ServerManager: Registering server=slave1,16020,1446969781083
2015-11-08 16:03:04,135 INFO  [master:16000.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 2, slept for 1603 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2015-11-08 16:03:05,638 INFO  [master:16000.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 2, slept for 3106 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2015-11-08 16:03:07,042 INFO  [master:16000.activeMasterManager] master.ServerManager: Finished waiting for region servers count to settle; checked in 2, slept for 4510 ms, expecting minimum of 1, maximum of 2147483647, master is running
2015-11-08 16:03:07,054 INFO  [master:16000.activeMasterManager] master.MasterFileSystem: Log folder hdfs://192.168.1.101:9000/hbase/WALs/master,16020,1446969780781 belongs to an existing region server
2015-11-08 16:03:07,057 INFO  [master:16000.activeMasterManager] master.MasterFileSystem: Log folder hdfs://192.168.1.101:9000/hbase/WALs/slave1,16020,1446969781083 belongs to an existing region server
2015-11-08 16:03:07,181 INFO  [master:16000.activeMasterManager] zookeeper.MetaTableLocator: Failed verification of hbase:meta,,1 at address=master,16020,1446969328252, exception=org.apache.hadoop.hbase.NotServingRegionException: Region hbase:meta,,1 is not online on master,16020,1446969780781
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2898)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.getRegion(RSRpcServices.java:947)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.getRegionInfo(RSRpcServices.java:1232)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$2.callBlockingMethod(AdminProtos.java:22233)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2114)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:101)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:130)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:107)
	at java.lang.Thread.run(Thread.java:745)

2015-11-08 16:03:07,203 INFO  [master:16000.activeMasterManager] master.SplitLogManager: dead splitlog workers [master,16020,1446969328252]
2015-11-08 16:03:07,209 INFO  [master:16000.activeMasterManager] master.SplitLogManager: hdfs://192.168.1.101:9000/hbase/WALs/master,16020,1446969328252-splitting is empty dir, no logs to split
2015-11-08 16:03:07,210 INFO  [master:16000.activeMasterManager] master.SplitLogManager: started splitting 0 logs in [hdfs://192.168.1.101:9000/hbase/WALs/master,16020,1446969328252-splitting] for [master,16020,1446969328252]
2015-11-08 16:03:07,217 INFO  [master:16000.activeMasterManager] master.SplitLogManager: finished splitting (more than or equal to) 0 bytes in 0 log files in [hdfs://192.168.1.101:9000/hbase/WALs/master,16020,1446969328252-splitting] in 7ms
2015-11-08 16:03:07,217 INFO  [master:16000.activeMasterManager] zookeeper.MetaTableLocator: Deleting hbase:meta region location in ZooKeeper
2015-11-08 16:03:07,294 INFO  [master:16000.activeMasterManager] master.AssignmentManager: Assigning hbase:meta,,1.1588230740 to slave1,16020,1446969781083
2015-11-08 16:03:07,294 INFO  [master:16000.activeMasterManager] master.RegionStates: Transition {1588230740 state=OFFLINE, ts=1446969787266, server=null} to {1588230740 state=PENDING_OPEN, ts=1446969787294, server=slave1,16020,1446969781083}
2015-11-08 16:03:07,417 INFO  [master:16000.activeMasterManager] master.ServerManager: AssignmentManager hasn't finished failover cleanup; waiting
2015-11-08 16:03:07,463 INFO  [AM.ZK.Worker-pool2-t1] master.RegionStates: Transition {1588230740 state=PENDING_OPEN, ts=1446969787294, server=slave1,16020,1446969781083} to {1588230740 state=OPENING, ts=1446969787463, server=slave1,16020,1446969781083}
2015-11-08 16:03:08,252 INFO  [AM.ZK.Worker-pool2-t2] master.RegionStates: Transition {1588230740 state=OPENING, ts=1446969787463, server=slave1,16020,1446969781083} to {1588230740 state=OPEN, ts=1446969788252, server=slave1,16020,1446969781083}
2015-11-08 16:03:08,255 INFO  [AM.ZK.Worker-pool2-t2] coordination.ZkOpenRegionCoordination: Handling OPENED of 1588230740 from master,16000,1446969779177; deleting unassigned node
2015-11-08 16:03:08,279 INFO  [master:16000.activeMasterManager] master.HMaster: hbase:meta with replicaId 0 assigned=1, rit=false, location=slave1,16020,1446969781083
2015-11-08 16:03:08,459 INFO  [master:16000.activeMasterManager] hbase.MetaMigrationConvertingToPB: META already up-to date with PB serialization
2015-11-08 16:03:08,497 INFO  [master:16000.activeMasterManager] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=OPEN, ts=1446969788497, server=master,16020,1446969328252} to {6f3d653b8b106cc2df931825f52d6dec state=OFFLINE, ts=1446969788497, server=master,16020,1446969328252}
2015-11-08 16:03:08,505 INFO  [master:16000.activeMasterManager] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=OFFLINE, ts=1446969788497, server=master,16020,1446969328252} to {6f3d653b8b106cc2df931825f52d6dec state=CLOSED, ts=1446969788505, server=master,16020,1446969328252}
2015-11-08 16:03:08,508 INFO  [master:16000.activeMasterManager] master.AssignmentManager: Clean cluster startup. Assigning user regions
2015-11-08 16:03:08,521 INFO  [master:16000.activeMasterManager] balancer.BaseLoadBalancer: Reassigned 1 regions. 1 retained the pre-restart assignment. 
2015-11-08 16:03:08,521 INFO  [master:16000.activeMasterManager] master.AssignmentManager: Assigning 1 region(s) to master,16020,1446969780781
2015-11-08 16:03:08,523 INFO  [master:16000.activeMasterManager] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=CLOSED, ts=1446969788505, server=master,16020,1446969328252} to {6f3d653b8b106cc2df931825f52d6dec state=OFFLINE, ts=1446969788523, server=master,16020,1446969328252}
2015-11-08 16:03:08,544 INFO  [master:16000.activeMasterManager] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=OFFLINE, ts=1446969788523, server=master,16020,1446969328252} to {6f3d653b8b106cc2df931825f52d6dec state=PENDING_OPEN, ts=1446969788544, server=master,16020,1446969780781}
2015-11-08 16:03:08,631 INFO  [master:16000.activeMasterManager] master.AssignmentManager: Joined the cluster in 172ms, failover=false
2015-11-08 16:03:08,674 INFO  [AM.ZK.Worker-pool2-t5] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=PENDING_OPEN, ts=1446969788544, server=master,16020,1446969780781} to {6f3d653b8b106cc2df931825f52d6dec state=OPENING, ts=1446969788674, server=master,16020,1446969780781}
2015-11-08 16:03:09,194 INFO  [AM.ZK.Worker-pool2-t6] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=OPENING, ts=1446969788674, server=master,16020,1446969780781} to {6f3d653b8b106cc2df931825f52d6dec state=OPEN, ts=1446969789193, server=master,16020,1446969780781}
2015-11-08 16:03:09,211 INFO  [AM.ZK.Worker-pool2-t8] master.RegionStates: Offlined 6f3d653b8b106cc2df931825f52d6dec from master,16020,1446969328252
2015-11-08 16:03:09,441 INFO  [master:16000.activeMasterManager] master.HMaster: Master has completed initialization
2015-11-08 16:03:09,448 INFO  [master:16000.activeMasterManager] quotas.MasterQuotaManager: Quota support disabled
Sun Nov  8 16:06:29 CST 2015 Stopping hbase (via master)
2015-11-08 16:06:31,884 INFO  [B.defaultRpcServer.handler=1,queue=1,port=16000] master.MasterRpcServices: Client=hadoop/null shutdown
2015-11-08 16:06:31,884 INFO  [B.defaultRpcServer.handler=1,queue=1,port=16000] regionserver.HRegionServer: STOPPED: Cluster shutdown requested
2015-11-08 16:06:31,884 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: Stopping infoServer
2015-11-08 16:06:31,886 INFO  [master/master/192.168.1.101:16000] mortbay.log: Stopped SelectChannelConnector@0.0.0.0:16010
2015-11-08 16:06:31,987 INFO  [master/master/192.168.1.101:16000] procedure2.ProcedureExecutor: Stopping the procedure executor
2015-11-08 16:06:31,987 INFO  [master/master/192.168.1.101:16000] wal.WALProcedureStore: Stopping the WAL Procedure Store
2015-11-08 16:06:32,082 INFO  [master,16000,1446969779177_splitLogManager__ChoreService_1] master.SplitLogManager$TimeoutMonitor: Chore: SplitLogManager Timeout Monitor was stopped
2015-11-08 16:06:32,129 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: stopping server master,16000,1446969779177
2015-11-08 16:06:32,129 INFO  [master/master/192.168.1.101:16000] client.ConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x150e61e9e520000
2015-11-08 16:06:32,140 INFO  [master/master/192.168.1.101:16000] zookeeper.ZooKeeper: Session: 0x150e61e9e520000 closed
2015-11-08 16:06:32,140 INFO  [master/master/192.168.1.101:16000-EventThread] zookeeper.ClientCnxn: EventThread shut down
2015-11-08 16:06:32,140 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: stopping server master,16000,1446969779177; all regions closed.
2015-11-08 16:06:32,141 INFO  [master/master/192.168.1.101:16000] hbase.ChoreService: Chore service for: master,16000,1446969779177 had [[ScheduledChore: Name: CatalogJanitor-master:16000 Period: 300000 Unit: MILLISECONDS], [ScheduledChore: Name: master,16000,1446969779177-ClusterStatusChore Period: 60000 Unit: MILLISECONDS], [ScheduledChore: Name: HFileCleaner Period: 60000 Unit: MILLISECONDS], [ScheduledChore: Name: master,16000,1446969779177-BalancerChore Period: 300000 Unit: MILLISECONDS], [ScheduledChore: Name: LogsCleaner Period: 60000 Unit: MILLISECONDS]] on shutdown
2015-11-08 16:06:32,141 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave1,16020,1446969781083, master,16020,1446969780781
2015-11-08 16:06:33,162 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave1,16020,1446969781083, master,16020,1446969780781
2015-11-08 16:06:34,183 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave1,16020,1446969781083, master,16020,1446969780781
2015-11-08 16:06:35,203 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave1,16020,1446969781083, master,16020,1446969780781
2015-11-08 16:06:36,223 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave1,16020,1446969781083, master,16020,1446969780781
2015-11-08 16:06:37,244 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave1,16020,1446969781083, master,16020,1446969780781
2015-11-08 16:06:38,264 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave1,16020,1446969781083, master,16020,1446969780781
2015-11-08 16:06:39,285 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave1,16020,1446969781083, master,16020,1446969780781
2015-11-08 16:06:40,305 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave1,16020,1446969781083, master,16020,1446969780781
2015-11-08 16:06:41,325 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave1,16020,1446969781083, master,16020,1446969780781
2015-11-08 16:06:42,344 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave1,16020,1446969781083, master,16020,1446969780781
2015-11-08 16:06:43,364 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave1,16020,1446969781083, master,16020,1446969780781
2015-11-08 16:06:43,891 INFO  [main-EventThread] zookeeper.RegionServerTracker: RegionServer ephemeral node deleted, processing expiration [master,16020,1446969780781]
2015-11-08 16:06:43,892 INFO  [main-EventThread] master.ServerManager: Cluster shutdown set; master,16020,1446969780781 expired; onlineServers=1
2015-11-08 16:06:44,401 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave1,16020,1446969781083
2015-11-08 16:06:44,831 INFO  [main-EventThread] zookeeper.RegionServerTracker: RegionServer ephemeral node deleted, processing expiration [slave1,16020,1446969781083]
2015-11-08 16:06:44,832 INFO  [main-EventThread] master.ServerManager: Cluster shutdown set; slave1,16020,1446969781083 expired; onlineServers=0
2015-11-08 16:06:44,857 INFO  [master/master/192.168.1.101:16000] client.ConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x150e61e9e520001
2015-11-08 16:06:44,865 INFO  [master/master/192.168.1.101:16000] zookeeper.ZooKeeper: Session: 0x150e61e9e520001 closed
2015-11-08 16:06:44,865 INFO  [master:16000.activeMasterManager-EventThread] zookeeper.ClientCnxn: EventThread shut down
2015-11-08 16:06:44,865 INFO  [master/master/192.168.1.101:16000] hbase.ChoreService: Chore service for: master,16000,1446969779177_splitLogManager_ had [] on shutdown
2015-11-08 16:06:44,865 INFO  [master/master/192.168.1.101:16000] flush.MasterFlushTableProcedureManager: stop: server shutting down.
2015-11-08 16:06:44,865 INFO  [master/master/192.168.1.101:16000] ipc.RpcServer: Stopping server on 16000
2015-11-08 16:06:44,866 INFO  [RpcServer.listener,port=16000] ipc.RpcServer: RpcServer.listener,port=16000: stopping
2015-11-08 16:06:44,866 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopped
2015-11-08 16:06:44,866 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopping
2015-11-08 16:06:44,881 INFO  [master/master/192.168.1.101:16000] zookeeper.RecoverableZooKeeper: Node /hbase/rs/master,16000,1446969779177 already deleted, retry=false
2015-11-08 16:06:44,890 INFO  [master/master/192.168.1.101:16000] zookeeper.ZooKeeper: Session: 0x250e396fa1b0001 closed
2015-11-08 16:06:44,890 INFO  [main-EventThread] zookeeper.ClientCnxn: EventThread shut down
2015-11-08 16:06:44,890 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: stopping server master,16000,1446969779177; zookeeper connection closed.
2015-11-08 16:06:44,890 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: master/master/192.168.1.101:16000 exiting
Sun Nov  8 16:06:59 CST 2015 Starting master on master
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 30141
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 10240
cpu time               (seconds, -t) unlimited
max user processes              (-u) 1024
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2015-11-08 16:07:00,119 INFO  [main] util.VersionInfo: HBase 1.1.2
2015-11-08 16:07:00,120 INFO  [main] util.VersionInfo: Source code repository git://hw11397.local/Volumes/hbase-1.1.2RC2/hbase revision=cc2b70cf03e3378800661ec5cab11eb43fafe0fc
2015-11-08 16:07:00,120 INFO  [main] util.VersionInfo: Compiled by ndimiduk on Wed Aug 26 20:11:27 PDT 2015
2015-11-08 16:07:00,120 INFO  [main] util.VersionInfo: From source with checksum 73da41f3d1b867b7aba6166c77fafc17
2015-11-08 16:07:00,481 INFO  [main] util.ServerCommandLine: env:TERM=xterm
2015-11-08 16:07:00,481 INFO  [main] util.ServerCommandLine: env:HADOOP_COMMON_LIB_NATIVE_DIR=/opt/hadoop/lib/native
2015-11-08 16:07:00,481 INFO  [main] util.ServerCommandLine: env:IMSETTINGS_MODULE=none
2015-11-08 16:07:00,481 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/opt/java
2015-11-08 16:07:00,481 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/opt/hbase/bin/..
2015-11-08 16:07:00,481 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2015-11-08 16:07:00,481 INFO  [main] util.ServerCommandLine: env:SESSION_MANAGER=local/unix:@/tmp/.ICE-unix/2995,unix/unix:/tmp/.ICE-unix/2995
2015-11-08 16:07:00,482 INFO  [main] util.ServerCommandLine: env:IMSETTINGS_INTEGRATE_DESKTOP=yes
2015-11-08 16:07:00,482 INFO  [main] util.ServerCommandLine: env:GNOME_DESKTOP_SESSION_ID=this-is-deprecated
2015-11-08 16:07:00,482 INFO  [main] util.ServerCommandLine: env:MAIL=/var/spool/mail/hadoop
2015-11-08 16:07:00,482 INFO  [main] util.ServerCommandLine: env:XDG_SESSION_COOKIE=ab8c9d4f5491283c7c300d7800000013-1446958848.52338-1725977001
2015-11-08 16:07:00,482 INFO  [main] util.ServerCommandLine: env:GDMSESSION=gnome
2015-11-08 16:07:00,482 INFO  [main] util.ServerCommandLine: env:HOSTNAME=master
2015-11-08 16:07:00,482 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/tmp/hbase-hadoop-master.znode
2015-11-08 16:07:00,482 INFO  [main] util.ServerCommandLine: env:PWD=/opt/hbase/bin
2015-11-08 16:07:00,482 INFO  [main] util.ServerCommandLine: env:HBASE_MASTER_OPTS= -XX:PermSize=128m -XX:MaxPermSize=128m
2015-11-08 16:07:00,482 INFO  [main] util.ServerCommandLine: env:CVS_RSH=ssh
2015-11-08 16:07:00,482 INFO  [main] util.ServerCommandLine: env:JAVA_LIBRARY_PATH=/opt/hadoop/lib/native::/opt/hadoop/lib/native:
2015-11-08 16:07:00,482 INFO  [main] util.ServerCommandLine: env:G_BROKEN_FILENAMES=1
2015-11-08 16:07:00,482 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2015-11-08 16:07:00,482 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2015-11-08 16:07:00,482 INFO  [main] util.ServerCommandLine: env:NLSPATH=/usr/dt/lib/nls/msg/%L/%N.cat
2015-11-08 16:07:00,483 INFO  [main] util.ServerCommandLine: env:GNOME_KEYRING_SOCKET=/tmp/keyring-IruJ62/socket
2015-11-08 16:07:00,483 INFO  [main] util.ServerCommandLine: env:GDM_KEYBOARD_LAYOUT=us
2015-11-08 16:07:00,483 INFO  [main] util.ServerCommandLine: env:HBASE_REGIONSERVER_OPTS= -XX:PermSize=128m -XX:MaxPermSize=128m
2015-11-08 16:07:00,483 INFO  [main] util.ServerCommandLine: env:HISTSIZE=1000
2015-11-08 16:07:00,483 INFO  [main] util.ServerCommandLine: env:PATH=/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin:/sbin:/opt/java//bin:/opt/java/jre/bin:/opt/hadoop/bin:/home/hadoop/bin
2015-11-08 16:07:00,483 INFO  [main] util.ServerCommandLine: env:QTLIB=/usr/lib64/qt-3.3/lib
2015-11-08 16:07:00,483 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2015-11-08 16:07:00,483 INFO  [main] util.ServerCommandLine: env:GDM_LANG=en_US.UTF-8
2015-11-08 16:07:00,483 INFO  [main] util.ServerCommandLine: env:XAUTHORITY=/var/run/gdm/auth-for-hadoop-akmkFp/database
2015-11-08 16:07:00,483 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/tmp/hbase-hadoop-master.autorestart
2015-11-08 16:07:00,483 INFO  [main] util.ServerCommandLine: env:USERNAME=hadoop
2015-11-08 16:07:00,483 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-hadoop-master-master.log
2015-11-08 16:07:00,483 INFO  [main] util.ServerCommandLine: env:SSH_ASKPASS=/usr/libexec/openssh/gnome-ssh-askpass
2015-11-08 16:07:00,483 INFO  [main] util.ServerCommandLine: env:SHLVL=5
2015-11-08 16:07:00,483 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/opt/hbase/bin/../logs
2015-11-08 16:07:00,484 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-XX:+UseConcMarkSweepGC   -XX:PermSize=128m -XX:MaxPermSize=128m -Dhbase.log.dir=/opt/hbase/bin/../logs -Dhbase.log.file=hbase-hadoop-master-master.log -Dhbase.home.dir=/opt/hbase/bin/.. -Dhbase.id.str=hadoop -Dhbase.root.logger=INFO,RFA -Djava.library.path=/opt/hadoop/lib/native::/opt/hadoop/lib/native: -Dhbase.security.logger=INFO,RFAS
2015-11-08 16:07:00,484 INFO  [main] util.ServerCommandLine: env:XFILESEARCHPATH=/usr/dt/app-defaults/%L/Dt
2015-11-08 16:07:00,484 INFO  [main] util.ServerCommandLine: env:COLORTERM=gnome-terminal
2015-11-08 16:07:00,484 INFO  [main] util.ServerCommandLine: env:QT_IM_MODULE=xim
2015-11-08 16:07:00,484 INFO  [main] util.ServerCommandLine: env:WINDOWID=20979824
2015-11-08 16:07:00,484 INFO  [main] util.ServerCommandLine: env:LOGNAME=hadoop
2015-11-08 16:07:00,484 INFO  [main] util.ServerCommandLine: env:QTDIR=/usr/lib64/qt-3.3
2015-11-08 16:07:00,484 INFO  [main] util.ServerCommandLine: env:XMODIFIERS=@im=none
2015-11-08 16:07:00,484 INFO  [main] util.ServerCommandLine: env:SSH_AUTH_SOCK=/tmp/keyring-IruJ62/socket.ssh
2015-11-08 16:07:00,484 INFO  [main] util.ServerCommandLine: env:HADOOP_HOME=/opt/hadoop
2015-11-08 16:07:00,484 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=:/opt/hadoop/lib/native::/opt/hadoop/lib/native:
2015-11-08 16:07:00,484 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2015-11-08 16:07:00,484 INFO  [main] util.ServerCommandLine: env:HADOOP_OPTS=-Djava.library.path=/opt/hadoop/lib/native
2015-11-08 16:07:00,484 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2015-11-08 16:07:00,484 INFO  [main] util.ServerCommandLine: env:DBUS_SESSION_BUS_ADDRESS=unix:abstract=/tmp/dbus-uqNe1cANDo,guid=eca351d0636069d92d6d2f1900000495
2015-11-08 16:07:00,485 INFO  [main] util.ServerCommandLine: env:GNOME_KEYRING_PID=2985
2015-11-08 16:07:00,485 INFO  [main] util.ServerCommandLine: env:GTK_RC_FILES=/etc/gtk/gtkrc:/home/hadoop/.gtkrc-1.2-gnome2
2015-11-08 16:07:00,485 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2015-11-08 16:07:00,486 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/opt/hbase/bin/../conf:/opt/java/lib/tools.jar:/opt/hbase/bin/..:/opt/hbase/bin/../lib/activation-1.1.jar:/opt/hbase/bin/../lib/aopalliance-1.0.jar:/opt/hbase/bin/../lib/apacheds-i18n-2.0.0-M15.jar:/opt/hbase/bin/../lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hbase/bin/../lib/api-asn1-api-1.0.0-M20.jar:/opt/hbase/bin/../lib/api-util-1.0.0-M20.jar:/opt/hbase/bin/../lib/asm-3.1.jar:/opt/hbase/bin/../lib/avro-1.7.4.jar:/opt/hbase/bin/../lib/commons-beanutils-1.7.0.jar:/opt/hbase/bin/../lib/commons-beanutils-core-1.8.0.jar:/opt/hbase/bin/../lib/commons-cli-1.2.jar:/opt/hbase/bin/../lib/commons-codec-1.9.jar:/opt/hbase/bin/../lib/commons-collections-3.2.1.jar:/opt/hbase/bin/../lib/commons-compress-1.4.1.jar:/opt/hbase/bin/../lib/commons-configuration-1.6.jar:/opt/hbase/bin/../lib/commons-daemon-1.0.13.jar:/opt/hbase/bin/../lib/commons-digester-1.8.jar:/opt/hbase/bin/../lib/commons-el-1.0.jar:/opt/hbase/bin/../lib/commons-httpclient-3.1.jar:/opt/hbase/bin/../lib/commons-io-2.4.jar:/opt/hbase/bin/../lib/commons-lang-2.6.jar:/opt/hbase/bin/../lib/commons-logging-1.2.jar:/opt/hbase/bin/../lib/commons-math-2.2.jar:/opt/hbase/bin/../lib/commons-math3-3.1.1.jar:/opt/hbase/bin/../lib/commons-net-3.1.jar:/opt/hbase/bin/../lib/disruptor-3.3.0.jar:/opt/hbase/bin/../lib/findbugs-annotations-1.3.9-1.jar:/opt/hbase/bin/../lib/guava-12.0.1.jar:/opt/hbase/bin/../lib/guice-3.0.jar:/opt/hbase/bin/../lib/guice-servlet-3.0.jar:/opt/hbase/bin/../lib/hadoop-annotations-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-auth-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-client-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-common-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-hdfs-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-app-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-common-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-core-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-jobclient-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-shuffle-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-api-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-client-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-common-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-server-common-2.5.1.jar:/opt/hbase/bin/../lib/hbase-annotations-1.1.2.jar:/opt/hbase/bin/../lib/hbase-annotations-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-client-1.1.2.jar:/opt/hbase/bin/../lib/hbase-common-1.1.2.jar:/opt/hbase/bin/../lib/hbase-common-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-examples-1.1.2.jar:/opt/hbase/bin/../lib/hbase-hadoop2-compat-1.1.2.jar:/opt/hbase/bin/../lib/hbase-hadoop-compat-1.1.2.jar:/opt/hbase/bin/../lib/hbase-it-1.1.2.jar:/opt/hbase/bin/../lib/hbase-it-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-prefix-tree-1.1.2.jar:/opt/hbase/bin/../lib/hbase-procedure-1.1.2.jar:/opt/hbase/bin/../lib/hbase-protocol-1.1.2.jar:/opt/hbase/bin/../lib/hbase-resource-bundle-1.1.2.jar:/opt/hbase/bin/../lib/hbase-rest-1.1.2.jar:/opt/hbase/bin/../lib/hbase-server-1.1.2.jar:/opt/hbase/bin/../lib/hbase-server-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-shell-1.1.2.jar:/opt/hbase/bin/../lib/hbase-thrift-1.1.2.jar:/opt/hbase/bin/../lib/htrace-core-3.1.0-incubating.jar:/opt/hbase/bin/../lib/httpclient-4.2.5.jar:/opt/hbase/bin/../lib/httpcore-4.1.3.jar:/opt/hbase/bin/../lib/jackson-core-asl-1.9.13.jar:/opt/hbase/bin/../lib/jackson-jaxrs-1.9.13.jar:/opt/hbase/bin/../lib/jackson-mapper-asl-1.9.13.jar:/opt/hbase/bin/../lib/jackson-xc-1.9.13.jar:/opt/hbase/bin/../lib/jamon-runtime-2.3.1.jar:/opt/hbase/bin/../lib/jasper-compiler-5.5.23.jar:/opt/hbase/bin/../lib/jasper-runtime-5.5.23.jar:/opt/hbase/bin/../lib/javax.inject-1.jar:/opt/hbase/bin/../lib/java-xmlbuilder-0.4.jar:/opt/hbase/bin/../lib/jaxb-api-2.2.2.jar:/opt/hbase/bin/../lib/jaxb-impl-2.2.3-1.jar:/opt/hbase/bin/../lib/jcodings-1.0.8.jar:/opt/hbase/bin/../lib/jersey-client-1.9.jar:/opt/hbase/bin/../lib/jersey-core-1.9.jar:/opt/hbase/bin/../lib/jersey-guice-1.9.jar:/opt/hbase/bin/../lib/jersey-json-1.9.jar:/opt/hbase/bin/../lib/jersey-server-1.9.jar:/opt/hbase/bin/../lib/jets3t-0.9.0.jar:/opt/hbase/bin/../lib/jettison-1.3.3.jar:/opt/hbase/bin/../lib/jetty-6.1.26.jar:/opt/hbase/bin/../lib/jetty-sslengine-6.1.26.jar:/opt/hbase/bin/../lib/jetty-util-6.1.26.jar:/opt/hbase/bin/../lib/joni-2.1.2.jar:/opt/hbase/bin/../lib/jruby-complete-1.6.8.jar:/opt/hbase/bin/../lib/jsch-0.1.42.jar:/opt/hbase/bin/../lib/jsp-2.1-6.1.14.jar:/opt/hbase/bin/../lib/jsp-api-2.1-6.1.14.jar:/opt/hbase/bin/../lib/jsr305-1.3.9.jar:/opt/hbase/bin/../lib/junit-4.11.jar:/opt/hbase/bin/../lib/leveldbjni-all-1.8.jar:/opt/hbase/bin/../lib/libthrift-0.9.0.jar:/opt/hbase/bin/../lib/log4j-1.2.17.jar:/opt/hbase/bin/../lib/metrics-core-2.2.0.jar:/opt/hbase/bin/../lib/netty-3.2.4.Final.jar:/opt/hbase/bin/../lib/netty-all-4.0.23.Final.jar:/opt/hbase/bin/../lib/paranamer-2.3.jar:/opt/hbase/bin/../lib/protobuf-java-2.5.0.jar:/opt/hbase/bin/../lib/servlet-api-2.5-6.1.14.jar:/opt/hbase/bin/../lib/servlet-api-2.5.jar:/opt/hbase/bin/../lib/slf4j-api-1.7.7.jar:/opt/hbase/bin/../lib/slf4j-log4j12-1.7.5.jar:/opt/hbase/bin/../lib/snappy-java-1.0.4.1.jar:/opt/hbase/bin/../lib/spymemcached-2.11.6.jar:/opt/hbase/bin/../lib/xmlenc-0.52.jar:/opt/hbase/bin/../lib/xz-1.0.jar:/opt/hbase/bin/../lib/zookeeper-3.4.6.jar:/opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/contrib/capacity-scheduler/*.jar
2015-11-08 16:07:00,486 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2015-11-08 16:07:00,486 INFO  [main] util.ServerCommandLine: env:JRE_HOME=/opt/java/jre
2015-11-08 16:07:00,486 INFO  [main] util.ServerCommandLine: env:DESKTOP_SESSION=gnome
2015-11-08 16:07:00,486 INFO  [main] util.ServerCommandLine: env:QTINC=/usr/lib64/qt-3.3/include
2015-11-08 16:07:00,486 INFO  [main] util.ServerCommandLine: env:DISPLAY=192.168.1.100:2.0
2015-11-08 16:07:00,486 INFO  [main] util.ServerCommandLine: env:USER=hadoop
2015-11-08 16:07:00,486 INFO  [main] util.ServerCommandLine: env:HISTCONTROL=ignoredups
2015-11-08 16:07:00,486 INFO  [main] util.ServerCommandLine: env:HOME=/home/hadoop
2015-11-08 16:07:00,486 INFO  [main] util.ServerCommandLine: env:LESSOPEN=||/usr/bin/lesspipe.sh %s
2015-11-08 16:07:00,486 INFO  [main] util.ServerCommandLine: env:LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arj=01;31:*.taz=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lz=01;31:*.xz=01;31:*.bz2=01;31:*.tbz=01;31:*.tbz2=01;31:*.bz=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.rar=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
2015-11-08 16:07:00,487 INFO  [main] util.ServerCommandLine: env:ORBIT_SOCKETDIR=/tmp/orbit-hadoop
2015-11-08 16:07:00,487 INFO  [main] util.ServerCommandLine: env:LANG=en_US.UTF-8
2015-11-08 16:07:00,487 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-hadoop-master-master
2015-11-08 16:07:00,487 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=hadoop
2015-11-08 16:07:00,489 INFO  [main] util.ServerCommandLine: vmName=Java HotSpot(TM) 64-Bit Server VM, vmVendor=Oracle Corporation, vmVersion=24.79-b02
2015-11-08 16:07:00,489 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_master, -XX:OnOutOfMemoryError=kill -9 %p, -XX:+UseConcMarkSweepGC, -XX:PermSize=128m, -XX:MaxPermSize=128m, -Dhbase.log.dir=/opt/hbase/bin/../logs, -Dhbase.log.file=hbase-hadoop-master-master.log, -Dhbase.home.dir=/opt/hbase/bin/.., -Dhbase.id.str=hadoop, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=/opt/hadoop/lib/native::/opt/hadoop/lib/native:, -Dhbase.security.logger=INFO,RFAS]
2015-11-08 16:07:00,941 WARN  [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-11-08 16:07:01,197 INFO  [main] regionserver.RSRpcServices: master/master/192.168.1.101:16000 server-side HConnection retries=350
2015-11-08 16:07:01,432 INFO  [main] ipc.SimpleRpcScheduler: Using deadline as user call queue, count=3
2015-11-08 16:07:01,447 INFO  [main] ipc.RpcServer: master/master/192.168.1.101:16000: started 10 reader(s).
2015-11-08 16:07:01,514 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2015-11-08 16:07:01,572 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-11-08 16:07:01,572 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2015-11-08 16:07:02,472 INFO  [main] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2015-11-08 16:07:02,718 INFO  [main] zookeeper.RecoverableZooKeeper: Process identifier=master:16000 connecting to ZooKeeper ensemble=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181
2015-11-08 16:07:02,727 INFO  [main] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2015-11-08 16:07:02,727 INFO  [main] zookeeper.ZooKeeper: Client environment:host.name=master
2015-11-08 16:07:02,727 INFO  [main] zookeeper.ZooKeeper: Client environment:java.version=1.7.0_79
2015-11-08 16:07:02,727 INFO  [main] zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
2015-11-08 16:07:02,727 INFO  [main] zookeeper.ZooKeeper: Client environment:java.home=/opt/java/jre
2015-11-08 16:07:02,727 INFO  [main] zookeeper.ZooKeeper: Client environment:java.class.path=/opt/hbase/bin/../conf:/opt/java/lib/tools.jar:/opt/hbase/bin/..:/opt/hbase/bin/../lib/activation-1.1.jar:/opt/hbase/bin/../lib/aopalliance-1.0.jar:/opt/hbase/bin/../lib/apacheds-i18n-2.0.0-M15.jar:/opt/hbase/bin/../lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hbase/bin/../lib/api-asn1-api-1.0.0-M20.jar:/opt/hbase/bin/../lib/api-util-1.0.0-M20.jar:/opt/hbase/bin/../lib/asm-3.1.jar:/opt/hbase/bin/../lib/avro-1.7.4.jar:/opt/hbase/bin/../lib/commons-beanutils-1.7.0.jar:/opt/hbase/bin/../lib/commons-beanutils-core-1.8.0.jar:/opt/hbase/bin/../lib/commons-cli-1.2.jar:/opt/hbase/bin/../lib/commons-codec-1.9.jar:/opt/hbase/bin/../lib/commons-collections-3.2.1.jar:/opt/hbase/bin/../lib/commons-compress-1.4.1.jar:/opt/hbase/bin/../lib/commons-configuration-1.6.jar:/opt/hbase/bin/../lib/commons-daemon-1.0.13.jar:/opt/hbase/bin/../lib/commons-digester-1.8.jar:/opt/hbase/bin/../lib/commons-el-1.0.jar:/opt/hbase/bin/../lib/commons-httpclient-3.1.jar:/opt/hbase/bin/../lib/commons-io-2.4.jar:/opt/hbase/bin/../lib/commons-lang-2.6.jar:/opt/hbase/bin/../lib/commons-logging-1.2.jar:/opt/hbase/bin/../lib/commons-math-2.2.jar:/opt/hbase/bin/../lib/commons-math3-3.1.1.jar:/opt/hbase/bin/../lib/commons-net-3.1.jar:/opt/hbase/bin/../lib/disruptor-3.3.0.jar:/opt/hbase/bin/../lib/findbugs-annotations-1.3.9-1.jar:/opt/hbase/bin/../lib/guava-12.0.1.jar:/opt/hbase/bin/../lib/guice-3.0.jar:/opt/hbase/bin/../lib/guice-servlet-3.0.jar:/opt/hbase/bin/../lib/hadoop-annotations-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-auth-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-client-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-common-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-hdfs-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-app-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-common-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-core-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-jobclient-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-mapreduce-client-shuffle-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-api-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-client-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-common-2.5.1.jar:/opt/hbase/bin/../lib/hadoop-yarn-server-common-2.5.1.jar:/opt/hbase/bin/../lib/hbase-annotations-1.1.2.jar:/opt/hbase/bin/../lib/hbase-annotations-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-client-1.1.2.jar:/opt/hbase/bin/../lib/hbase-common-1.1.2.jar:/opt/hbase/bin/../lib/hbase-common-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-examples-1.1.2.jar:/opt/hbase/bin/../lib/hbase-hadoop2-compat-1.1.2.jar:/opt/hbase/bin/../lib/hbase-hadoop-compat-1.1.2.jar:/opt/hbase/bin/../lib/hbase-it-1.1.2.jar:/opt/hbase/bin/../lib/hbase-it-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-prefix-tree-1.1.2.jar:/opt/hbase/bin/../lib/hbase-procedure-1.1.2.jar:/opt/hbase/bin/../lib/hbase-protocol-1.1.2.jar:/opt/hbase/bin/../lib/hbase-resource-bundle-1.1.2.jar:/opt/hbase/bin/../lib/hbase-rest-1.1.2.jar:/opt/hbase/bin/../lib/hbase-server-1.1.2.jar:/opt/hbase/bin/../lib/hbase-server-1.1.2-tests.jar:/opt/hbase/bin/../lib/hbase-shell-1.1.2.jar:/opt/hbase/bin/../lib/hbase-thrift-1.1.2.jar:/opt/hbase/bin/../lib/htrace-core-3.1.0-incubating.jar:/opt/hbase/bin/../lib/httpclient-4.2.5.jar:/opt/hbase/bin/../lib/httpcore-4.1.3.jar:/opt/hbase/bin/../lib/jackson-core-asl-1.9.13.jar:/opt/hbase/bin/../lib/jackson-jaxrs-1.9.13.jar:/opt/hbase/bin/../lib/jackson-mapper-asl-1.9.13.jar:/opt/hbase/bin/../lib/jackson-xc-1.9.13.jar:/opt/hbase/bin/../lib/jamon-runtime-2.3.1.jar:/opt/hbase/bin/../lib/jasper-compiler-5.5.23.jar:/opt/hbase/bin/../lib/jasper-runtime-5.5.23.jar:/opt/hbase/bin/../lib/javax.inject-1.jar:/opt/hbase/bin/../lib/java-xmlbuilder-0.4.jar:/opt/hbase/bin/../lib/jaxb-api-2.2.2.jar:/opt/hbase/bin/../lib/jaxb-impl-2.2.3-1.jar:/opt/hbase/bin/../lib/jcodings-1.0.8.jar:/opt/hbase/bin/../lib/jersey-client-1.9.jar:/opt/hbase/bin/../lib/jersey-core-1.9.jar:/opt/hbase/bin/../lib/jersey-guice-1.9.jar:/opt/hbase/bin/../lib/jersey-json-1.9.jar:/opt/hbase/bin/../lib/jersey-server-1.9.jar:/opt/hbase/bin/../lib/jets3t-0.9.0.jar:/opt/hbase/bin/../lib/jettison-1.3.3.jar:/opt/hbase/bin/../lib/jetty-6.1.26.jar:/opt/hbase/bin/../lib/jetty-sslengine-6.1.26.jar:/opt/hbase/bin/../lib/jetty-util-6.1.26.jar:/opt/hbase/bin/../lib/joni-2.1.2.jar:/opt/hbase/bin/../lib/jruby-complete-1.6.8.jar:/opt/hbase/bin/../lib/jsch-0.1.42.jar:/opt/hbase/bin/../lib/jsp-2.1-6.1.14.jar:/opt/hbase/bin/../lib/jsp-api-2.1-6.1.14.jar:/opt/hbase/bin/../lib/jsr305-1.3.9.jar:/opt/hbase/bin/../lib/junit-4.11.jar:/opt/hbase/bin/../lib/leveldbjni-all-1.8.jar:/opt/hbase/bin/../lib/libthrift-0.9.0.jar:/opt/hbase/bin/../lib/log4j-1.2.17.jar:/opt/hbase/bin/../lib/metrics-core-2.2.0.jar:/opt/hbase/bin/../lib/netty-3.2.4.Final.jar:/opt/hbase/bin/../lib/netty-all-4.0.23.Final.jar:/opt/hbase/bin/../lib/paranamer-2.3.jar:/opt/hbase/bin/../lib/protobuf-java-2.5.0.jar:/opt/hbase/bin/../lib/servlet-api-2.5-6.1.14.jar:/opt/hbase/bin/../lib/servlet-api-2.5.jar:/opt/hbase/bin/../lib/slf4j-api-1.7.7.jar:/opt/hbase/bin/../lib/slf4j-log4j12-1.7.5.jar:/opt/hbase/bin/../lib/snappy-java-1.0.4.1.jar:/opt/hbase/bin/../lib/spymemcached-2.11.6.jar:/opt/hbase/bin/../lib/xmlenc-0.52.jar:/opt/hbase/bin/../lib/xz-1.0.jar:/opt/hbase/bin/../lib/zookeeper-3.4.6.jar:/opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-auth-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/opt/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/opt/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop/share/hadoop/common/lib/curator-framework-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/opt/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/opt/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop/share/hadoop/common/lib/curator-client-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/opt/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-annotations-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/opt/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop/share/hadoop/common/lib/htrace-core-3.0.4.jar:/opt/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop/share/hadoop/common/hadoop-common-2.6.0-tests.jar:/opt/hadoop/share/hadoop/common/hadoop-common-2.6.0.jar:/opt/hadoop/share/hadoop/common/hadoop-nfs-2.6.0.jar:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/opt/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.0-tests.jar:/opt/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jline-0.9.94.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-tests.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar
2015-11-08 16:07:02,727 INFO  [main] zookeeper.ZooKeeper: Client environment:java.library.path=/opt/hadoop/lib/native::/opt/hadoop/lib/native:
2015-11-08 16:07:02,727 INFO  [main] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2015-11-08 16:07:02,727 INFO  [main] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2015-11-08 16:07:02,727 INFO  [main] zookeeper.ZooKeeper: Client environment:os.name=Linux
2015-11-08 16:07:02,727 INFO  [main] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2015-11-08 16:07:02,727 INFO  [main] zookeeper.ZooKeeper: Client environment:os.version=2.6.32-573.el6.x86_64
2015-11-08 16:07:02,727 INFO  [main] zookeeper.ZooKeeper: Client environment:user.name=hadoop
2015-11-08 16:07:02,727 INFO  [main] zookeeper.ZooKeeper: Client environment:user.home=/home/hadoop
2015-11-08 16:07:02,727 INFO  [main] zookeeper.ZooKeeper: Client environment:user.dir=/opt/hbase/bin
2015-11-08 16:07:02,728 INFO  [main] zookeeper.ZooKeeper: Initiating client connection, connectString=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181 sessionTimeout=90000 watcher=master:160000x0, quorum=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181, baseZNode=/hbase
2015-11-08 16:07:02,748 INFO  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 16:07:02,752 INFO  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.102/192.168.1.102:2181, initiating session
2015-11-08 16:07:02,849 INFO  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.102/192.168.1.102:2181, sessionid = 0x150e622517c0000, negotiated timeout = 90000
2015-11-08 16:07:02,968 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2015-11-08 16:07:02,978 INFO  [RpcServer.listener,port=16000] ipc.RpcServer: RpcServer.listener,port=16000: starting
2015-11-08 16:07:03,159 INFO  [main] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-11-08 16:07:03,165 INFO  [main] http.HttpRequestLog: Http request log for http.requests.master is not defined
2015-11-08 16:07:03,181 INFO  [main] http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.hbase.http.HttpServer$QuotingInputFilter)
2015-11-08 16:07:03,185 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context master
2015-11-08 16:07:03,185 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-11-08 16:07:03,185 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-11-08 16:07:03,209 INFO  [main] http.HttpServer: Jetty bound to port 16010
2015-11-08 16:07:03,209 INFO  [main] mortbay.log: jetty-6.1.26
2015-11-08 16:07:03,929 INFO  [main] mortbay.log: Started SelectChannelConnector@0.0.0.0:16010
2015-11-08 16:07:03,934 INFO  [main] master.HMaster: hbase.rootdir=hdfs://192.168.1.101:9000/hbase, hbase.cluster.distributed=true
2015-11-08 16:07:03,951 INFO  [main] master.HMaster: Adding backup master ZNode /hbase/backup-masters/master,16000,1446970021587
2015-11-08 16:07:04,134 INFO  [master:16000.activeMasterManager] master.ActiveMasterManager: Deleting ZNode for /hbase/backup-masters/master,16000,1446970021587 from backup master directory
2015-11-08 16:07:04,150 INFO  [master:16000.activeMasterManager] master.ActiveMasterManager: Registered Active Master=master,16000,1446970021587
2015-11-08 16:07:04,264 INFO  [master/master/192.168.1.101:16000] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x279de6fb connecting to ZooKeeper ensemble=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181
2015-11-08 16:07:04,269 INFO  [master/master/192.168.1.101:16000] zookeeper.ZooKeeper: Initiating client connection, connectString=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181 sessionTimeout=90000 watcher=hconnection-0x279de6fb0x0, quorum=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181, baseZNode=/hbase
2015-11-08 16:07:04,272 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 16:07:04,280 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.106/192.168.1.106:2181, initiating session
2015-11-08 16:07:04,290 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.106/192.168.1.106:2181, sessionid = 0x250e39aad820001, negotiated timeout = 90000
2015-11-08 16:07:04,553 INFO  [master:16000.activeMasterManager] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2015-11-08 16:07:04,566 INFO  [master:16000.activeMasterManager] coordination.SplitLogManagerCoordination: Found 0 orphan tasks and 0 rescan nodes
2015-11-08 16:07:04,644 INFO  [master:16000.activeMasterManager] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x5d3cb19a connecting to ZooKeeper ensemble=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181
2015-11-08 16:07:04,644 INFO  [master:16000.activeMasterManager] zookeeper.ZooKeeper: Initiating client connection, connectString=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181 sessionTimeout=90000 watcher=hconnection-0x5d3cb19a0x0, quorum=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181, baseZNode=/hbase
2015-11-08 16:07:04,645 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 16:07:04,646 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.102/192.168.1.102:2181, initiating session
2015-11-08 16:07:04,657 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.102/192.168.1.102:2181, sessionid = 0x150e622517c0002, negotiated timeout = 90000
2015-11-08 16:07:04,697 INFO  [master:16000.activeMasterManager] balancer.StochasticLoadBalancer: loading config
2015-11-08 16:07:04,785 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: ClusterId : 18e4235c-98ec-4147-8ac4-00cf10508c80
2015-11-08 16:07:04,793 INFO  [master:16000.activeMasterManager] master.HMaster: Server active/primary master=master,16000,1446970021587, sessionid=0x150e622517c0000, setting cluster-up flag (Was=false)
2015-11-08 16:07:04,835 INFO  [master:16000.activeMasterManager] procedure.ZKProcedureUtil: Clearing all procedure znodes: /hbase/online-snapshot/acquired /hbase/online-snapshot/reached /hbase/online-snapshot/abort
2015-11-08 16:07:04,859 INFO  [master:16000.activeMasterManager] procedure.ZKProcedureUtil: Clearing all procedure znodes: /hbase/flush-table-proc/acquired /hbase/flush-table-proc/reached /hbase/flush-table-proc/abort
2015-11-08 16:07:04,894 INFO  [master:16000.activeMasterManager] master.MasterCoprocessorHost: System coprocessor loading is enabled
2015-11-08 16:07:04,910 INFO  [master:16000.activeMasterManager] procedure2.ProcedureExecutor: Starting procedure executor threads=5
2015-11-08 16:07:04,911 INFO  [master:16000.activeMasterManager] wal.WALProcedureStore: Starting WAL Procedure Store lease recovery
2015-11-08 16:07:04,916 INFO  [master:16000.activeMasterManager] util.FSHDFSUtils: Recovering lease on dfs file hdfs://192.168.1.101:9000/hbase/MasterProcWALs/state-00000000000000000001.log
2015-11-08 16:07:04,923 INFO  [master:16000.activeMasterManager] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://192.168.1.101:9000/hbase/MasterProcWALs/state-00000000000000000001.log after 6ms
2015-11-08 16:07:04,935 INFO  [master:16000.activeMasterManager] util.FSHDFSUtils: Recovering lease on dfs file hdfs://192.168.1.101:9000/hbase/MasterProcWALs/state-00000000000000000003.log
2015-11-08 16:07:04,936 INFO  [master:16000.activeMasterManager] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://192.168.1.101:9000/hbase/MasterProcWALs/state-00000000000000000003.log after 1ms
2015-11-08 16:07:04,988 INFO  [master:16000.activeMasterManager] wal.WALProcedureStore: Lease acquired for flushLogId: 4
2015-11-08 16:07:04,992 INFO  [master:16000.activeMasterManager] wal.ProcedureWALFormatReader: No active entry found in state log hdfs://192.168.1.101:9000/hbase/MasterProcWALs/state-00000000000000000003.log. removing it
2015-11-08 16:07:05,029 INFO  [master:16000.activeMasterManager] zookeeper.RecoverableZooKeeper: Process identifier=replicationLogCleaner connecting to ZooKeeper ensemble=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181
2015-11-08 16:07:05,029 INFO  [master:16000.activeMasterManager] zookeeper.ZooKeeper: Initiating client connection, connectString=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181 sessionTimeout=90000 watcher=replicationLogCleaner0x0, quorum=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181, baseZNode=/hbase
2015-11-08 16:07:05,029 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 16:07:05,030 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.102/192.168.1.102:2181, initiating session
2015-11-08 16:07:05,042 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.102/192.168.1.102:2181, sessionid = 0x150e622517c0003, negotiated timeout = 90000
2015-11-08 16:07:05,057 INFO  [master:16000.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 0 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2015-11-08 16:07:05,185 INFO  [PriorityRpcServer.handler=0,queue=0,port=16000] master.ServerManager: Registering server=master,16020,1446970022735
2015-11-08 16:07:05,207 INFO  [master:16000.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 1, slept for 150 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2015-11-08 16:07:05,924 WARN  [PriorityRpcServer.handler=1,queue=1,port=16000] master.ServerManager: Server slave2,16020,1446927579545 has been rejected; Reported time is too far out of sync with master.  Time difference of 42444006ms > max allowed of 30000ms
2015-11-08 16:07:05,984 ERROR [PriorityRpcServer.handler=6,queue=0,port=16000] master.MasterRpcServices: Region server slave2,16020,1446927579545 reported a fatal error:
ABORTING region server slave2,16020,1446927579545: Unhandled: org.apache.hadoop.hbase.ClockOutOfSyncException: Server slave2,16020,1446927579545 has been rejected; Reported time is too far out of sync with master.  Time difference of 42444006ms > max allowed of 30000ms
	at org.apache.hadoop.hbase.master.ServerManager.checkClockSkew(ServerManager.java:388)
	at org.apache.hadoop.hbase.master.ServerManager.regionServerStartup(ServerManager.java:262)
	at org.apache.hadoop.hbase.master.MasterRpcServices.regionServerStartup(MasterRpcServices.java:318)
	at org.apache.hadoop.hbase.protobuf.generated.RegionServerStatusProtos$RegionServerStatusService$2.callBlockingMethod(RegionServerStatusProtos.java:8615)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2114)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:101)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:130)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:107)
	at java.lang.Thread.run(Thread.java:745)

Cause:
org.apache.hadoop.hbase.ClockOutOfSyncException: org.apache.hadoop.hbase.ClockOutOfSyncException: Server slave2,16020,1446927579545 has been rejected; Reported time is too far out of sync with master.  Time difference of 42444006ms > max allowed of 30000ms
	at org.apache.hadoop.hbase.master.ServerManager.checkClockSkew(ServerManager.java:388)
	at org.apache.hadoop.hbase.master.ServerManager.regionServerStartup(ServerManager.java:262)
	at org.apache.hadoop.hbase.master.MasterRpcServices.regionServerStartup(MasterRpcServices.java:318)
	at org.apache.hadoop.hbase.protobuf.generated.RegionServerStatusProtos$RegionServerStatusService$2.callBlockingMethod(RegionServerStatusProtos.java:8615)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2114)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:101)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:130)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:107)
	at java.lang.Thread.run(Thread.java:745)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:95)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.getRemoteException(ProtobufUtil.java:325)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.reportForDuty(HRegionServer.java:2272)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:894)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hadoop.hbase.ipc.RemoteWithExtrasException(org.apache.hadoop.hbase.ClockOutOfSyncException): org.apache.hadoop.hbase.ClockOutOfSyncException: Server slave2,16020,1446927579545 has been rejected; Reported time is too far out of sync with master.  Time difference of 42444006ms > max allowed of 30000ms
	at org.apache.hadoop.hbase.master.ServerManager.checkClockSkew(ServerManager.java:388)
	at org.apache.hadoop.hbase.master.ServerManager.regionServerStartup(ServerManager.java:262)
	at org.apache.hadoop.hbase.master.MasterRpcServices.regionServerStartup(MasterRpcServices.java:318)
	at org.apache.hadoop.hbase.protobuf.generated.RegionServerStatusProtos$RegionServerStatusService$2.callBlockingMethod(RegionServerStatusProtos.java:8615)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2114)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:101)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:130)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:107)
	at java.lang.Thread.run(Thread.java:745)

	at org.apache.hadoop.hbase.ipc.RpcClientImpl.call(RpcClientImpl.java:1248)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.callBlockingMethod(AbstractRpcClient.java:213)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$BlockingRpcChannelImplementation.callBlockingMethod(AbstractRpcClient.java:287)
	at org.apache.hadoop.hbase.protobuf.generated.RegionServerStatusProtos$RegionServerStatusService$BlockingStub.regionServerStartup(RegionServerStatusProtos.java:8982)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.reportForDuty(HRegionServer.java:2270)
	... 2 more

2015-11-08 16:07:06,041 INFO  [main-EventThread] zookeeper.RegionServerTracker: RegionServer ephemeral node deleted, processing expiration [slave2,16020,1446927579545]
2015-11-08 16:07:06,041 WARN  [main-EventThread] zookeeper.RegionServerTracker: slave2,16020,1446927579545 is not online or isn't known to the master.The latter could be caused by a DNS misconfiguration.
2015-11-08 16:07:06,650 INFO  [PriorityRpcServer.handler=5,queue=1,port=16000] master.ServerManager: Registering server=slave1,16020,1446970023531
2015-11-08 16:07:06,660 INFO  [master:16000.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 2, slept for 1603 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2015-11-08 16:07:08,163 INFO  [master:16000.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 2, slept for 3106 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2015-11-08 16:07:09,567 INFO  [master:16000.activeMasterManager] master.ServerManager: Finished waiting for region servers count to settle; checked in 2, slept for 4510 ms, expecting minimum of 1, maximum of 2147483647, master is running
2015-11-08 16:07:09,574 INFO  [master:16000.activeMasterManager] master.MasterFileSystem: Log folder hdfs://192.168.1.101:9000/hbase/WALs/master,16020,1446970022735 belongs to an existing region server
2015-11-08 16:07:09,577 INFO  [master:16000.activeMasterManager] master.MasterFileSystem: Log folder hdfs://192.168.1.101:9000/hbase/WALs/slave1,16020,1446970023531 belongs to an existing region server
2015-11-08 16:07:09,721 INFO  [master:16000.activeMasterManager] zookeeper.MetaTableLocator: Failed verification of hbase:meta,,1 at address=slave1,16020,1446969781083, exception=org.apache.hadoop.hbase.NotServingRegionException: Region hbase:meta,,1 is not online on slave1,16020,1446970023531
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2898)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.getRegion(RSRpcServices.java:947)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.getRegionInfo(RSRpcServices.java:1232)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$2.callBlockingMethod(AdminProtos.java:22233)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2114)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:101)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:130)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:107)
	at java.lang.Thread.run(Thread.java:745)

2015-11-08 16:07:09,744 INFO  [master:16000.activeMasterManager] master.SplitLogManager: dead splitlog workers [slave1,16020,1446969781083]
2015-11-08 16:07:09,748 INFO  [master:16000.activeMasterManager] master.SplitLogManager: hdfs://192.168.1.101:9000/hbase/WALs/slave1,16020,1446969781083-splitting is empty dir, no logs to split
2015-11-08 16:07:09,750 INFO  [master:16000.activeMasterManager] master.SplitLogManager: started splitting 0 logs in [hdfs://192.168.1.101:9000/hbase/WALs/slave1,16020,1446969781083-splitting] for [slave1,16020,1446969781083]
2015-11-08 16:07:09,758 INFO  [master:16000.activeMasterManager] master.SplitLogManager: finished splitting (more than or equal to) 0 bytes in 0 log files in [hdfs://192.168.1.101:9000/hbase/WALs/slave1,16020,1446969781083-splitting] in 8ms
2015-11-08 16:07:09,758 INFO  [master:16000.activeMasterManager] zookeeper.MetaTableLocator: Deleting hbase:meta region location in ZooKeeper
2015-11-08 16:07:09,852 INFO  [master:16000.activeMasterManager] master.AssignmentManager: Assigning hbase:meta,,1.1588230740 to slave1,16020,1446970023531
2015-11-08 16:07:09,852 INFO  [master:16000.activeMasterManager] master.RegionStates: Transition {1588230740 state=OFFLINE, ts=1446970029819, server=null} to {1588230740 state=PENDING_OPEN, ts=1446970029852, server=slave1,16020,1446970023531}
2015-11-08 16:07:09,920 INFO  [master:16000.activeMasterManager] master.ServerManager: AssignmentManager hasn't finished failover cleanup; waiting
2015-11-08 16:07:09,978 INFO  [AM.ZK.Worker-pool2-t1] master.RegionStates: Transition {1588230740 state=PENDING_OPEN, ts=1446970029852, server=slave1,16020,1446970023531} to {1588230740 state=OPENING, ts=1446970029978, server=slave1,16020,1446970023531}
2015-11-08 16:07:10,878 INFO  [AM.ZK.Worker-pool2-t2] master.RegionStates: Transition {1588230740 state=OPENING, ts=1446970029978, server=slave1,16020,1446970023531} to {1588230740 state=OPEN, ts=1446970030878, server=slave1,16020,1446970023531}
2015-11-08 16:07:10,880 INFO  [AM.ZK.Worker-pool2-t2] coordination.ZkOpenRegionCoordination: Handling OPENED of 1588230740 from master,16000,1446970021587; deleting unassigned node
2015-11-08 16:07:10,903 INFO  [master:16000.activeMasterManager] master.HMaster: hbase:meta with replicaId 0 assigned=1, rit=false, location=slave1,16020,1446970023531
2015-11-08 16:07:11,045 INFO  [master:16000.activeMasterManager] hbase.MetaMigrationConvertingToPB: META already up-to date with PB serialization
2015-11-08 16:07:11,077 INFO  [master:16000.activeMasterManager] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=OPEN, ts=1446970031077, server=master,16020,1446969780781} to {6f3d653b8b106cc2df931825f52d6dec state=OFFLINE, ts=1446970031077, server=master,16020,1446969780781}
2015-11-08 16:07:11,083 INFO  [master:16000.activeMasterManager] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=OFFLINE, ts=1446970031077, server=master,16020,1446969780781} to {6f3d653b8b106cc2df931825f52d6dec state=CLOSED, ts=1446970031083, server=master,16020,1446969780781}
2015-11-08 16:07:11,086 INFO  [master:16000.activeMasterManager] master.AssignmentManager: Clean cluster startup. Assigning user regions
2015-11-08 16:07:11,100 INFO  [master:16000.activeMasterManager] balancer.BaseLoadBalancer: Reassigned 1 regions. 1 retained the pre-restart assignment. 
2015-11-08 16:07:11,100 INFO  [master:16000.activeMasterManager] master.AssignmentManager: Assigning 1 region(s) to master,16020,1446970022735
2015-11-08 16:07:11,102 INFO  [master:16000.activeMasterManager] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=CLOSED, ts=1446970031083, server=master,16020,1446969780781} to {6f3d653b8b106cc2df931825f52d6dec state=OFFLINE, ts=1446970031102, server=master,16020,1446969780781}
2015-11-08 16:07:11,123 INFO  [master:16000.activeMasterManager] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=OFFLINE, ts=1446970031102, server=master,16020,1446969780781} to {6f3d653b8b106cc2df931825f52d6dec state=PENDING_OPEN, ts=1446970031123, server=master,16020,1446970022735}
2015-11-08 16:07:11,234 INFO  [master:16000.activeMasterManager] master.AssignmentManager: Joined the cluster in 189ms, failover=false
2015-11-08 16:07:11,290 INFO  [AM.ZK.Worker-pool2-t5] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=PENDING_OPEN, ts=1446970031123, server=master,16020,1446970022735} to {6f3d653b8b106cc2df931825f52d6dec state=OPENING, ts=1446970031290, server=master,16020,1446970022735}
2015-11-08 16:07:11,794 INFO  [AM.ZK.Worker-pool2-t6] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=OPENING, ts=1446970031290, server=master,16020,1446970022735} to {6f3d653b8b106cc2df931825f52d6dec state=OPEN, ts=1446970031794, server=master,16020,1446970022735}
2015-11-08 16:07:11,811 INFO  [AM.ZK.Worker-pool2-t8] master.RegionStates: Offlined 6f3d653b8b106cc2df931825f52d6dec from master,16020,1446969780781
2015-11-08 16:07:12,050 INFO  [master:16000.activeMasterManager] master.HMaster: Master has completed initialization
2015-11-08 16:07:12,058 INFO  [master:16000.activeMasterManager] quotas.MasterQuotaManager: Quota support disabled
Sun Nov  8 16:13:40 CST 2015 Stopping hbase (via master)
2015-11-08 16:13:42,963 INFO  [B.defaultRpcServer.handler=0,queue=0,port=16000] master.MasterRpcServices: Client=hadoop/null shutdown
2015-11-08 16:13:42,963 INFO  [B.defaultRpcServer.handler=0,queue=0,port=16000] regionserver.HRegionServer: STOPPED: Cluster shutdown requested
2015-11-08 16:13:42,963 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: Stopping infoServer
2015-11-08 16:13:42,966 INFO  [master/master/192.168.1.101:16000] mortbay.log: Stopped SelectChannelConnector@0.0.0.0:16010
2015-11-08 16:13:42,966 INFO  [master/master/192.168.1.101:16000] procedure2.ProcedureExecutor: Stopping the procedure executor
2015-11-08 16:13:42,967 INFO  [master/master/192.168.1.101:16000] wal.WALProcedureStore: Stopping the WAL Procedure Store
2015-11-08 16:13:43,004 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: stopping server master,16000,1446970021587
2015-11-08 16:13:43,004 INFO  [master/master/192.168.1.101:16000] client.ConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x250e39aad820001
2015-11-08 16:13:43,017 INFO  [master/master/192.168.1.101:16000] zookeeper.ZooKeeper: Session: 0x250e39aad820001 closed
2015-11-08 16:13:43,017 INFO  [master/master/192.168.1.101:16000-EventThread] zookeeper.ClientCnxn: EventThread shut down
2015-11-08 16:13:43,118 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: stopping server master,16000,1446970021587; all regions closed.
2015-11-08 16:13:43,119 INFO  [master/master/192.168.1.101:16000] hbase.ChoreService: Chore service for: master,16000,1446970021587 had [[ScheduledChore: Name: CatalogJanitor-master:16000 Period: 300000 Unit: MILLISECONDS], [ScheduledChore: Name: LogsCleaner Period: 60000 Unit: MILLISECONDS], [ScheduledChore: Name: master,16000,1446970021587-BalancerChore Period: 300000 Unit: MILLISECONDS], [ScheduledChore: Name: HFileCleaner Period: 60000 Unit: MILLISECONDS], [ScheduledChore: Name: master,16000,1446970021587-ClusterStatusChore Period: 60000 Unit: MILLISECONDS]] on shutdown
2015-11-08 16:13:43,119 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave1,16020,1446970023531, master,16020,1446970022735
2015-11-08 16:13:43,567 INFO  [master,16000,1446970021587_splitLogManager__ChoreService_1] master.SplitLogManager$TimeoutMonitor: Chore: SplitLogManager Timeout Monitor was stopped
2015-11-08 16:13:44,145 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave1,16020,1446970023531, master,16020,1446970022735
2015-11-08 16:13:45,166 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave1,16020,1446970023531, master,16020,1446970022735
2015-11-08 16:13:46,187 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave1,16020,1446970023531, master,16020,1446970022735
2015-11-08 16:13:47,207 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave1,16020,1446970023531, master,16020,1446970022735
2015-11-08 16:13:48,228 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave1,16020,1446970023531, master,16020,1446970022735
2015-11-08 16:13:49,248 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave1,16020,1446970023531, master,16020,1446970022735
2015-11-08 16:13:50,267 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave1,16020,1446970023531, master,16020,1446970022735
2015-11-08 16:13:51,287 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave1,16020,1446970023531, master,16020,1446970022735
2015-11-08 16:13:52,306 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave1,16020,1446970023531, master,16020,1446970022735
2015-11-08 16:13:53,326 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave1,16020,1446970023531, master,16020,1446970022735
2015-11-08 16:13:54,345 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave1,16020,1446970023531, master,16020,1446970022735
2015-11-08 16:13:55,184 INFO  [main-EventThread] zookeeper.RegionServerTracker: RegionServer ephemeral node deleted, processing expiration [master,16020,1446970022735]
2015-11-08 16:13:55,185 INFO  [main-EventThread] master.ServerManager: Cluster shutdown set; master,16020,1446970022735 expired; onlineServers=1
2015-11-08 16:13:55,389 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave1,16020,1446970023531
2015-11-08 16:13:56,406 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave1,16020,1446970023531
2015-11-08 16:13:57,424 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave1,16020,1446970023531
2015-11-08 16:13:58,442 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave1,16020,1446970023531
2015-11-08 16:13:59,460 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave1,16020,1446970023531
2015-11-08 16:13:59,730 INFO  [main-EventThread] zookeeper.RegionServerTracker: RegionServer ephemeral node deleted, processing expiration [slave1,16020,1446970023531]
2015-11-08 16:13:59,730 INFO  [main-EventThread] master.ServerManager: Cluster shutdown set; slave1,16020,1446970023531 expired; onlineServers=0
2015-11-08 16:13:59,751 INFO  [master/master/192.168.1.101:16000] client.ConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x150e622517c0002
2015-11-08 16:13:59,763 INFO  [master/master/192.168.1.101:16000] zookeeper.ZooKeeper: Session: 0x150e622517c0002 closed
2015-11-08 16:13:59,763 INFO  [master:16000.activeMasterManager-EventThread] zookeeper.ClientCnxn: EventThread shut down
2015-11-08 16:13:59,764 INFO  [master/master/192.168.1.101:16000] hbase.ChoreService: Chore service for: master,16000,1446970021587_splitLogManager_ had [] on shutdown
2015-11-08 16:13:59,764 INFO  [master/master/192.168.1.101:16000] flush.MasterFlushTableProcedureManager: stop: server shutting down.
2015-11-08 16:13:59,764 INFO  [master/master/192.168.1.101:16000] ipc.RpcServer: Stopping server on 16000
2015-11-08 16:13:59,764 INFO  [RpcServer.listener,port=16000] ipc.RpcServer: RpcServer.listener,port=16000: stopping
2015-11-08 16:13:59,764 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopped
2015-11-08 16:13:59,765 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopping
2015-11-08 16:13:59,779 INFO  [master/master/192.168.1.101:16000] zookeeper.RecoverableZooKeeper: Node /hbase/rs/master,16000,1446970021587 already deleted, retry=false
2015-11-08 16:13:59,792 INFO  [master/master/192.168.1.101:16000] zookeeper.ZooKeeper: Session: 0x150e622517c0000 closed
2015-11-08 16:13:59,792 INFO  [main-EventThread] zookeeper.ClientCnxn: EventThread shut down
2015-11-08 16:13:59,792 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: stopping server master,16000,1446970021587; zookeeper connection closed.
2015-11-08 16:13:59,792 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: master/master/192.168.1.101:16000 exiting
Sun Nov  8 16:22:13 CST 2015 Starting master on master
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 30141
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 10240
cpu time               (seconds, -t) unlimited
max user processes              (-u) 1024
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2015-11-08 16:22:14,386 INFO  [main] util.VersionInfo: HBase 1.1.2
2015-11-08 16:22:14,386 INFO  [main] util.VersionInfo: Source code repository git://hw11397.local/Volumes/hbase-1.1.2RC2/hbase revision=cc2b70cf03e3378800661ec5cab11eb43fafe0fc
2015-11-08 16:22:14,386 INFO  [main] util.VersionInfo: Compiled by ndimiduk on Wed Aug 26 20:11:27 PDT 2015
2015-11-08 16:22:14,386 INFO  [main] util.VersionInfo: From source with checksum 73da41f3d1b867b7aba6166c77fafc17
2015-11-08 16:22:14,848 INFO  [main] util.ServerCommandLine: env:TERM=xterm
2015-11-08 16:22:14,848 INFO  [main] util.ServerCommandLine: env:HADOOP_COMMON_LIB_NATIVE_DIR=/opt/hadoop/lib/native
2015-11-08 16:22:14,848 INFO  [main] util.ServerCommandLine: env:IMSETTINGS_MODULE=none
2015-11-08 16:22:14,848 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/opt/java
2015-11-08 16:22:14,848 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/opt/hbase
2015-11-08 16:22:14,848 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2015-11-08 16:22:14,848 INFO  [main] util.ServerCommandLine: env:SESSION_MANAGER=local/unix:@/tmp/.ICE-unix/2957,unix/unix:/tmp/.ICE-unix/2957
2015-11-08 16:22:14,848 INFO  [main] util.ServerCommandLine: env:IMSETTINGS_INTEGRATE_DESKTOP=yes
2015-11-08 16:22:14,848 INFO  [main] util.ServerCommandLine: env:GNOME_DESKTOP_SESSION_ID=this-is-deprecated
2015-11-08 16:22:14,849 INFO  [main] util.ServerCommandLine: env:MAIL=/var/spool/mail/hadoop
2015-11-08 16:22:14,849 INFO  [main] util.ServerCommandLine: env:XDG_SESSION_COOKIE=ab8c9d4f5491283c7c300d7800000013-1446970837.780533-57183565
2015-11-08 16:22:14,849 INFO  [main] util.ServerCommandLine: env:GDMSESSION=gnome
2015-11-08 16:22:14,849 INFO  [main] util.ServerCommandLine: env:HOSTNAME=master
2015-11-08 16:22:14,849 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/tmp/hbase-hadoop-master.znode
2015-11-08 16:22:14,849 INFO  [main] util.ServerCommandLine: env:PWD=/home/hadoop
2015-11-08 16:22:14,849 INFO  [main] util.ServerCommandLine: env:HBASE_MASTER_OPTS= -XX:PermSize=128m -XX:MaxPermSize=128m
2015-11-08 16:22:14,849 INFO  [main] util.ServerCommandLine: env:CVS_RSH=ssh
2015-11-08 16:22:14,849 INFO  [main] util.ServerCommandLine: env:JAVA_LIBRARY_PATH=/opt/hadoop/lib/native::/opt/hadoop/lib/native:
2015-11-08 16:22:14,849 INFO  [main] util.ServerCommandLine: env:G_BROKEN_FILENAMES=1
2015-11-08 16:22:14,849 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2015-11-08 16:22:14,849 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2015-11-08 16:22:14,849 INFO  [main] util.ServerCommandLine: env:NLSPATH=/usr/dt/lib/nls/msg/%L/%N.cat
2015-11-08 16:22:14,849 INFO  [main] util.ServerCommandLine: env:GNOME_KEYRING_SOCKET=/tmp/keyring-8q0f1M/socket
2015-11-08 16:22:14,849 INFO  [main] util.ServerCommandLine: env:GDM_KEYBOARD_LAYOUT=us
2015-11-08 16:22:14,849 INFO  [main] util.ServerCommandLine: env:HBASE_REGIONSERVER_OPTS= -XX:PermSize=128m -XX:MaxPermSize=128m
2015-11-08 16:22:14,849 INFO  [main] util.ServerCommandLine: env:HISTSIZE=1000
2015-11-08 16:22:14,849 INFO  [main] util.ServerCommandLine: env:PATH=/opt/hbase:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin:/sbin:/opt/java//bin:/opt/java/jre/bin:/opt/hadoop/bin:/home/hadoop/bin
2015-11-08 16:22:14,849 INFO  [main] util.ServerCommandLine: env:QTLIB=/usr/lib64/qt-3.3/lib
2015-11-08 16:22:14,849 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2015-11-08 16:22:14,850 INFO  [main] util.ServerCommandLine: env:GDM_LANG=en_US.UTF-8
2015-11-08 16:22:14,850 INFO  [main] util.ServerCommandLine: env:XAUTHORITY=/var/run/gdm/auth-for-hadoop-ApHB7y/database
2015-11-08 16:22:14,850 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/tmp/hbase-hadoop-master.autorestart
2015-11-08 16:22:14,850 INFO  [main] util.ServerCommandLine: env:USERNAME=hadoop
2015-11-08 16:22:14,850 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-hadoop-master-master.log
2015-11-08 16:22:14,850 INFO  [main] util.ServerCommandLine: env:SSH_ASKPASS=/usr/libexec/openssh/gnome-ssh-askpass
2015-11-08 16:22:14,850 INFO  [main] util.ServerCommandLine: env:SHLVL=5
2015-11-08 16:22:14,850 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/opt/hbase/logs
2015-11-08 16:22:14,850 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-XX:+UseConcMarkSweepGC   -XX:PermSize=128m -XX:MaxPermSize=128m -Dhbase.log.dir=/opt/hbase/logs -Dhbase.log.file=hbase-hadoop-master-master.log -Dhbase.home.dir=/opt/hbase -Dhbase.id.str=hadoop -Dhbase.root.logger=INFO,RFA -Djava.library.path=/opt/hadoop/lib/native::/opt/hadoop/lib/native: -Dhbase.security.logger=INFO,RFAS
2015-11-08 16:22:14,850 INFO  [main] util.ServerCommandLine: env:XFILESEARCHPATH=/usr/dt/app-defaults/%L/Dt
2015-11-08 16:22:14,850 INFO  [main] util.ServerCommandLine: env:COLORTERM=gnome-terminal
2015-11-08 16:22:14,850 INFO  [main] util.ServerCommandLine: env:QT_IM_MODULE=xim
2015-11-08 16:22:14,850 INFO  [main] util.ServerCommandLine: env:WINDOWID=23068675
2015-11-08 16:22:14,850 INFO  [main] util.ServerCommandLine: env:LOGNAME=hadoop
2015-11-08 16:22:14,850 INFO  [main] util.ServerCommandLine: env:QTDIR=/usr/lib64/qt-3.3
2015-11-08 16:22:14,851 INFO  [main] util.ServerCommandLine: env:XMODIFIERS=@im=none
2015-11-08 16:22:14,851 INFO  [main] util.ServerCommandLine: env:SSH_AUTH_SOCK=/tmp/keyring-8q0f1M/socket.ssh
2015-11-08 16:22:14,851 INFO  [main] util.ServerCommandLine: env:HADOOP_HOME=/opt/hadoop
2015-11-08 16:22:14,851 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=:/opt/hadoop/lib/native::/opt/hadoop/lib/native:
2015-11-08 16:22:14,851 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2015-11-08 16:22:14,851 INFO  [main] util.ServerCommandLine: env:HADOOP_OPTS=-Djava.library.path=/opt/hadoop/lib/native
2015-11-08 16:22:14,851 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2015-11-08 16:22:14,851 INFO  [main] util.ServerCommandLine: env:DBUS_SESSION_BUS_ADDRESS=unix:abstract=/tmp/dbus-BE8cSLU3kg,guid=266d9eaea9c6327e69c81ff6000000c7
2015-11-08 16:22:14,851 INFO  [main] util.ServerCommandLine: env:GNOME_KEYRING_PID=2947
2015-11-08 16:22:14,851 INFO  [main] util.ServerCommandLine: env:GTK_RC_FILES=/etc/gtk/gtkrc:/home/hadoop/.gtkrc-1.2-gnome2
2015-11-08 16:22:14,851 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2015-11-08 16:22:14,852 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/opt/hbase/conf:/opt/java/lib/tools.jar:/opt/hbase:/opt/hbase/lib/activation-1.1.jar:/opt/hbase/lib/aopalliance-1.0.jar:/opt/hbase/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hbase/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hbase/lib/api-asn1-api-1.0.0-M20.jar:/opt/hbase/lib/api-util-1.0.0-M20.jar:/opt/hbase/lib/asm-3.1.jar:/opt/hbase/lib/avro-1.7.4.jar:/opt/hbase/lib/commons-beanutils-1.7.0.jar:/opt/hbase/lib/commons-beanutils-core-1.8.0.jar:/opt/hbase/lib/commons-cli-1.2.jar:/opt/hbase/lib/commons-codec-1.9.jar:/opt/hbase/lib/commons-collections-3.2.1.jar:/opt/hbase/lib/commons-compress-1.4.1.jar:/opt/hbase/lib/commons-configuration-1.6.jar:/opt/hbase/lib/commons-daemon-1.0.13.jar:/opt/hbase/lib/commons-digester-1.8.jar:/opt/hbase/lib/commons-el-1.0.jar:/opt/hbase/lib/commons-httpclient-3.1.jar:/opt/hbase/lib/commons-io-2.4.jar:/opt/hbase/lib/commons-lang-2.6.jar:/opt/hbase/lib/commons-logging-1.2.jar:/opt/hbase/lib/commons-math-2.2.jar:/opt/hbase/lib/commons-math3-3.1.1.jar:/opt/hbase/lib/commons-net-3.1.jar:/opt/hbase/lib/disruptor-3.3.0.jar:/opt/hbase/lib/findbugs-annotations-1.3.9-1.jar:/opt/hbase/lib/guava-12.0.1.jar:/opt/hbase/lib/guice-3.0.jar:/opt/hbase/lib/guice-servlet-3.0.jar:/opt/hbase/lib/hadoop-annotations-2.5.1.jar:/opt/hbase/lib/hadoop-auth-2.5.1.jar:/opt/hbase/lib/hadoop-client-2.5.1.jar:/opt/hbase/lib/hadoop-common-2.5.1.jar:/opt/hbase/lib/hadoop-hdfs-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-app-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-common-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-core-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-jobclient-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-shuffle-2.5.1.jar:/opt/hbase/lib/hadoop-yarn-api-2.5.1.jar:/opt/hbase/lib/hadoop-yarn-client-2.5.1.jar:/opt/hbase/lib/hadoop-yarn-common-2.5.1.jar:/opt/hbase/lib/hadoop-yarn-server-common-2.5.1.jar:/opt/hbase/lib/hbase-annotations-1.1.2.jar:/opt/hbase/lib/hbase-annotations-1.1.2-tests.jar:/opt/hbase/lib/hbase-client-1.1.2.jar:/opt/hbase/lib/hbase-common-1.1.2.jar:/opt/hbase/lib/hbase-common-1.1.2-tests.jar:/opt/hbase/lib/hbase-examples-1.1.2.jar:/opt/hbase/lib/hbase-hadoop2-compat-1.1.2.jar:/opt/hbase/lib/hbase-hadoop-compat-1.1.2.jar:/opt/hbase/lib/hbase-it-1.1.2.jar:/opt/hbase/lib/hbase-it-1.1.2-tests.jar:/opt/hbase/lib/hbase-prefix-tree-1.1.2.jar:/opt/hbase/lib/hbase-procedure-1.1.2.jar:/opt/hbase/lib/hbase-protocol-1.1.2.jar:/opt/hbase/lib/hbase-resource-bundle-1.1.2.jar:/opt/hbase/lib/hbase-rest-1.1.2.jar:/opt/hbase/lib/hbase-server-1.1.2.jar:/opt/hbase/lib/hbase-server-1.1.2-tests.jar:/opt/hbase/lib/hbase-shell-1.1.2.jar:/opt/hbase/lib/hbase-thrift-1.1.2.jar:/opt/hbase/lib/htrace-core-3.1.0-incubating.jar:/opt/hbase/lib/httpclient-4.2.5.jar:/opt/hbase/lib/httpcore-4.1.3.jar:/opt/hbase/lib/jackson-core-asl-1.9.13.jar:/opt/hbase/lib/jackson-jaxrs-1.9.13.jar:/opt/hbase/lib/jackson-mapper-asl-1.9.13.jar:/opt/hbase/lib/jackson-xc-1.9.13.jar:/opt/hbase/lib/jamon-runtime-2.3.1.jar:/opt/hbase/lib/jasper-compiler-5.5.23.jar:/opt/hbase/lib/jasper-runtime-5.5.23.jar:/opt/hbase/lib/javax.inject-1.jar:/opt/hbase/lib/java-xmlbuilder-0.4.jar:/opt/hbase/lib/jaxb-api-2.2.2.jar:/opt/hbase/lib/jaxb-impl-2.2.3-1.jar:/opt/hbase/lib/jcodings-1.0.8.jar:/opt/hbase/lib/jersey-client-1.9.jar:/opt/hbase/lib/jersey-core-1.9.jar:/opt/hbase/lib/jersey-guice-1.9.jar:/opt/hbase/lib/jersey-json-1.9.jar:/opt/hbase/lib/jersey-server-1.9.jar:/opt/hbase/lib/jets3t-0.9.0.jar:/opt/hbase/lib/jettison-1.3.3.jar:/opt/hbase/lib/jetty-6.1.26.jar:/opt/hbase/lib/jetty-sslengine-6.1.26.jar:/opt/hbase/lib/jetty-util-6.1.26.jar:/opt/hbase/lib/joni-2.1.2.jar:/opt/hbase/lib/jruby-complete-1.6.8.jar:/opt/hbase/lib/jsch-0.1.42.jar:/opt/hbase/lib/jsp-2.1-6.1.14.jar:/opt/hbase/lib/jsp-api-2.1-6.1.14.jar:/opt/hbase/lib/jsr305-1.3.9.jar:/opt/hbase/lib/junit-4.11.jar:/opt/hbase/lib/leveldbjni-all-1.8.jar:/opt/hbase/lib/libthrift-0.9.0.jar:/opt/hbase/lib/log4j-1.2.17.jar:/opt/hbase/lib/metrics-core-2.2.0.jar:/opt/hbase/lib/netty-3.2.4.Final.jar:/opt/hbase/lib/netty-all-4.0.23.Final.jar:/opt/hbase/lib/paranamer-2.3.jar:/opt/hbase/lib/protobuf-java-2.5.0.jar:/opt/hbase/lib/servlet-api-2.5-6.1.14.jar:/opt/hbase/lib/servlet-api-2.5.jar:/opt/hbase/lib/slf4j-api-1.7.7.jar:/opt/hbase/lib/slf4j-log4j12-1.7.5.jar:/opt/hbase/lib/snappy-java-1.0.4.1.jar:/opt/hbase/lib/spymemcached-2.11.6.jar:/opt/hbase/lib/xmlenc-0.52.jar:/opt/hbase/lib/xz-1.0.jar:/opt/hbase/lib/zookeeper-3.4.6.jar:/opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/contrib/capacity-scheduler/*.jar
2015-11-08 16:22:14,852 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2015-11-08 16:22:14,852 INFO  [main] util.ServerCommandLine: env:JRE_HOME=/opt/java/jre
2015-11-08 16:22:14,852 INFO  [main] util.ServerCommandLine: env:DESKTOP_SESSION=gnome
2015-11-08 16:22:14,852 INFO  [main] util.ServerCommandLine: env:QTINC=/usr/lib64/qt-3.3/include
2015-11-08 16:22:14,852 INFO  [main] util.ServerCommandLine: env:DISPLAY=192.168.1.100:1.0
2015-11-08 16:22:14,853 INFO  [main] util.ServerCommandLine: env:USER=hadoop
2015-11-08 16:22:14,853 INFO  [main] util.ServerCommandLine: env:HISTCONTROL=ignoredups
2015-11-08 16:22:14,853 INFO  [main] util.ServerCommandLine: env:HOME=/home/hadoop
2015-11-08 16:22:14,853 INFO  [main] util.ServerCommandLine: env:LESSOPEN=||/usr/bin/lesspipe.sh %s
2015-11-08 16:22:14,853 INFO  [main] util.ServerCommandLine: env:LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arj=01;31:*.taz=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lz=01;31:*.xz=01;31:*.bz2=01;31:*.tbz=01;31:*.tbz2=01;31:*.bz=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.rar=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
2015-11-08 16:22:14,853 INFO  [main] util.ServerCommandLine: env:ORBIT_SOCKETDIR=/tmp/orbit-hadoop
2015-11-08 16:22:14,853 INFO  [main] util.ServerCommandLine: env:LANG=en_US.UTF-8
2015-11-08 16:22:14,853 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-hadoop-master-master
2015-11-08 16:22:14,853 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=hadoop
2015-11-08 16:22:14,855 INFO  [main] util.ServerCommandLine: vmName=Java HotSpot(TM) 64-Bit Server VM, vmVendor=Oracle Corporation, vmVersion=24.79-b02
2015-11-08 16:22:14,856 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_master, -XX:OnOutOfMemoryError=kill -9 %p, -XX:+UseConcMarkSweepGC, -XX:PermSize=128m, -XX:MaxPermSize=128m, -Dhbase.log.dir=/opt/hbase/logs, -Dhbase.log.file=hbase-hadoop-master-master.log, -Dhbase.home.dir=/opt/hbase, -Dhbase.id.str=hadoop, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=/opt/hadoop/lib/native::/opt/hadoop/lib/native:, -Dhbase.security.logger=INFO,RFAS]
2015-11-08 16:22:15,559 WARN  [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-11-08 16:22:15,900 INFO  [main] regionserver.RSRpcServices: master/master/192.168.1.101:16000 server-side HConnection retries=350
2015-11-08 16:22:16,195 INFO  [main] ipc.SimpleRpcScheduler: Using deadline as user call queue, count=3
2015-11-08 16:22:16,252 INFO  [main] ipc.RpcServer: master/master/192.168.1.101:16000: started 10 reader(s).
2015-11-08 16:22:16,417 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2015-11-08 16:22:16,482 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-11-08 16:22:16,482 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2015-11-08 16:22:17,553 INFO  [main] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2015-11-08 16:22:17,811 INFO  [main] zookeeper.RecoverableZooKeeper: Process identifier=master:16000 connecting to ZooKeeper ensemble=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181
2015-11-08 16:22:17,842 INFO  [main] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2015-11-08 16:22:17,842 INFO  [main] zookeeper.ZooKeeper: Client environment:host.name=master
2015-11-08 16:22:17,842 INFO  [main] zookeeper.ZooKeeper: Client environment:java.version=1.7.0_79
2015-11-08 16:22:17,842 INFO  [main] zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
2015-11-08 16:22:17,842 INFO  [main] zookeeper.ZooKeeper: Client environment:java.home=/opt/java/jre
2015-11-08 16:22:17,843 INFO  [main] zookeeper.ZooKeeper: Client environment:java.class.path=/opt/hbase/conf:/opt/java/lib/tools.jar:/opt/hbase:/opt/hbase/lib/activation-1.1.jar:/opt/hbase/lib/aopalliance-1.0.jar:/opt/hbase/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hbase/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hbase/lib/api-asn1-api-1.0.0-M20.jar:/opt/hbase/lib/api-util-1.0.0-M20.jar:/opt/hbase/lib/asm-3.1.jar:/opt/hbase/lib/avro-1.7.4.jar:/opt/hbase/lib/commons-beanutils-1.7.0.jar:/opt/hbase/lib/commons-beanutils-core-1.8.0.jar:/opt/hbase/lib/commons-cli-1.2.jar:/opt/hbase/lib/commons-codec-1.9.jar:/opt/hbase/lib/commons-collections-3.2.1.jar:/opt/hbase/lib/commons-compress-1.4.1.jar:/opt/hbase/lib/commons-configuration-1.6.jar:/opt/hbase/lib/commons-daemon-1.0.13.jar:/opt/hbase/lib/commons-digester-1.8.jar:/opt/hbase/lib/commons-el-1.0.jar:/opt/hbase/lib/commons-httpclient-3.1.jar:/opt/hbase/lib/commons-io-2.4.jar:/opt/hbase/lib/commons-lang-2.6.jar:/opt/hbase/lib/commons-logging-1.2.jar:/opt/hbase/lib/commons-math-2.2.jar:/opt/hbase/lib/commons-math3-3.1.1.jar:/opt/hbase/lib/commons-net-3.1.jar:/opt/hbase/lib/disruptor-3.3.0.jar:/opt/hbase/lib/findbugs-annotations-1.3.9-1.jar:/opt/hbase/lib/guava-12.0.1.jar:/opt/hbase/lib/guice-3.0.jar:/opt/hbase/lib/guice-servlet-3.0.jar:/opt/hbase/lib/hadoop-annotations-2.5.1.jar:/opt/hbase/lib/hadoop-auth-2.5.1.jar:/opt/hbase/lib/hadoop-client-2.5.1.jar:/opt/hbase/lib/hadoop-common-2.5.1.jar:/opt/hbase/lib/hadoop-hdfs-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-app-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-common-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-core-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-jobclient-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-shuffle-2.5.1.jar:/opt/hbase/lib/hadoop-yarn-api-2.5.1.jar:/opt/hbase/lib/hadoop-yarn-client-2.5.1.jar:/opt/hbase/lib/hadoop-yarn-common-2.5.1.jar:/opt/hbase/lib/hadoop-yarn-server-common-2.5.1.jar:/opt/hbase/lib/hbase-annotations-1.1.2.jar:/opt/hbase/lib/hbase-annotations-1.1.2-tests.jar:/opt/hbase/lib/hbase-client-1.1.2.jar:/opt/hbase/lib/hbase-common-1.1.2.jar:/opt/hbase/lib/hbase-common-1.1.2-tests.jar:/opt/hbase/lib/hbase-examples-1.1.2.jar:/opt/hbase/lib/hbase-hadoop2-compat-1.1.2.jar:/opt/hbase/lib/hbase-hadoop-compat-1.1.2.jar:/opt/hbase/lib/hbase-it-1.1.2.jar:/opt/hbase/lib/hbase-it-1.1.2-tests.jar:/opt/hbase/lib/hbase-prefix-tree-1.1.2.jar:/opt/hbase/lib/hbase-procedure-1.1.2.jar:/opt/hbase/lib/hbase-protocol-1.1.2.jar:/opt/hbase/lib/hbase-resource-bundle-1.1.2.jar:/opt/hbase/lib/hbase-rest-1.1.2.jar:/opt/hbase/lib/hbase-server-1.1.2.jar:/opt/hbase/lib/hbase-server-1.1.2-tests.jar:/opt/hbase/lib/hbase-shell-1.1.2.jar:/opt/hbase/lib/hbase-thrift-1.1.2.jar:/opt/hbase/lib/htrace-core-3.1.0-incubating.jar:/opt/hbase/lib/httpclient-4.2.5.jar:/opt/hbase/lib/httpcore-4.1.3.jar:/opt/hbase/lib/jackson-core-asl-1.9.13.jar:/opt/hbase/lib/jackson-jaxrs-1.9.13.jar:/opt/hbase/lib/jackson-mapper-asl-1.9.13.jar:/opt/hbase/lib/jackson-xc-1.9.13.jar:/opt/hbase/lib/jamon-runtime-2.3.1.jar:/opt/hbase/lib/jasper-compiler-5.5.23.jar:/opt/hbase/lib/jasper-runtime-5.5.23.jar:/opt/hbase/lib/javax.inject-1.jar:/opt/hbase/lib/java-xmlbuilder-0.4.jar:/opt/hbase/lib/jaxb-api-2.2.2.jar:/opt/hbase/lib/jaxb-impl-2.2.3-1.jar:/opt/hbase/lib/jcodings-1.0.8.jar:/opt/hbase/lib/jersey-client-1.9.jar:/opt/hbase/lib/jersey-core-1.9.jar:/opt/hbase/lib/jersey-guice-1.9.jar:/opt/hbase/lib/jersey-json-1.9.jar:/opt/hbase/lib/jersey-server-1.9.jar:/opt/hbase/lib/jets3t-0.9.0.jar:/opt/hbase/lib/jettison-1.3.3.jar:/opt/hbase/lib/jetty-6.1.26.jar:/opt/hbase/lib/jetty-sslengine-6.1.26.jar:/opt/hbase/lib/jetty-util-6.1.26.jar:/opt/hbase/lib/joni-2.1.2.jar:/opt/hbase/lib/jruby-complete-1.6.8.jar:/opt/hbase/lib/jsch-0.1.42.jar:/opt/hbase/lib/jsp-2.1-6.1.14.jar:/opt/hbase/lib/jsp-api-2.1-6.1.14.jar:/opt/hbase/lib/jsr305-1.3.9.jar:/opt/hbase/lib/junit-4.11.jar:/opt/hbase/lib/leveldbjni-all-1.8.jar:/opt/hbase/lib/libthrift-0.9.0.jar:/opt/hbase/lib/log4j-1.2.17.jar:/opt/hbase/lib/metrics-core-2.2.0.jar:/opt/hbase/lib/netty-3.2.4.Final.jar:/opt/hbase/lib/netty-all-4.0.23.Final.jar:/opt/hbase/lib/paranamer-2.3.jar:/opt/hbase/lib/protobuf-java-2.5.0.jar:/opt/hbase/lib/servlet-api-2.5-6.1.14.jar:/opt/hbase/lib/servlet-api-2.5.jar:/opt/hbase/lib/slf4j-api-1.7.7.jar:/opt/hbase/lib/slf4j-log4j12-1.7.5.jar:/opt/hbase/lib/snappy-java-1.0.4.1.jar:/opt/hbase/lib/spymemcached-2.11.6.jar:/opt/hbase/lib/xmlenc-0.52.jar:/opt/hbase/lib/xz-1.0.jar:/opt/hbase/lib/zookeeper-3.4.6.jar:/opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-auth-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/opt/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/opt/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop/share/hadoop/common/lib/curator-framework-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/opt/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/opt/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop/share/hadoop/common/lib/curator-client-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/opt/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-annotations-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/opt/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop/share/hadoop/common/lib/htrace-core-3.0.4.jar:/opt/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop/share/hadoop/common/hadoop-common-2.6.0-tests.jar:/opt/hadoop/share/hadoop/common/hadoop-common-2.6.0.jar:/opt/hadoop/share/hadoop/common/hadoop-nfs-2.6.0.jar:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/opt/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.0-tests.jar:/opt/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jline-0.9.94.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-tests.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar
2015-11-08 16:22:17,843 INFO  [main] zookeeper.ZooKeeper: Client environment:java.library.path=/opt/hadoop/lib/native::/opt/hadoop/lib/native:
2015-11-08 16:22:17,843 INFO  [main] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2015-11-08 16:22:17,843 INFO  [main] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2015-11-08 16:22:17,843 INFO  [main] zookeeper.ZooKeeper: Client environment:os.name=Linux
2015-11-08 16:22:17,843 INFO  [main] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2015-11-08 16:22:17,843 INFO  [main] zookeeper.ZooKeeper: Client environment:os.version=2.6.32-573.el6.x86_64
2015-11-08 16:22:17,843 INFO  [main] zookeeper.ZooKeeper: Client environment:user.name=hadoop
2015-11-08 16:22:17,843 INFO  [main] zookeeper.ZooKeeper: Client environment:user.home=/home/hadoop
2015-11-08 16:22:17,843 INFO  [main] zookeeper.ZooKeeper: Client environment:user.dir=/home/hadoop
2015-11-08 16:22:17,844 INFO  [main] zookeeper.ZooKeeper: Initiating client connection, connectString=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181 sessionTimeout=90000 watcher=master:160000x0, quorum=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181, baseZNode=/hbase
2015-11-08 16:22:17,911 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.101/192.168.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 16:22:17,921 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.101/192.168.1.101:2181, initiating session
2015-11-08 16:22:17,925 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x0, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-08 16:22:18,030 WARN  [main] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase
2015-11-08 16:22:18,080 INFO  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 16:22:18,082 WARN  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2015-11-08 16:22:19,056 INFO  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 16:22:19,056 WARN  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2015-11-08 16:22:19,156 WARN  [main] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase
2015-11-08 16:22:20,477 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.101/192.168.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 16:22:20,477 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.101/192.168.1.101:2181, initiating session
2015-11-08 16:22:20,478 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x0, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-08 16:22:20,854 INFO  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 16:22:20,855 WARN  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2015-11-08 16:22:21,234 INFO  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 16:22:21,234 WARN  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2015-11-08 16:22:21,335 WARN  [main] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase
2015-11-08 16:22:23,224 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.101/192.168.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 16:22:23,224 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.101/192.168.1.101:2181, initiating session
2015-11-08 16:22:23,225 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x0, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-08 16:22:23,890 INFO  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 16:22:23,890 WARN  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2015-11-08 16:22:24,197 INFO  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 16:22:24,197 WARN  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2015-11-08 16:22:25,602 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.101/192.168.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 16:22:25,603 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.101/192.168.1.101:2181, initiating session
2015-11-08 16:22:25,604 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x0, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-08 16:22:25,704 WARN  [main] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase
2015-11-08 16:22:26,548 INFO  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 16:22:26,549 WARN  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2015-11-08 16:22:27,079 INFO  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 16:22:27,080 WARN  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2015-11-08 16:22:28,851 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.101/192.168.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 16:22:28,851 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.101/192.168.1.101:2181, initiating session
2015-11-08 16:22:28,852 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x0, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-08 16:22:29,568 INFO  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 16:22:29,569 WARN  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2015-11-08 16:22:30,119 INFO  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 16:22:30,119 WARN  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2015-11-08 16:22:31,764 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.101/192.168.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 16:22:31,764 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.101/192.168.1.101:2181, initiating session
2015-11-08 16:22:31,765 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x0, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-08 16:22:32,847 INFO  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 16:22:32,847 WARN  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2015-11-08 16:22:33,228 INFO  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 16:22:33,229 WARN  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2015-11-08 16:22:34,481 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.101/192.168.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 16:22:34,482 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.101/192.168.1.101:2181, initiating session
2015-11-08 16:22:34,482 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x0, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-08 16:22:34,583 WARN  [main] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase
2015-11-08 16:22:34,583 ERROR [main] zookeeper.RecoverableZooKeeper: ZooKeeper create failed after 4 attempts
2015-11-08 16:22:34,583 ERROR [main] master.HMasterCommandLine: Master exiting
java.lang.RuntimeException: Failed construction of Master: class org.apache.hadoop.hbase.master.HMaster
	at org.apache.hadoop.hbase.master.HMaster.constructMaster(HMaster.java:2290)
	at org.apache.hadoop.hbase.master.HMasterCommandLine.startMaster(HMasterCommandLine.java:233)
	at org.apache.hadoop.hbase.master.HMasterCommandLine.run(HMasterCommandLine.java:139)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at org.apache.hadoop.hbase.util.ServerCommandLine.doMain(ServerCommandLine.java:126)
	at org.apache.hadoop.hbase.master.HMaster.main(HMaster.java:2304)
Caused by: org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:783)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.createNonSequential(RecoverableZooKeeper.java:575)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.create(RecoverableZooKeeper.java:554)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.createWithParents(ZKUtil.java:1313)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.createWithParents(ZKUtil.java:1291)
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.createBaseZNodes(ZooKeeperWatcher.java:184)
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.<init>(ZooKeeperWatcher.java:177)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.<init>(HRegionServer.java:580)
	at org.apache.hadoop.hbase.master.HMaster.<init>(HMaster.java:364)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.hbase.master.HMaster.constructMaster(HMaster.java:2285)
	... 5 more
Sun Nov  8 16:29:46 CST 2015 Stopping hbase (via master)
Sun Nov  8 16:30:34 CST 2015 Starting master on master
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 30141
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 10240
cpu time               (seconds, -t) unlimited
max user processes              (-u) 1024
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2015-11-08 16:30:35,448 INFO  [main] util.VersionInfo: HBase 1.1.2
2015-11-08 16:30:35,449 INFO  [main] util.VersionInfo: Source code repository git://hw11397.local/Volumes/hbase-1.1.2RC2/hbase revision=cc2b70cf03e3378800661ec5cab11eb43fafe0fc
2015-11-08 16:30:35,449 INFO  [main] util.VersionInfo: Compiled by ndimiduk on Wed Aug 26 20:11:27 PDT 2015
2015-11-08 16:30:35,449 INFO  [main] util.VersionInfo: From source with checksum 73da41f3d1b867b7aba6166c77fafc17
2015-11-08 16:30:35,769 INFO  [main] util.ServerCommandLine: env:TERM=xterm
2015-11-08 16:30:35,769 INFO  [main] util.ServerCommandLine: env:HADOOP_COMMON_LIB_NATIVE_DIR=/opt/hadoop/lib/native
2015-11-08 16:30:35,769 INFO  [main] util.ServerCommandLine: env:IMSETTINGS_MODULE=none
2015-11-08 16:30:35,769 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/opt/java
2015-11-08 16:30:35,769 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/opt/hbase
2015-11-08 16:30:35,769 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2015-11-08 16:30:35,769 INFO  [main] util.ServerCommandLine: env:SESSION_MANAGER=local/unix:@/tmp/.ICE-unix/2957,unix/unix:/tmp/.ICE-unix/2957
2015-11-08 16:30:35,769 INFO  [main] util.ServerCommandLine: env:IMSETTINGS_INTEGRATE_DESKTOP=yes
2015-11-08 16:30:35,769 INFO  [main] util.ServerCommandLine: env:GNOME_DESKTOP_SESSION_ID=this-is-deprecated
2015-11-08 16:30:35,769 INFO  [main] util.ServerCommandLine: env:MAIL=/var/spool/mail/hadoop
2015-11-08 16:30:35,769 INFO  [main] util.ServerCommandLine: env:XDG_SESSION_COOKIE=ab8c9d4f5491283c7c300d7800000013-1446970837.780533-57183565
2015-11-08 16:30:35,769 INFO  [main] util.ServerCommandLine: env:GDMSESSION=gnome
2015-11-08 16:30:35,769 INFO  [main] util.ServerCommandLine: env:HOSTNAME=master
2015-11-08 16:30:35,769 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/tmp/hbase-hadoop-master.znode
2015-11-08 16:30:35,769 INFO  [main] util.ServerCommandLine: env:PWD=/opt/hbase/logs
2015-11-08 16:30:35,770 INFO  [main] util.ServerCommandLine: env:HBASE_MASTER_OPTS= -XX:PermSize=128m -XX:MaxPermSize=128m
2015-11-08 16:30:35,770 INFO  [main] util.ServerCommandLine: env:CVS_RSH=ssh
2015-11-08 16:30:35,770 INFO  [main] util.ServerCommandLine: env:JAVA_LIBRARY_PATH=/opt/hadoop/lib/native::/opt/hadoop/lib/native:
2015-11-08 16:30:35,770 INFO  [main] util.ServerCommandLine: env:G_BROKEN_FILENAMES=1
2015-11-08 16:30:35,770 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2015-11-08 16:30:35,770 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2015-11-08 16:30:35,770 INFO  [main] util.ServerCommandLine: env:NLSPATH=/usr/dt/lib/nls/msg/%L/%N.cat
2015-11-08 16:30:35,770 INFO  [main] util.ServerCommandLine: env:GNOME_KEYRING_SOCKET=/tmp/keyring-8q0f1M/socket
2015-11-08 16:30:35,770 INFO  [main] util.ServerCommandLine: env:GDM_KEYBOARD_LAYOUT=us
2015-11-08 16:30:35,770 INFO  [main] util.ServerCommandLine: env:HBASE_REGIONSERVER_OPTS= -XX:PermSize=128m -XX:MaxPermSize=128m
2015-11-08 16:30:35,770 INFO  [main] util.ServerCommandLine: env:HISTSIZE=1000
2015-11-08 16:30:35,770 INFO  [main] util.ServerCommandLine: env:PATH=/opt/hbase:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin:/sbin:/opt/java//bin:/opt/java/jre/bin:/opt/hadoop/bin:/home/hadoop/bin
2015-11-08 16:30:35,770 INFO  [main] util.ServerCommandLine: env:QTLIB=/usr/lib64/qt-3.3/lib
2015-11-08 16:30:35,770 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2015-11-08 16:30:35,770 INFO  [main] util.ServerCommandLine: env:GDM_LANG=en_US.UTF-8
2015-11-08 16:30:35,770 INFO  [main] util.ServerCommandLine: env:XAUTHORITY=/var/run/gdm/auth-for-hadoop-ApHB7y/database
2015-11-08 16:30:35,770 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/tmp/hbase-hadoop-master.autorestart
2015-11-08 16:30:35,770 INFO  [main] util.ServerCommandLine: env:USERNAME=hadoop
2015-11-08 16:30:35,770 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-hadoop-master-master.log
2015-11-08 16:30:35,770 INFO  [main] util.ServerCommandLine: env:SSH_ASKPASS=/usr/libexec/openssh/gnome-ssh-askpass
2015-11-08 16:30:35,771 INFO  [main] util.ServerCommandLine: env:SHLVL=5
2015-11-08 16:30:35,771 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/opt/hbase/logs
2015-11-08 16:30:35,771 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-XX:+UseConcMarkSweepGC   -XX:PermSize=128m -XX:MaxPermSize=128m -Dhbase.log.dir=/opt/hbase/logs -Dhbase.log.file=hbase-hadoop-master-master.log -Dhbase.home.dir=/opt/hbase -Dhbase.id.str=hadoop -Dhbase.root.logger=INFO,RFA -Djava.library.path=/opt/hadoop/lib/native::/opt/hadoop/lib/native: -Dhbase.security.logger=INFO,RFAS
2015-11-08 16:30:35,771 INFO  [main] util.ServerCommandLine: env:XFILESEARCHPATH=/usr/dt/app-defaults/%L/Dt
2015-11-08 16:30:35,771 INFO  [main] util.ServerCommandLine: env:COLORTERM=gnome-terminal
2015-11-08 16:30:35,771 INFO  [main] util.ServerCommandLine: env:QT_IM_MODULE=xim
2015-11-08 16:30:35,771 INFO  [main] util.ServerCommandLine: env:WINDOWID=23068675
2015-11-08 16:30:35,771 INFO  [main] util.ServerCommandLine: env:LOGNAME=hadoop
2015-11-08 16:30:35,771 INFO  [main] util.ServerCommandLine: env:QTDIR=/usr/lib64/qt-3.3
2015-11-08 16:30:35,771 INFO  [main] util.ServerCommandLine: env:XMODIFIERS=@im=none
2015-11-08 16:30:35,771 INFO  [main] util.ServerCommandLine: env:SSH_AUTH_SOCK=/tmp/keyring-8q0f1M/socket.ssh
2015-11-08 16:30:35,771 INFO  [main] util.ServerCommandLine: env:HADOOP_HOME=/opt/hadoop
2015-11-08 16:30:35,771 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=:/opt/hadoop/lib/native::/opt/hadoop/lib/native:
2015-11-08 16:30:35,771 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2015-11-08 16:30:35,771 INFO  [main] util.ServerCommandLine: env:HADOOP_OPTS=-Djava.library.path=/opt/hadoop/lib/native
2015-11-08 16:30:35,771 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2015-11-08 16:30:35,771 INFO  [main] util.ServerCommandLine: env:DBUS_SESSION_BUS_ADDRESS=unix:abstract=/tmp/dbus-BE8cSLU3kg,guid=266d9eaea9c6327e69c81ff6000000c7
2015-11-08 16:30:35,771 INFO  [main] util.ServerCommandLine: env:GNOME_KEYRING_PID=2947
2015-11-08 16:30:35,771 INFO  [main] util.ServerCommandLine: env:GTK_RC_FILES=/etc/gtk/gtkrc:/home/hadoop/.gtkrc-1.2-gnome2
2015-11-08 16:30:35,772 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2015-11-08 16:30:35,772 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/opt/hbase/conf:/opt/java/lib/tools.jar:/opt/hbase:/opt/hbase/lib/activation-1.1.jar:/opt/hbase/lib/aopalliance-1.0.jar:/opt/hbase/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hbase/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hbase/lib/api-asn1-api-1.0.0-M20.jar:/opt/hbase/lib/api-util-1.0.0-M20.jar:/opt/hbase/lib/asm-3.1.jar:/opt/hbase/lib/avro-1.7.4.jar:/opt/hbase/lib/commons-beanutils-1.7.0.jar:/opt/hbase/lib/commons-beanutils-core-1.8.0.jar:/opt/hbase/lib/commons-cli-1.2.jar:/opt/hbase/lib/commons-codec-1.9.jar:/opt/hbase/lib/commons-collections-3.2.1.jar:/opt/hbase/lib/commons-compress-1.4.1.jar:/opt/hbase/lib/commons-configuration-1.6.jar:/opt/hbase/lib/commons-daemon-1.0.13.jar:/opt/hbase/lib/commons-digester-1.8.jar:/opt/hbase/lib/commons-el-1.0.jar:/opt/hbase/lib/commons-httpclient-3.1.jar:/opt/hbase/lib/commons-io-2.4.jar:/opt/hbase/lib/commons-lang-2.6.jar:/opt/hbase/lib/commons-logging-1.2.jar:/opt/hbase/lib/commons-math-2.2.jar:/opt/hbase/lib/commons-math3-3.1.1.jar:/opt/hbase/lib/commons-net-3.1.jar:/opt/hbase/lib/disruptor-3.3.0.jar:/opt/hbase/lib/findbugs-annotations-1.3.9-1.jar:/opt/hbase/lib/guava-12.0.1.jar:/opt/hbase/lib/guice-3.0.jar:/opt/hbase/lib/guice-servlet-3.0.jar:/opt/hbase/lib/hadoop-annotations-2.5.1.jar:/opt/hbase/lib/hadoop-auth-2.5.1.jar:/opt/hbase/lib/hadoop-client-2.5.1.jar:/opt/hbase/lib/hadoop-common-2.5.1.jar:/opt/hbase/lib/hadoop-hdfs-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-app-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-common-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-core-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-jobclient-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-shuffle-2.5.1.jar:/opt/hbase/lib/hadoop-yarn-api-2.5.1.jar:/opt/hbase/lib/hadoop-yarn-client-2.5.1.jar:/opt/hbase/lib/hadoop-yarn-common-2.5.1.jar:/opt/hbase/lib/hadoop-yarn-server-common-2.5.1.jar:/opt/hbase/lib/hbase-annotations-1.1.2.jar:/opt/hbase/lib/hbase-annotations-1.1.2-tests.jar:/opt/hbase/lib/hbase-client-1.1.2.jar:/opt/hbase/lib/hbase-common-1.1.2.jar:/opt/hbase/lib/hbase-common-1.1.2-tests.jar:/opt/hbase/lib/hbase-examples-1.1.2.jar:/opt/hbase/lib/hbase-hadoop2-compat-1.1.2.jar:/opt/hbase/lib/hbase-hadoop-compat-1.1.2.jar:/opt/hbase/lib/hbase-it-1.1.2.jar:/opt/hbase/lib/hbase-it-1.1.2-tests.jar:/opt/hbase/lib/hbase-prefix-tree-1.1.2.jar:/opt/hbase/lib/hbase-procedure-1.1.2.jar:/opt/hbase/lib/hbase-protocol-1.1.2.jar:/opt/hbase/lib/hbase-resource-bundle-1.1.2.jar:/opt/hbase/lib/hbase-rest-1.1.2.jar:/opt/hbase/lib/hbase-server-1.1.2.jar:/opt/hbase/lib/hbase-server-1.1.2-tests.jar:/opt/hbase/lib/hbase-shell-1.1.2.jar:/opt/hbase/lib/hbase-thrift-1.1.2.jar:/opt/hbase/lib/htrace-core-3.1.0-incubating.jar:/opt/hbase/lib/httpclient-4.2.5.jar:/opt/hbase/lib/httpcore-4.1.3.jar:/opt/hbase/lib/jackson-core-asl-1.9.13.jar:/opt/hbase/lib/jackson-jaxrs-1.9.13.jar:/opt/hbase/lib/jackson-mapper-asl-1.9.13.jar:/opt/hbase/lib/jackson-xc-1.9.13.jar:/opt/hbase/lib/jamon-runtime-2.3.1.jar:/opt/hbase/lib/jasper-compiler-5.5.23.jar:/opt/hbase/lib/jasper-runtime-5.5.23.jar:/opt/hbase/lib/javax.inject-1.jar:/opt/hbase/lib/java-xmlbuilder-0.4.jar:/opt/hbase/lib/jaxb-api-2.2.2.jar:/opt/hbase/lib/jaxb-impl-2.2.3-1.jar:/opt/hbase/lib/jcodings-1.0.8.jar:/opt/hbase/lib/jersey-client-1.9.jar:/opt/hbase/lib/jersey-core-1.9.jar:/opt/hbase/lib/jersey-guice-1.9.jar:/opt/hbase/lib/jersey-json-1.9.jar:/opt/hbase/lib/jersey-server-1.9.jar:/opt/hbase/lib/jets3t-0.9.0.jar:/opt/hbase/lib/jettison-1.3.3.jar:/opt/hbase/lib/jetty-6.1.26.jar:/opt/hbase/lib/jetty-sslengine-6.1.26.jar:/opt/hbase/lib/jetty-util-6.1.26.jar:/opt/hbase/lib/joni-2.1.2.jar:/opt/hbase/lib/jruby-complete-1.6.8.jar:/opt/hbase/lib/jsch-0.1.42.jar:/opt/hbase/lib/jsp-2.1-6.1.14.jar:/opt/hbase/lib/jsp-api-2.1-6.1.14.jar:/opt/hbase/lib/jsr305-1.3.9.jar:/opt/hbase/lib/junit-4.11.jar:/opt/hbase/lib/leveldbjni-all-1.8.jar:/opt/hbase/lib/libthrift-0.9.0.jar:/opt/hbase/lib/log4j-1.2.17.jar:/opt/hbase/lib/metrics-core-2.2.0.jar:/opt/hbase/lib/netty-3.2.4.Final.jar:/opt/hbase/lib/netty-all-4.0.23.Final.jar:/opt/hbase/lib/paranamer-2.3.jar:/opt/hbase/lib/protobuf-java-2.5.0.jar:/opt/hbase/lib/servlet-api-2.5-6.1.14.jar:/opt/hbase/lib/servlet-api-2.5.jar:/opt/hbase/lib/slf4j-api-1.7.7.jar:/opt/hbase/lib/slf4j-log4j12-1.7.5.jar:/opt/hbase/lib/snappy-java-1.0.4.1.jar:/opt/hbase/lib/spymemcached-2.11.6.jar:/opt/hbase/lib/xmlenc-0.52.jar:/opt/hbase/lib/xz-1.0.jar:/opt/hbase/lib/zookeeper-3.4.6.jar:/opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/contrib/capacity-scheduler/*.jar
2015-11-08 16:30:35,772 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2015-11-08 16:30:35,772 INFO  [main] util.ServerCommandLine: env:JRE_HOME=/opt/java/jre
2015-11-08 16:30:35,772 INFO  [main] util.ServerCommandLine: env:DESKTOP_SESSION=gnome
2015-11-08 16:30:35,773 INFO  [main] util.ServerCommandLine: env:QTINC=/usr/lib64/qt-3.3/include
2015-11-08 16:30:35,773 INFO  [main] util.ServerCommandLine: env:DISPLAY=192.168.1.100:1.0
2015-11-08 16:30:35,773 INFO  [main] util.ServerCommandLine: env:USER=hadoop
2015-11-08 16:30:35,773 INFO  [main] util.ServerCommandLine: env:HISTCONTROL=ignoredups
2015-11-08 16:30:35,773 INFO  [main] util.ServerCommandLine: env:HOME=/home/hadoop
2015-11-08 16:30:35,773 INFO  [main] util.ServerCommandLine: env:LESSOPEN=||/usr/bin/lesspipe.sh %s
2015-11-08 16:30:35,773 INFO  [main] util.ServerCommandLine: env:LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arj=01;31:*.taz=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lz=01;31:*.xz=01;31:*.bz2=01;31:*.tbz=01;31:*.tbz2=01;31:*.bz=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.rar=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
2015-11-08 16:30:35,773 INFO  [main] util.ServerCommandLine: env:ORBIT_SOCKETDIR=/tmp/orbit-hadoop
2015-11-08 16:30:35,773 INFO  [main] util.ServerCommandLine: env:LANG=en_US.UTF-8
2015-11-08 16:30:35,773 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-hadoop-master-master
2015-11-08 16:30:35,773 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=hadoop
2015-11-08 16:30:35,774 INFO  [main] util.ServerCommandLine: vmName=Java HotSpot(TM) 64-Bit Server VM, vmVendor=Oracle Corporation, vmVersion=24.79-b02
2015-11-08 16:30:35,775 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_master, -XX:OnOutOfMemoryError=kill -9 %p, -XX:+UseConcMarkSweepGC, -XX:PermSize=128m, -XX:MaxPermSize=128m, -Dhbase.log.dir=/opt/hbase/logs, -Dhbase.log.file=hbase-hadoop-master-master.log, -Dhbase.home.dir=/opt/hbase, -Dhbase.id.str=hadoop, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=/opt/hadoop/lib/native::/opt/hadoop/lib/native:, -Dhbase.security.logger=INFO,RFAS]
2015-11-08 16:30:36,208 WARN  [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-11-08 16:30:36,492 INFO  [main] regionserver.RSRpcServices: master/master/192.168.1.101:16000 server-side HConnection retries=350
2015-11-08 16:30:36,719 INFO  [main] ipc.SimpleRpcScheduler: Using deadline as user call queue, count=3
2015-11-08 16:30:36,744 INFO  [main] ipc.RpcServer: master/master/192.168.1.101:16000: started 10 reader(s).
2015-11-08 16:30:36,806 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2015-11-08 16:30:36,865 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-11-08 16:30:36,865 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2015-11-08 16:30:37,671 INFO  [main] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2015-11-08 16:30:37,924 INFO  [main] zookeeper.RecoverableZooKeeper: Process identifier=master:16000 connecting to ZooKeeper ensemble=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181
2015-11-08 16:30:37,933 INFO  [main] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2015-11-08 16:30:37,934 INFO  [main] zookeeper.ZooKeeper: Client environment:host.name=master
2015-11-08 16:30:37,934 INFO  [main] zookeeper.ZooKeeper: Client environment:java.version=1.7.0_79
2015-11-08 16:30:37,934 INFO  [main] zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
2015-11-08 16:30:37,934 INFO  [main] zookeeper.ZooKeeper: Client environment:java.home=/opt/java/jre
2015-11-08 16:30:37,934 INFO  [main] zookeeper.ZooKeeper: Client environment:java.class.path=/opt/hbase/conf:/opt/java/lib/tools.jar:/opt/hbase:/opt/hbase/lib/activation-1.1.jar:/opt/hbase/lib/aopalliance-1.0.jar:/opt/hbase/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hbase/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hbase/lib/api-asn1-api-1.0.0-M20.jar:/opt/hbase/lib/api-util-1.0.0-M20.jar:/opt/hbase/lib/asm-3.1.jar:/opt/hbase/lib/avro-1.7.4.jar:/opt/hbase/lib/commons-beanutils-1.7.0.jar:/opt/hbase/lib/commons-beanutils-core-1.8.0.jar:/opt/hbase/lib/commons-cli-1.2.jar:/opt/hbase/lib/commons-codec-1.9.jar:/opt/hbase/lib/commons-collections-3.2.1.jar:/opt/hbase/lib/commons-compress-1.4.1.jar:/opt/hbase/lib/commons-configuration-1.6.jar:/opt/hbase/lib/commons-daemon-1.0.13.jar:/opt/hbase/lib/commons-digester-1.8.jar:/opt/hbase/lib/commons-el-1.0.jar:/opt/hbase/lib/commons-httpclient-3.1.jar:/opt/hbase/lib/commons-io-2.4.jar:/opt/hbase/lib/commons-lang-2.6.jar:/opt/hbase/lib/commons-logging-1.2.jar:/opt/hbase/lib/commons-math-2.2.jar:/opt/hbase/lib/commons-math3-3.1.1.jar:/opt/hbase/lib/commons-net-3.1.jar:/opt/hbase/lib/disruptor-3.3.0.jar:/opt/hbase/lib/findbugs-annotations-1.3.9-1.jar:/opt/hbase/lib/guava-12.0.1.jar:/opt/hbase/lib/guice-3.0.jar:/opt/hbase/lib/guice-servlet-3.0.jar:/opt/hbase/lib/hadoop-annotations-2.5.1.jar:/opt/hbase/lib/hadoop-auth-2.5.1.jar:/opt/hbase/lib/hadoop-client-2.5.1.jar:/opt/hbase/lib/hadoop-common-2.5.1.jar:/opt/hbase/lib/hadoop-hdfs-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-app-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-common-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-core-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-jobclient-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-shuffle-2.5.1.jar:/opt/hbase/lib/hadoop-yarn-api-2.5.1.jar:/opt/hbase/lib/hadoop-yarn-client-2.5.1.jar:/opt/hbase/lib/hadoop-yarn-common-2.5.1.jar:/opt/hbase/lib/hadoop-yarn-server-common-2.5.1.jar:/opt/hbase/lib/hbase-annotations-1.1.2.jar:/opt/hbase/lib/hbase-annotations-1.1.2-tests.jar:/opt/hbase/lib/hbase-client-1.1.2.jar:/opt/hbase/lib/hbase-common-1.1.2.jar:/opt/hbase/lib/hbase-common-1.1.2-tests.jar:/opt/hbase/lib/hbase-examples-1.1.2.jar:/opt/hbase/lib/hbase-hadoop2-compat-1.1.2.jar:/opt/hbase/lib/hbase-hadoop-compat-1.1.2.jar:/opt/hbase/lib/hbase-it-1.1.2.jar:/opt/hbase/lib/hbase-it-1.1.2-tests.jar:/opt/hbase/lib/hbase-prefix-tree-1.1.2.jar:/opt/hbase/lib/hbase-procedure-1.1.2.jar:/opt/hbase/lib/hbase-protocol-1.1.2.jar:/opt/hbase/lib/hbase-resource-bundle-1.1.2.jar:/opt/hbase/lib/hbase-rest-1.1.2.jar:/opt/hbase/lib/hbase-server-1.1.2.jar:/opt/hbase/lib/hbase-server-1.1.2-tests.jar:/opt/hbase/lib/hbase-shell-1.1.2.jar:/opt/hbase/lib/hbase-thrift-1.1.2.jar:/opt/hbase/lib/htrace-core-3.1.0-incubating.jar:/opt/hbase/lib/httpclient-4.2.5.jar:/opt/hbase/lib/httpcore-4.1.3.jar:/opt/hbase/lib/jackson-core-asl-1.9.13.jar:/opt/hbase/lib/jackson-jaxrs-1.9.13.jar:/opt/hbase/lib/jackson-mapper-asl-1.9.13.jar:/opt/hbase/lib/jackson-xc-1.9.13.jar:/opt/hbase/lib/jamon-runtime-2.3.1.jar:/opt/hbase/lib/jasper-compiler-5.5.23.jar:/opt/hbase/lib/jasper-runtime-5.5.23.jar:/opt/hbase/lib/javax.inject-1.jar:/opt/hbase/lib/java-xmlbuilder-0.4.jar:/opt/hbase/lib/jaxb-api-2.2.2.jar:/opt/hbase/lib/jaxb-impl-2.2.3-1.jar:/opt/hbase/lib/jcodings-1.0.8.jar:/opt/hbase/lib/jersey-client-1.9.jar:/opt/hbase/lib/jersey-core-1.9.jar:/opt/hbase/lib/jersey-guice-1.9.jar:/opt/hbase/lib/jersey-json-1.9.jar:/opt/hbase/lib/jersey-server-1.9.jar:/opt/hbase/lib/jets3t-0.9.0.jar:/opt/hbase/lib/jettison-1.3.3.jar:/opt/hbase/lib/jetty-6.1.26.jar:/opt/hbase/lib/jetty-sslengine-6.1.26.jar:/opt/hbase/lib/jetty-util-6.1.26.jar:/opt/hbase/lib/joni-2.1.2.jar:/opt/hbase/lib/jruby-complete-1.6.8.jar:/opt/hbase/lib/jsch-0.1.42.jar:/opt/hbase/lib/jsp-2.1-6.1.14.jar:/opt/hbase/lib/jsp-api-2.1-6.1.14.jar:/opt/hbase/lib/jsr305-1.3.9.jar:/opt/hbase/lib/junit-4.11.jar:/opt/hbase/lib/leveldbjni-all-1.8.jar:/opt/hbase/lib/libthrift-0.9.0.jar:/opt/hbase/lib/log4j-1.2.17.jar:/opt/hbase/lib/metrics-core-2.2.0.jar:/opt/hbase/lib/netty-3.2.4.Final.jar:/opt/hbase/lib/netty-all-4.0.23.Final.jar:/opt/hbase/lib/paranamer-2.3.jar:/opt/hbase/lib/protobuf-java-2.5.0.jar:/opt/hbase/lib/servlet-api-2.5-6.1.14.jar:/opt/hbase/lib/servlet-api-2.5.jar:/opt/hbase/lib/slf4j-api-1.7.7.jar:/opt/hbase/lib/slf4j-log4j12-1.7.5.jar:/opt/hbase/lib/snappy-java-1.0.4.1.jar:/opt/hbase/lib/spymemcached-2.11.6.jar:/opt/hbase/lib/xmlenc-0.52.jar:/opt/hbase/lib/xz-1.0.jar:/opt/hbase/lib/zookeeper-3.4.6.jar:/opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-auth-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/opt/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/opt/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop/share/hadoop/common/lib/curator-framework-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/opt/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/opt/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop/share/hadoop/common/lib/curator-client-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/opt/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-annotations-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/opt/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop/share/hadoop/common/lib/htrace-core-3.0.4.jar:/opt/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop/share/hadoop/common/hadoop-common-2.6.0-tests.jar:/opt/hadoop/share/hadoop/common/hadoop-common-2.6.0.jar:/opt/hadoop/share/hadoop/common/hadoop-nfs-2.6.0.jar:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/opt/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.0-tests.jar:/opt/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jline-0.9.94.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-tests.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar
2015-11-08 16:30:37,934 INFO  [main] zookeeper.ZooKeeper: Client environment:java.library.path=/opt/hadoop/lib/native::/opt/hadoop/lib/native:
2015-11-08 16:30:37,934 INFO  [main] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2015-11-08 16:30:37,934 INFO  [main] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2015-11-08 16:30:37,934 INFO  [main] zookeeper.ZooKeeper: Client environment:os.name=Linux
2015-11-08 16:30:37,934 INFO  [main] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2015-11-08 16:30:37,934 INFO  [main] zookeeper.ZooKeeper: Client environment:os.version=2.6.32-573.el6.x86_64
2015-11-08 16:30:37,934 INFO  [main] zookeeper.ZooKeeper: Client environment:user.name=hadoop
2015-11-08 16:30:37,934 INFO  [main] zookeeper.ZooKeeper: Client environment:user.home=/home/hadoop
2015-11-08 16:30:37,934 INFO  [main] zookeeper.ZooKeeper: Client environment:user.dir=/opt/hbase/logs
2015-11-08 16:30:37,935 INFO  [main] zookeeper.ZooKeeper: Initiating client connection, connectString=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181 sessionTimeout=90000 watcher=master:160000x0, quorum=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181, baseZNode=/hbase
2015-11-08 16:30:37,956 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.101/192.168.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 16:30:37,965 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.101/192.168.1.101:2181, initiating session
2015-11-08 16:30:38,081 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.101/192.168.1.101:2181, sessionid = 0x50e637ed730000, negotiated timeout = 90000
2015-11-08 16:30:38,153 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2015-11-08 16:30:38,153 INFO  [RpcServer.listener,port=16000] ipc.RpcServer: RpcServer.listener,port=16000: starting
2015-11-08 16:30:38,243 INFO  [main] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-11-08 16:30:38,249 INFO  [main] http.HttpRequestLog: Http request log for http.requests.master is not defined
2015-11-08 16:30:38,266 INFO  [main] http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.hbase.http.HttpServer$QuotingInputFilter)
2015-11-08 16:30:38,269 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context master
2015-11-08 16:30:38,269 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-11-08 16:30:38,269 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-11-08 16:30:38,302 INFO  [main] http.HttpServer: Jetty bound to port 16010
2015-11-08 16:30:38,303 INFO  [main] mortbay.log: jetty-6.1.26
2015-11-08 16:30:38,866 INFO  [main] mortbay.log: Started SelectChannelConnector@0.0.0.0:16010
2015-11-08 16:30:38,869 INFO  [main] master.HMaster: hbase.rootdir=hdfs://192.168.1.101:9000/hbase, hbase.cluster.distributed=true
2015-11-08 16:30:38,890 INFO  [main] master.HMaster: Adding backup master ZNode /hbase/backup-masters/master,16000,1446971436881
2015-11-08 16:30:39,043 INFO  [master:16000.activeMasterManager] master.ActiveMasterManager: Deleting ZNode for /hbase/backup-masters/master,16000,1446971436881 from backup master directory
2015-11-08 16:30:39,056 INFO  [master:16000.activeMasterManager] master.ActiveMasterManager: Registered Active Master=master,16000,1446971436881
2015-11-08 16:30:39,102 INFO  [master/master/192.168.1.101:16000] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x6d217978 connecting to ZooKeeper ensemble=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181
2015-11-08 16:30:39,102 INFO  [master/master/192.168.1.101:16000] zookeeper.ZooKeeper: Initiating client connection, connectString=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181 sessionTimeout=90000 watcher=hconnection-0x6d2179780x0, quorum=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181, baseZNode=/hbase
2015-11-08 16:30:39,110 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 16:30:39,114 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.102/192.168.1.102:2181, initiating session
2015-11-08 16:30:39,150 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.102/192.168.1.102:2181, sessionid = 0x150e637ea0d0000, negotiated timeout = 90000
2015-11-08 16:30:40,281 INFO  [master:16000.activeMasterManager] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2015-11-08 16:30:40,289 INFO  [master:16000.activeMasterManager] coordination.SplitLogManagerCoordination: Found 0 orphan tasks and 0 rescan nodes
2015-11-08 16:30:40,355 INFO  [master:16000.activeMasterManager] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x29e919d4 connecting to ZooKeeper ensemble=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181
2015-11-08 16:30:40,355 INFO  [master:16000.activeMasterManager] zookeeper.ZooKeeper: Initiating client connection, connectString=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181 sessionTimeout=90000 watcher=hconnection-0x29e919d40x0, quorum=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181, baseZNode=/hbase
2015-11-08 16:30:40,356 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 16:30:40,356 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.106/192.168.1.106:2181, initiating session
2015-11-08 16:30:40,364 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.106/192.168.1.106:2181, sessionid = 0x250e637ea680002, negotiated timeout = 90000
2015-11-08 16:30:40,380 INFO  [master:16000.activeMasterManager] balancer.StochasticLoadBalancer: loading config
2015-11-08 16:30:40,454 INFO  [master:16000.activeMasterManager] master.HMaster: Server active/primary master=master,16000,1446971436881, sessionid=0x50e637ed730000, setting cluster-up flag (Was=false)
2015-11-08 16:30:40,458 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: ClusterId : 18e4235c-98ec-4147-8ac4-00cf10508c80
2015-11-08 16:30:40,530 INFO  [master:16000.activeMasterManager] procedure.ZKProcedureUtil: Clearing all procedure znodes: /hbase/online-snapshot/acquired /hbase/online-snapshot/reached /hbase/online-snapshot/abort
2015-11-08 16:30:40,548 INFO  [master:16000.activeMasterManager] procedure.ZKProcedureUtil: Clearing all procedure znodes: /hbase/flush-table-proc/acquired /hbase/flush-table-proc/reached /hbase/flush-table-proc/abort
2015-11-08 16:30:40,570 INFO  [master:16000.activeMasterManager] master.MasterCoprocessorHost: System coprocessor loading is enabled
2015-11-08 16:30:40,596 INFO  [master:16000.activeMasterManager] procedure2.ProcedureExecutor: Starting procedure executor threads=5
2015-11-08 16:30:40,596 INFO  [master:16000.activeMasterManager] wal.WALProcedureStore: Starting WAL Procedure Store lease recovery
2015-11-08 16:30:40,622 INFO  [master:16000.activeMasterManager] util.FSHDFSUtils: Recovering lease on dfs file hdfs://192.168.1.101:9000/hbase/MasterProcWALs/state-00000000000000000001.log
2015-11-08 16:30:40,648 INFO  [master:16000.activeMasterManager] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://192.168.1.101:9000/hbase/MasterProcWALs/state-00000000000000000001.log after 25ms
2015-11-08 16:30:40,675 INFO  [master:16000.activeMasterManager] util.FSHDFSUtils: Recovering lease on dfs file hdfs://192.168.1.101:9000/hbase/MasterProcWALs/state-00000000000000000004.log
2015-11-08 16:30:40,676 INFO  [master:16000.activeMasterManager] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://192.168.1.101:9000/hbase/MasterProcWALs/state-00000000000000000004.log after 1ms
2015-11-08 16:30:40,760 INFO  [master:16000.activeMasterManager] wal.WALProcedureStore: Lease acquired for flushLogId: 5
2015-11-08 16:30:40,764 INFO  [master:16000.activeMasterManager] wal.ProcedureWALFormatReader: No active entry found in state log hdfs://192.168.1.101:9000/hbase/MasterProcWALs/state-00000000000000000004.log. removing it
2015-11-08 16:30:40,776 INFO  [master:16000.activeMasterManager] wal.ProcedureWALFormatReader: No active entry found in state log hdfs://192.168.1.101:9000/hbase/MasterProcWALs/state-00000000000000000001.log. removing it
2015-11-08 16:30:40,804 INFO  [master:16000.activeMasterManager] zookeeper.RecoverableZooKeeper: Process identifier=replicationLogCleaner connecting to ZooKeeper ensemble=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181
2015-11-08 16:30:40,804 INFO  [master:16000.activeMasterManager] zookeeper.ZooKeeper: Initiating client connection, connectString=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181 sessionTimeout=90000 watcher=replicationLogCleaner0x0, quorum=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181, baseZNode=/hbase
2015-11-08 16:30:40,804 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 16:30:40,804 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.106/192.168.1.106:2181, initiating session
2015-11-08 16:30:40,822 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.106/192.168.1.106:2181, sessionid = 0x250e637ea680003, negotiated timeout = 90000
2015-11-08 16:30:40,851 INFO  [master:16000.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 0 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2015-11-08 16:30:40,996 INFO  [PriorityRpcServer.handler=0,queue=0,port=16000] master.ServerManager: Registering server=master,16020,1446971438113
2015-11-08 16:30:41,001 INFO  [master:16000.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 1, slept for 150 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2015-11-08 16:30:41,743 INFO  [PriorityRpcServer.handler=2,queue=0,port=16000] master.ServerManager: Registering server=slave2,16020,1446971438717
2015-11-08 16:30:41,753 INFO  [master:16000.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 2, slept for 902 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2015-11-08 16:30:42,144 INFO  [PriorityRpcServer.handler=4,queue=0,port=16000] master.ServerManager: Registering server=slave1,16020,1446971438863
2015-11-08 16:30:42,154 INFO  [master:16000.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 3, slept for 1303 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2015-11-08 16:30:43,657 INFO  [master:16000.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 3, slept for 2806 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2015-11-08 16:30:45,161 INFO  [master:16000.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 3, slept for 4310 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2015-11-08 16:30:45,361 INFO  [master:16000.activeMasterManager] master.ServerManager: Finished waiting for region servers count to settle; checked in 3, slept for 4510 ms, expecting minimum of 1, maximum of 2147483647, master is running
2015-11-08 16:30:45,377 INFO  [master:16000.activeMasterManager] master.MasterFileSystem: Log folder hdfs://192.168.1.101:9000/hbase/WALs/master,16020,1446971438113 belongs to an existing region server
2015-11-08 16:30:45,382 INFO  [master:16000.activeMasterManager] master.MasterFileSystem: Log folder hdfs://192.168.1.101:9000/hbase/WALs/slave1,16020,1446971438863 belongs to an existing region server
2015-11-08 16:30:45,385 INFO  [master:16000.activeMasterManager] master.MasterFileSystem: Log folder hdfs://192.168.1.101:9000/hbase/WALs/slave2,16020,1446971438717 belongs to an existing region server
2015-11-08 16:30:45,626 INFO  [master:16000.activeMasterManager] zookeeper.MetaTableLocator: Failed verification of hbase:meta,,1 at address=slave1,16020,1446970023531, exception=org.apache.hadoop.hbase.NotServingRegionException: Region hbase:meta,,1 is not online on slave1,16020,1446971438863
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2898)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.getRegion(RSRpcServices.java:947)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.getRegionInfo(RSRpcServices.java:1232)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$2.callBlockingMethod(AdminProtos.java:22233)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2114)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:101)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:130)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:107)
	at java.lang.Thread.run(Thread.java:745)

2015-11-08 16:30:45,655 INFO  [master:16000.activeMasterManager] master.SplitLogManager: dead splitlog workers [slave1,16020,1446970023531]
2015-11-08 16:30:45,659 INFO  [master:16000.activeMasterManager] master.SplitLogManager: hdfs://192.168.1.101:9000/hbase/WALs/slave1,16020,1446970023531-splitting is empty dir, no logs to split
2015-11-08 16:30:45,660 INFO  [master:16000.activeMasterManager] master.SplitLogManager: started splitting 0 logs in [hdfs://192.168.1.101:9000/hbase/WALs/slave1,16020,1446970023531-splitting] for [slave1,16020,1446970023531]
2015-11-08 16:30:45,673 INFO  [master:16000.activeMasterManager] master.SplitLogManager: finished splitting (more than or equal to) 0 bytes in 0 log files in [hdfs://192.168.1.101:9000/hbase/WALs/slave1,16020,1446970023531-splitting] in 13ms
2015-11-08 16:30:45,673 INFO  [master:16000.activeMasterManager] zookeeper.MetaTableLocator: Deleting hbase:meta region location in ZooKeeper
2015-11-08 16:30:45,769 INFO  [master:16000.activeMasterManager] master.AssignmentManager: Assigning hbase:meta,,1.1588230740 to master,16020,1446971438113
2015-11-08 16:30:45,769 INFO  [master:16000.activeMasterManager] master.RegionStates: Transition {1588230740 state=OFFLINE, ts=1446971445749, server=null} to {1588230740 state=PENDING_OPEN, ts=1446971445769, server=master,16020,1446971438113}
2015-11-08 16:30:45,863 INFO  [master:16000.activeMasterManager] master.ServerManager: AssignmentManager hasn't finished failover cleanup; waiting
2015-11-08 16:30:45,925 INFO  [AM.ZK.Worker-pool2-t1] master.RegionStates: Transition {1588230740 state=PENDING_OPEN, ts=1446971445769, server=master,16020,1446971438113} to {1588230740 state=OPENING, ts=1446971445925, server=master,16020,1446971438113}
2015-11-08 16:30:46,645 INFO  [AM.ZK.Worker-pool2-t2] master.RegionStates: Transition {1588230740 state=OPENING, ts=1446971445925, server=master,16020,1446971438113} to {1588230740 state=OPEN, ts=1446971446645, server=master,16020,1446971438113}
2015-11-08 16:30:46,649 INFO  [AM.ZK.Worker-pool2-t2] coordination.ZkOpenRegionCoordination: Handling OPENED of 1588230740 from master,16000,1446971436881; deleting unassigned node
2015-11-08 16:30:46,670 INFO  [master:16000.activeMasterManager] master.HMaster: hbase:meta with replicaId 0 assigned=1, rit=false, location=master,16020,1446971438113
2015-11-08 16:30:46,849 INFO  [master:16000.activeMasterManager] hbase.MetaMigrationConvertingToPB: META already up-to date with PB serialization
2015-11-08 16:30:46,874 INFO  [master:16000.activeMasterManager] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=OPEN, ts=1446971446874, server=master,16020,1446970022735} to {6f3d653b8b106cc2df931825f52d6dec state=OFFLINE, ts=1446971446874, server=master,16020,1446970022735}
2015-11-08 16:30:46,877 INFO  [master:16000.activeMasterManager] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=OFFLINE, ts=1446971446874, server=master,16020,1446970022735} to {6f3d653b8b106cc2df931825f52d6dec state=CLOSED, ts=1446971446877, server=master,16020,1446970022735}
2015-11-08 16:30:46,879 INFO  [master:16000.activeMasterManager] master.AssignmentManager: Clean cluster startup. Assigning user regions
2015-11-08 16:30:46,894 INFO  [master:16000.activeMasterManager] balancer.BaseLoadBalancer: Reassigned 1 regions. 1 retained the pre-restart assignment. 
2015-11-08 16:30:46,894 INFO  [master:16000.activeMasterManager] master.AssignmentManager: Bulk assigning 1 region(s) across 3 server(s), retainAssignment=true
2015-11-08 16:30:46,897 INFO  [master,16000,1446971436881-GeneralBulkAssigner-0] master.AssignmentManager: Assigning 1 region(s) to master,16020,1446971438113
2015-11-08 16:30:46,900 INFO  [master,16000,1446971436881-GeneralBulkAssigner-0] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=CLOSED, ts=1446971446877, server=master,16020,1446970022735} to {6f3d653b8b106cc2df931825f52d6dec state=OFFLINE, ts=1446971446900, server=master,16020,1446970022735}
2015-11-08 16:30:46,921 INFO  [master,16000,1446971436881-GeneralBulkAssigner-0] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=OFFLINE, ts=1446971446900, server=master,16020,1446970022735} to {6f3d653b8b106cc2df931825f52d6dec state=PENDING_OPEN, ts=1446971446921, server=master,16020,1446971438113}
2015-11-08 16:30:46,982 INFO  [master:16000.activeMasterManager] master.AssignmentManager: Bulk assigning done
2015-11-08 16:30:46,986 INFO  [master:16000.activeMasterManager] master.AssignmentManager: Joined the cluster in 137ms, failover=false
2015-11-08 16:30:47,038 INFO  [AM.ZK.Worker-pool2-t5] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=PENDING_OPEN, ts=1446971446921, server=master,16020,1446971438113} to {6f3d653b8b106cc2df931825f52d6dec state=OPENING, ts=1446971447038, server=master,16020,1446971438113}
2015-11-08 16:30:47,286 INFO  [AM.ZK.Worker-pool2-t6] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=OPENING, ts=1446971447038, server=master,16020,1446971438113} to {6f3d653b8b106cc2df931825f52d6dec state=OPEN, ts=1446971447286, server=master,16020,1446971438113}
2015-11-08 16:30:47,304 INFO  [AM.ZK.Worker-pool2-t8] master.RegionStates: Offlined 6f3d653b8b106cc2df931825f52d6dec from master,16020,1446970022735
2015-11-08 16:30:47,441 INFO  [master:16000.activeMasterManager] master.HMaster: Master has completed initialization
2015-11-08 16:30:47,452 INFO  [master:16000.activeMasterManager] quotas.MasterQuotaManager: Quota support disabled
2015-11-08 16:35:47,047 INFO  [master,16000,1446971436881_ChoreService_1] master.HMaster: balance hri=hbase:namespace,,1446969270988.6f3d653b8b106cc2df931825f52d6dec., src=master,16020,1446971438113, dest=slave2,16020,1446971438717
2015-11-08 16:35:47,079 INFO  [master,16000,1446971436881_ChoreService_1] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=OPEN, ts=1446971447304, server=master,16020,1446971438113} to {6f3d653b8b106cc2df931825f52d6dec state=PENDING_CLOSE, ts=1446971747079, server=master,16020,1446971438113}
2015-11-08 16:35:47,227 INFO  [AM.ZK.Worker-pool2-t10] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=PENDING_CLOSE, ts=1446971747079, server=master,16020,1446971438113} to {6f3d653b8b106cc2df931825f52d6dec state=CLOSED, ts=1446971747227, server=master,16020,1446971438113}
2015-11-08 16:35:47,227 INFO  [AM.ZK.Worker-pool2-t10] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=CLOSED, ts=1446971747227, server=master,16020,1446971438113} to {6f3d653b8b106cc2df931825f52d6dec state=OFFLINE, ts=1446971747227, server=master,16020,1446971438113}
2015-11-08 16:35:47,238 INFO  [AM.ZK.Worker-pool2-t10] master.AssignmentManager: Assigning hbase:namespace,,1446969270988.6f3d653b8b106cc2df931825f52d6dec. to slave2,16020,1446971438717
2015-11-08 16:35:47,238 INFO  [AM.ZK.Worker-pool2-t10] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=OFFLINE, ts=1446971747227, server=master,16020,1446971438113} to {6f3d653b8b106cc2df931825f52d6dec state=PENDING_OPEN, ts=1446971747238, server=slave2,16020,1446971438717}
2015-11-08 16:35:47,561 INFO  [AM.ZK.Worker-pool2-t12] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=PENDING_OPEN, ts=1446971747238, server=slave2,16020,1446971438717} to {6f3d653b8b106cc2df931825f52d6dec state=OPENING, ts=1446971747561, server=slave2,16020,1446971438717}
2015-11-08 16:35:48,421 INFO  [AM.ZK.Worker-pool2-t13] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=OPENING, ts=1446971747561, server=slave2,16020,1446971438717} to {6f3d653b8b106cc2df931825f52d6dec state=OPEN, ts=1446971748421, server=slave2,16020,1446971438717}
2015-11-08 16:35:48,437 INFO  [AM.ZK.Worker-pool2-t15] master.RegionStates: Offlined 6f3d653b8b106cc2df931825f52d6dec from master,16020,1446971438113
Sun Nov  8 16:35:55 CST 2015 Stopping hbase (via master)
2015-11-08 16:35:57,691 INFO  [B.defaultRpcServer.handler=1,queue=1,port=16000] master.MasterRpcServices: Client=hadoop/null shutdown
2015-11-08 16:35:57,691 INFO  [B.defaultRpcServer.handler=1,queue=1,port=16000] regionserver.HRegionServer: STOPPED: Cluster shutdown requested
2015-11-08 16:35:57,691 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: Stopping infoServer
2015-11-08 16:35:57,692 INFO  [master/master/192.168.1.101:16000] mortbay.log: Stopped SelectChannelConnector@0.0.0.0:16010
2015-11-08 16:35:57,793 INFO  [master/master/192.168.1.101:16000] procedure2.ProcedureExecutor: Stopping the procedure executor
2015-11-08 16:35:57,793 INFO  [master/master/192.168.1.101:16000] wal.WALProcedureStore: Stopping the WAL Procedure Store
2015-11-08 16:35:57,931 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: stopping server master,16000,1446971436881
2015-11-08 16:35:57,931 INFO  [master/master/192.168.1.101:16000] client.ConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x150e637ea0d0000
2015-11-08 16:35:57,948 INFO  [master/master/192.168.1.101:16000] zookeeper.ZooKeeper: Session: 0x150e637ea0d0000 closed
2015-11-08 16:35:57,948 INFO  [master/master/192.168.1.101:16000-EventThread] zookeeper.ClientCnxn: EventThread shut down
2015-11-08 16:35:58,049 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: stopping server master,16000,1446971436881; all regions closed.
2015-11-08 16:35:58,050 INFO  [master/master/192.168.1.101:16000] hbase.ChoreService: Chore service for: master,16000,1446971436881 had [[ScheduledChore: Name: CatalogJanitor-master:16000 Period: 300000 Unit: MILLISECONDS], [ScheduledChore: Name: HFileCleaner Period: 60000 Unit: MILLISECONDS], [ScheduledChore: Name: master,16000,1446971436881-ClusterStatusChore Period: 60000 Unit: MILLISECONDS], [ScheduledChore: Name: LogsCleaner Period: 60000 Unit: MILLISECONDS], [ScheduledChore: Name: master,16000,1446971436881-BalancerChore Period: 300000 Unit: MILLISECONDS]] on shutdown
2015-11-08 16:35:58,050 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave2,16020,1446971438717, master,16020,1446971438113, slave1,16020,1446971438863
2015-11-08 16:35:58,290 INFO  [master,16000,1446971436881_splitLogManager__ChoreService_1] master.SplitLogManager$TimeoutMonitor: Chore: SplitLogManager Timeout Monitor was stopped
2015-11-08 16:35:59,060 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave2,16020,1446971438717, master,16020,1446971438113, slave1,16020,1446971438863
2015-11-08 16:36:00,071 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave2,16020,1446971438717, master,16020,1446971438113, slave1,16020,1446971438863
2015-11-08 16:36:01,080 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave2,16020,1446971438717, master,16020,1446971438113, slave1,16020,1446971438863
2015-11-08 16:36:02,093 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave2,16020,1446971438717, master,16020,1446971438113, slave1,16020,1446971438863
2015-11-08 16:36:03,101 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave2,16020,1446971438717, master,16020,1446971438113, slave1,16020,1446971438863
2015-11-08 16:36:03,135 INFO  [main-EventThread] zookeeper.RegionServerTracker: RegionServer ephemeral node deleted, processing expiration [slave1,16020,1446971438863]
2015-11-08 16:36:03,136 INFO  [main-EventThread] master.ServerManager: Cluster shutdown set; slave1,16020,1446971438863 expired; onlineServers=2
2015-11-08 16:36:04,145 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave2,16020,1446971438717, master,16020,1446971438113
2015-11-08 16:36:05,153 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave2,16020,1446971438717, master,16020,1446971438113
2015-11-08 16:36:06,161 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave2,16020,1446971438717, master,16020,1446971438113
2015-11-08 16:36:07,170 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave2,16020,1446971438717, master,16020,1446971438113
2015-11-08 16:36:07,317 INFO  [main-EventThread] zookeeper.RegionServerTracker: RegionServer ephemeral node deleted, processing expiration [master,16020,1446971438113]
2015-11-08 16:36:07,317 INFO  [main-EventThread] master.ServerManager: Cluster shutdown set; master,16020,1446971438113 expired; onlineServers=1
2015-11-08 16:36:08,226 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave2,16020,1446971438717
2015-11-08 16:36:08,593 INFO  [main-EventThread] zookeeper.RegionServerTracker: RegionServer ephemeral node deleted, processing expiration [slave2,16020,1446971438717]
2015-11-08 16:36:08,593 INFO  [main-EventThread] master.ServerManager: Cluster shutdown set; slave2,16020,1446971438717 expired; onlineServers=0
2015-11-08 16:36:08,607 INFO  [master/master/192.168.1.101:16000] client.ConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x250e637ea680002
2015-11-08 16:36:08,616 INFO  [master/master/192.168.1.101:16000] zookeeper.ZooKeeper: Session: 0x250e637ea680002 closed
2015-11-08 16:36:08,616 INFO  [master:16000.activeMasterManager-EventThread] zookeeper.ClientCnxn: EventThread shut down
2015-11-08 16:36:08,717 INFO  [master/master/192.168.1.101:16000] hbase.ChoreService: Chore service for: master,16000,1446971436881_splitLogManager_ had [] on shutdown
2015-11-08 16:36:08,717 INFO  [master/master/192.168.1.101:16000] flush.MasterFlushTableProcedureManager: stop: server shutting down.
2015-11-08 16:36:08,718 INFO  [master/master/192.168.1.101:16000] ipc.RpcServer: Stopping server on 16000
2015-11-08 16:36:08,718 INFO  [RpcServer.listener,port=16000] ipc.RpcServer: RpcServer.listener,port=16000: stopping
2015-11-08 16:36:08,718 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopped
2015-11-08 16:36:08,718 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopping
2015-11-08 16:36:08,732 INFO  [master/master/192.168.1.101:16000] zookeeper.RecoverableZooKeeper: Node /hbase/rs/master,16000,1446971436881 already deleted, retry=false
2015-11-08 16:36:08,741 INFO  [master/master/192.168.1.101:16000] zookeeper.ZooKeeper: Session: 0x50e637ed730000 closed
2015-11-08 16:36:08,741 INFO  [main-EventThread] zookeeper.ClientCnxn: EventThread shut down
2015-11-08 16:36:08,741 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: stopping server master,16000,1446971436881; zookeeper connection closed.
2015-11-08 16:36:08,741 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: master/master/192.168.1.101:16000 exiting
Sun Nov  8 16:36:12 CST 2015 Stopping hbase (via master)
Sun Nov  8 16:41:26 CST 2015 Stopping hbase (via master)
Sun Nov  8 16:41:32 CST 2015 Starting master on master
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 30141
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 10240
cpu time               (seconds, -t) unlimited
max user processes              (-u) 1024
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2015-11-08 16:41:33,139 INFO  [main] util.VersionInfo: HBase 1.1.2
2015-11-08 16:41:33,139 INFO  [main] util.VersionInfo: Source code repository git://hw11397.local/Volumes/hbase-1.1.2RC2/hbase revision=cc2b70cf03e3378800661ec5cab11eb43fafe0fc
2015-11-08 16:41:33,139 INFO  [main] util.VersionInfo: Compiled by ndimiduk on Wed Aug 26 20:11:27 PDT 2015
2015-11-08 16:41:33,139 INFO  [main] util.VersionInfo: From source with checksum 73da41f3d1b867b7aba6166c77fafc17
2015-11-08 16:41:33,457 INFO  [main] util.ServerCommandLine: env:TERM=xterm
2015-11-08 16:41:33,457 INFO  [main] util.ServerCommandLine: env:HADOOP_COMMON_LIB_NATIVE_DIR=/opt/hadoop/lib/native
2015-11-08 16:41:33,457 INFO  [main] util.ServerCommandLine: env:IMSETTINGS_MODULE=none
2015-11-08 16:41:33,457 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/opt/java
2015-11-08 16:41:33,458 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/opt/hbase
2015-11-08 16:41:33,458 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2015-11-08 16:41:33,458 INFO  [main] util.ServerCommandLine: env:SESSION_MANAGER=local/unix:@/tmp/.ICE-unix/2957,unix/unix:/tmp/.ICE-unix/2957
2015-11-08 16:41:33,458 INFO  [main] util.ServerCommandLine: env:IMSETTINGS_INTEGRATE_DESKTOP=yes
2015-11-08 16:41:33,458 INFO  [main] util.ServerCommandLine: env:GNOME_DESKTOP_SESSION_ID=this-is-deprecated
2015-11-08 16:41:33,458 INFO  [main] util.ServerCommandLine: env:MAIL=/var/spool/mail/hadoop
2015-11-08 16:41:33,458 INFO  [main] util.ServerCommandLine: env:XDG_SESSION_COOKIE=ab8c9d4f5491283c7c300d7800000013-1446970837.780533-57183565
2015-11-08 16:41:33,458 INFO  [main] util.ServerCommandLine: env:GDMSESSION=gnome
2015-11-08 16:41:33,458 INFO  [main] util.ServerCommandLine: env:HOSTNAME=master
2015-11-08 16:41:33,458 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/tmp/hbase-hadoop-master.znode
2015-11-08 16:41:33,458 INFO  [main] util.ServerCommandLine: env:PWD=/opt/hbase/bin
2015-11-08 16:41:33,458 INFO  [main] util.ServerCommandLine: env:HBASE_MASTER_OPTS= -XX:PermSize=128m -XX:MaxPermSize=128m
2015-11-08 16:41:33,458 INFO  [main] util.ServerCommandLine: env:CVS_RSH=ssh
2015-11-08 16:41:33,458 INFO  [main] util.ServerCommandLine: env:JAVA_LIBRARY_PATH=/opt/hadoop/lib/native::/opt/hadoop/lib/native:
2015-11-08 16:41:33,458 INFO  [main] util.ServerCommandLine: env:G_BROKEN_FILENAMES=1
2015-11-08 16:41:33,458 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2015-11-08 16:41:33,458 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2015-11-08 16:41:33,458 INFO  [main] util.ServerCommandLine: env:NLSPATH=/usr/dt/lib/nls/msg/%L/%N.cat
2015-11-08 16:41:33,458 INFO  [main] util.ServerCommandLine: env:GNOME_KEYRING_SOCKET=/tmp/keyring-8q0f1M/socket
2015-11-08 16:41:33,458 INFO  [main] util.ServerCommandLine: env:GDM_KEYBOARD_LAYOUT=us
2015-11-08 16:41:33,459 INFO  [main] util.ServerCommandLine: env:HBASE_REGIONSERVER_OPTS= -XX:PermSize=128m -XX:MaxPermSize=128m
2015-11-08 16:41:33,459 INFO  [main] util.ServerCommandLine: env:HISTSIZE=1000
2015-11-08 16:41:33,459 INFO  [main] util.ServerCommandLine: env:PATH=/opt/hbase:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin:/sbin:/opt/java//bin:/opt/java/jre/bin:/opt/hadoop/bin:/home/hadoop/bin
2015-11-08 16:41:33,459 INFO  [main] util.ServerCommandLine: env:QTLIB=/usr/lib64/qt-3.3/lib
2015-11-08 16:41:33,459 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2015-11-08 16:41:33,459 INFO  [main] util.ServerCommandLine: env:GDM_LANG=en_US.UTF-8
2015-11-08 16:41:33,459 INFO  [main] util.ServerCommandLine: env:XAUTHORITY=/var/run/gdm/auth-for-hadoop-ApHB7y/database
2015-11-08 16:41:33,459 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/tmp/hbase-hadoop-master.autorestart
2015-11-08 16:41:33,459 INFO  [main] util.ServerCommandLine: env:USERNAME=hadoop
2015-11-08 16:41:33,459 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-hadoop-master-master.log
2015-11-08 16:41:33,459 INFO  [main] util.ServerCommandLine: env:SSH_ASKPASS=/usr/libexec/openssh/gnome-ssh-askpass
2015-11-08 16:41:33,459 INFO  [main] util.ServerCommandLine: env:SHLVL=6
2015-11-08 16:41:33,459 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/opt/hbase/logs
2015-11-08 16:41:33,459 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-XX:+UseConcMarkSweepGC   -XX:PermSize=128m -XX:MaxPermSize=128m -Dhbase.log.dir=/opt/hbase/logs -Dhbase.log.file=hbase-hadoop-master-master.log -Dhbase.home.dir=/opt/hbase -Dhbase.id.str=hadoop -Dhbase.root.logger=INFO,RFA -Djava.library.path=/opt/hadoop/lib/native::/opt/hadoop/lib/native: -Dhbase.security.logger=INFO,RFAS
2015-11-08 16:41:33,459 INFO  [main] util.ServerCommandLine: env:XFILESEARCHPATH=/usr/dt/app-defaults/%L/Dt
2015-11-08 16:41:33,459 INFO  [main] util.ServerCommandLine: env:COLORTERM=gnome-terminal
2015-11-08 16:41:33,460 INFO  [main] util.ServerCommandLine: env:QT_IM_MODULE=xim
2015-11-08 16:41:33,460 INFO  [main] util.ServerCommandLine: env:WINDOWID=23070438
2015-11-08 16:41:33,460 INFO  [main] util.ServerCommandLine: env:LOGNAME=hadoop
2015-11-08 16:41:33,460 INFO  [main] util.ServerCommandLine: env:QTDIR=/usr/lib64/qt-3.3
2015-11-08 16:41:33,460 INFO  [main] util.ServerCommandLine: env:XMODIFIERS=@im=none
2015-11-08 16:41:33,460 INFO  [main] util.ServerCommandLine: env:SSH_AUTH_SOCK=/tmp/keyring-8q0f1M/socket.ssh
2015-11-08 16:41:33,460 INFO  [main] util.ServerCommandLine: env:HADOOP_HOME=/opt/hadoop
2015-11-08 16:41:33,460 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=:/opt/hadoop/lib/native::/opt/hadoop/lib/native:
2015-11-08 16:41:33,460 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2015-11-08 16:41:33,460 INFO  [main] util.ServerCommandLine: env:HADOOP_OPTS=-Djava.library.path=/opt/hadoop/lib/native
2015-11-08 16:41:33,460 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2015-11-08 16:41:33,460 INFO  [main] util.ServerCommandLine: env:DBUS_SESSION_BUS_ADDRESS=unix:abstract=/tmp/dbus-BE8cSLU3kg,guid=266d9eaea9c6327e69c81ff6000000c7
2015-11-08 16:41:33,460 INFO  [main] util.ServerCommandLine: env:GNOME_KEYRING_PID=2947
2015-11-08 16:41:33,460 INFO  [main] util.ServerCommandLine: env:GTK_RC_FILES=/etc/gtk/gtkrc:/home/hadoop/.gtkrc-1.2-gnome2
2015-11-08 16:41:33,460 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2015-11-08 16:41:33,461 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/opt/hbase/conf:/opt/java/lib/tools.jar:/opt/hbase:/opt/hbase/lib/activation-1.1.jar:/opt/hbase/lib/aopalliance-1.0.jar:/opt/hbase/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hbase/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hbase/lib/api-asn1-api-1.0.0-M20.jar:/opt/hbase/lib/api-util-1.0.0-M20.jar:/opt/hbase/lib/asm-3.1.jar:/opt/hbase/lib/avro-1.7.4.jar:/opt/hbase/lib/commons-beanutils-1.7.0.jar:/opt/hbase/lib/commons-beanutils-core-1.8.0.jar:/opt/hbase/lib/commons-cli-1.2.jar:/opt/hbase/lib/commons-codec-1.9.jar:/opt/hbase/lib/commons-collections-3.2.1.jar:/opt/hbase/lib/commons-compress-1.4.1.jar:/opt/hbase/lib/commons-configuration-1.6.jar:/opt/hbase/lib/commons-daemon-1.0.13.jar:/opt/hbase/lib/commons-digester-1.8.jar:/opt/hbase/lib/commons-el-1.0.jar:/opt/hbase/lib/commons-httpclient-3.1.jar:/opt/hbase/lib/commons-io-2.4.jar:/opt/hbase/lib/commons-lang-2.6.jar:/opt/hbase/lib/commons-logging-1.2.jar:/opt/hbase/lib/commons-math-2.2.jar:/opt/hbase/lib/commons-math3-3.1.1.jar:/opt/hbase/lib/commons-net-3.1.jar:/opt/hbase/lib/disruptor-3.3.0.jar:/opt/hbase/lib/findbugs-annotations-1.3.9-1.jar:/opt/hbase/lib/guava-12.0.1.jar:/opt/hbase/lib/guice-3.0.jar:/opt/hbase/lib/guice-servlet-3.0.jar:/opt/hbase/lib/hadoop-annotations-2.5.1.jar:/opt/hbase/lib/hadoop-auth-2.5.1.jar:/opt/hbase/lib/hadoop-client-2.5.1.jar:/opt/hbase/lib/hadoop-common-2.5.1.jar:/opt/hbase/lib/hadoop-hdfs-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-app-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-common-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-core-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-jobclient-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-shuffle-2.5.1.jar:/opt/hbase/lib/hadoop-yarn-api-2.5.1.jar:/opt/hbase/lib/hadoop-yarn-client-2.5.1.jar:/opt/hbase/lib/hadoop-yarn-common-2.5.1.jar:/opt/hbase/lib/hadoop-yarn-server-common-2.5.1.jar:/opt/hbase/lib/hbase-annotations-1.1.2.jar:/opt/hbase/lib/hbase-annotations-1.1.2-tests.jar:/opt/hbase/lib/hbase-client-1.1.2.jar:/opt/hbase/lib/hbase-common-1.1.2.jar:/opt/hbase/lib/hbase-common-1.1.2-tests.jar:/opt/hbase/lib/hbase-examples-1.1.2.jar:/opt/hbase/lib/hbase-hadoop2-compat-1.1.2.jar:/opt/hbase/lib/hbase-hadoop-compat-1.1.2.jar:/opt/hbase/lib/hbase-it-1.1.2.jar:/opt/hbase/lib/hbase-it-1.1.2-tests.jar:/opt/hbase/lib/hbase-prefix-tree-1.1.2.jar:/opt/hbase/lib/hbase-procedure-1.1.2.jar:/opt/hbase/lib/hbase-protocol-1.1.2.jar:/opt/hbase/lib/hbase-resource-bundle-1.1.2.jar:/opt/hbase/lib/hbase-rest-1.1.2.jar:/opt/hbase/lib/hbase-server-1.1.2.jar:/opt/hbase/lib/hbase-server-1.1.2-tests.jar:/opt/hbase/lib/hbase-shell-1.1.2.jar:/opt/hbase/lib/hbase-thrift-1.1.2.jar:/opt/hbase/lib/htrace-core-3.1.0-incubating.jar:/opt/hbase/lib/httpclient-4.2.5.jar:/opt/hbase/lib/httpcore-4.1.3.jar:/opt/hbase/lib/jackson-core-asl-1.9.13.jar:/opt/hbase/lib/jackson-jaxrs-1.9.13.jar:/opt/hbase/lib/jackson-mapper-asl-1.9.13.jar:/opt/hbase/lib/jackson-xc-1.9.13.jar:/opt/hbase/lib/jamon-runtime-2.3.1.jar:/opt/hbase/lib/jasper-compiler-5.5.23.jar:/opt/hbase/lib/jasper-runtime-5.5.23.jar:/opt/hbase/lib/javax.inject-1.jar:/opt/hbase/lib/java-xmlbuilder-0.4.jar:/opt/hbase/lib/jaxb-api-2.2.2.jar:/opt/hbase/lib/jaxb-impl-2.2.3-1.jar:/opt/hbase/lib/jcodings-1.0.8.jar:/opt/hbase/lib/jersey-client-1.9.jar:/opt/hbase/lib/jersey-core-1.9.jar:/opt/hbase/lib/jersey-guice-1.9.jar:/opt/hbase/lib/jersey-json-1.9.jar:/opt/hbase/lib/jersey-server-1.9.jar:/opt/hbase/lib/jets3t-0.9.0.jar:/opt/hbase/lib/jettison-1.3.3.jar:/opt/hbase/lib/jetty-6.1.26.jar:/opt/hbase/lib/jetty-sslengine-6.1.26.jar:/opt/hbase/lib/jetty-util-6.1.26.jar:/opt/hbase/lib/joni-2.1.2.jar:/opt/hbase/lib/jruby-complete-1.6.8.jar:/opt/hbase/lib/jsch-0.1.42.jar:/opt/hbase/lib/jsp-2.1-6.1.14.jar:/opt/hbase/lib/jsp-api-2.1-6.1.14.jar:/opt/hbase/lib/jsr305-1.3.9.jar:/opt/hbase/lib/junit-4.11.jar:/opt/hbase/lib/leveldbjni-all-1.8.jar:/opt/hbase/lib/libthrift-0.9.0.jar:/opt/hbase/lib/log4j-1.2.17.jar:/opt/hbase/lib/metrics-core-2.2.0.jar:/opt/hbase/lib/netty-3.2.4.Final.jar:/opt/hbase/lib/netty-all-4.0.23.Final.jar:/opt/hbase/lib/paranamer-2.3.jar:/opt/hbase/lib/protobuf-java-2.5.0.jar:/opt/hbase/lib/servlet-api-2.5-6.1.14.jar:/opt/hbase/lib/servlet-api-2.5.jar:/opt/hbase/lib/slf4j-api-1.7.7.jar:/opt/hbase/lib/slf4j-log4j12-1.7.5.jar:/opt/hbase/lib/snappy-java-1.0.4.1.jar:/opt/hbase/lib/spymemcached-2.11.6.jar:/opt/hbase/lib/xmlenc-0.52.jar:/opt/hbase/lib/xz-1.0.jar:/opt/hbase/lib/zookeeper-3.4.6.jar:/opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/contrib/capacity-scheduler/*.jar
2015-11-08 16:41:33,461 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2015-11-08 16:41:33,462 INFO  [main] util.ServerCommandLine: env:JRE_HOME=/opt/java/jre
2015-11-08 16:41:33,462 INFO  [main] util.ServerCommandLine: env:DESKTOP_SESSION=gnome
2015-11-08 16:41:33,462 INFO  [main] util.ServerCommandLine: env:QTINC=/usr/lib64/qt-3.3/include
2015-11-08 16:41:33,462 INFO  [main] util.ServerCommandLine: env:DISPLAY=192.168.1.100:1.0
2015-11-08 16:41:33,462 INFO  [main] util.ServerCommandLine: env:USER=hadoop
2015-11-08 16:41:33,462 INFO  [main] util.ServerCommandLine: env:HISTCONTROL=ignoredups
2015-11-08 16:41:33,462 INFO  [main] util.ServerCommandLine: env:HOME=/home/hadoop
2015-11-08 16:41:33,462 INFO  [main] util.ServerCommandLine: env:LESSOPEN=||/usr/bin/lesspipe.sh %s
2015-11-08 16:41:33,462 INFO  [main] util.ServerCommandLine: env:ORBIT_SOCKETDIR=/tmp/orbit-hadoop
2015-11-08 16:41:33,462 INFO  [main] util.ServerCommandLine: env:LANG=en_US.UTF-8
2015-11-08 16:41:33,462 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-hadoop-master-master
2015-11-08 16:41:33,462 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=hadoop
2015-11-08 16:41:33,464 INFO  [main] util.ServerCommandLine: vmName=Java HotSpot(TM) 64-Bit Server VM, vmVendor=Oracle Corporation, vmVersion=24.79-b02
2015-11-08 16:41:33,464 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_master, -XX:OnOutOfMemoryError=kill -9 %p, -XX:+UseConcMarkSweepGC, -XX:PermSize=128m, -XX:MaxPermSize=128m, -Dhbase.log.dir=/opt/hbase/logs, -Dhbase.log.file=hbase-hadoop-master-master.log, -Dhbase.home.dir=/opt/hbase, -Dhbase.id.str=hadoop, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=/opt/hadoop/lib/native::/opt/hadoop/lib/native:, -Dhbase.security.logger=INFO,RFAS]
2015-11-08 16:41:33,906 WARN  [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-11-08 16:41:34,181 INFO  [main] regionserver.RSRpcServices: master/master/192.168.1.101:16000 server-side HConnection retries=350
2015-11-08 16:41:34,384 INFO  [main] ipc.SimpleRpcScheduler: Using deadline as user call queue, count=3
2015-11-08 16:41:34,400 INFO  [main] ipc.RpcServer: master/master/192.168.1.101:16000: started 10 reader(s).
2015-11-08 16:41:34,458 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2015-11-08 16:41:34,520 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-11-08 16:41:34,520 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2015-11-08 16:41:35,346 INFO  [main] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2015-11-08 16:41:35,656 INFO  [main] zookeeper.RecoverableZooKeeper: Process identifier=master:16000 connecting to ZooKeeper ensemble=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181
2015-11-08 16:41:35,662 INFO  [main] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2015-11-08 16:41:35,662 INFO  [main] zookeeper.ZooKeeper: Client environment:host.name=master
2015-11-08 16:41:35,662 INFO  [main] zookeeper.ZooKeeper: Client environment:java.version=1.7.0_79
2015-11-08 16:41:35,662 INFO  [main] zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
2015-11-08 16:41:35,662 INFO  [main] zookeeper.ZooKeeper: Client environment:java.home=/opt/java/jre
2015-11-08 16:41:35,662 INFO  [main] zookeeper.ZooKeeper: Client environment:java.class.path=/opt/hbase/conf:/opt/java/lib/tools.jar:/opt/hbase:/opt/hbase/lib/activation-1.1.jar:/opt/hbase/lib/aopalliance-1.0.jar:/opt/hbase/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hbase/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hbase/lib/api-asn1-api-1.0.0-M20.jar:/opt/hbase/lib/api-util-1.0.0-M20.jar:/opt/hbase/lib/asm-3.1.jar:/opt/hbase/lib/avro-1.7.4.jar:/opt/hbase/lib/commons-beanutils-1.7.0.jar:/opt/hbase/lib/commons-beanutils-core-1.8.0.jar:/opt/hbase/lib/commons-cli-1.2.jar:/opt/hbase/lib/commons-codec-1.9.jar:/opt/hbase/lib/commons-collections-3.2.1.jar:/opt/hbase/lib/commons-compress-1.4.1.jar:/opt/hbase/lib/commons-configuration-1.6.jar:/opt/hbase/lib/commons-daemon-1.0.13.jar:/opt/hbase/lib/commons-digester-1.8.jar:/opt/hbase/lib/commons-el-1.0.jar:/opt/hbase/lib/commons-httpclient-3.1.jar:/opt/hbase/lib/commons-io-2.4.jar:/opt/hbase/lib/commons-lang-2.6.jar:/opt/hbase/lib/commons-logging-1.2.jar:/opt/hbase/lib/commons-math-2.2.jar:/opt/hbase/lib/commons-math3-3.1.1.jar:/opt/hbase/lib/commons-net-3.1.jar:/opt/hbase/lib/disruptor-3.3.0.jar:/opt/hbase/lib/findbugs-annotations-1.3.9-1.jar:/opt/hbase/lib/guava-12.0.1.jar:/opt/hbase/lib/guice-3.0.jar:/opt/hbase/lib/guice-servlet-3.0.jar:/opt/hbase/lib/hadoop-annotations-2.5.1.jar:/opt/hbase/lib/hadoop-auth-2.5.1.jar:/opt/hbase/lib/hadoop-client-2.5.1.jar:/opt/hbase/lib/hadoop-common-2.5.1.jar:/opt/hbase/lib/hadoop-hdfs-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-app-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-common-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-core-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-jobclient-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-shuffle-2.5.1.jar:/opt/hbase/lib/hadoop-yarn-api-2.5.1.jar:/opt/hbase/lib/hadoop-yarn-client-2.5.1.jar:/opt/hbase/lib/hadoop-yarn-common-2.5.1.jar:/opt/hbase/lib/hadoop-yarn-server-common-2.5.1.jar:/opt/hbase/lib/hbase-annotations-1.1.2.jar:/opt/hbase/lib/hbase-annotations-1.1.2-tests.jar:/opt/hbase/lib/hbase-client-1.1.2.jar:/opt/hbase/lib/hbase-common-1.1.2.jar:/opt/hbase/lib/hbase-common-1.1.2-tests.jar:/opt/hbase/lib/hbase-examples-1.1.2.jar:/opt/hbase/lib/hbase-hadoop2-compat-1.1.2.jar:/opt/hbase/lib/hbase-hadoop-compat-1.1.2.jar:/opt/hbase/lib/hbase-it-1.1.2.jar:/opt/hbase/lib/hbase-it-1.1.2-tests.jar:/opt/hbase/lib/hbase-prefix-tree-1.1.2.jar:/opt/hbase/lib/hbase-procedure-1.1.2.jar:/opt/hbase/lib/hbase-protocol-1.1.2.jar:/opt/hbase/lib/hbase-resource-bundle-1.1.2.jar:/opt/hbase/lib/hbase-rest-1.1.2.jar:/opt/hbase/lib/hbase-server-1.1.2.jar:/opt/hbase/lib/hbase-server-1.1.2-tests.jar:/opt/hbase/lib/hbase-shell-1.1.2.jar:/opt/hbase/lib/hbase-thrift-1.1.2.jar:/opt/hbase/lib/htrace-core-3.1.0-incubating.jar:/opt/hbase/lib/httpclient-4.2.5.jar:/opt/hbase/lib/httpcore-4.1.3.jar:/opt/hbase/lib/jackson-core-asl-1.9.13.jar:/opt/hbase/lib/jackson-jaxrs-1.9.13.jar:/opt/hbase/lib/jackson-mapper-asl-1.9.13.jar:/opt/hbase/lib/jackson-xc-1.9.13.jar:/opt/hbase/lib/jamon-runtime-2.3.1.jar:/opt/hbase/lib/jasper-compiler-5.5.23.jar:/opt/hbase/lib/jasper-runtime-5.5.23.jar:/opt/hbase/lib/javax.inject-1.jar:/opt/hbase/lib/java-xmlbuilder-0.4.jar:/opt/hbase/lib/jaxb-api-2.2.2.jar:/opt/hbase/lib/jaxb-impl-2.2.3-1.jar:/opt/hbase/lib/jcodings-1.0.8.jar:/opt/hbase/lib/jersey-client-1.9.jar:/opt/hbase/lib/jersey-core-1.9.jar:/opt/hbase/lib/jersey-guice-1.9.jar:/opt/hbase/lib/jersey-json-1.9.jar:/opt/hbase/lib/jersey-server-1.9.jar:/opt/hbase/lib/jets3t-0.9.0.jar:/opt/hbase/lib/jettison-1.3.3.jar:/opt/hbase/lib/jetty-6.1.26.jar:/opt/hbase/lib/jetty-sslengine-6.1.26.jar:/opt/hbase/lib/jetty-util-6.1.26.jar:/opt/hbase/lib/joni-2.1.2.jar:/opt/hbase/lib/jruby-complete-1.6.8.jar:/opt/hbase/lib/jsch-0.1.42.jar:/opt/hbase/lib/jsp-2.1-6.1.14.jar:/opt/hbase/lib/jsp-api-2.1-6.1.14.jar:/opt/hbase/lib/jsr305-1.3.9.jar:/opt/hbase/lib/junit-4.11.jar:/opt/hbase/lib/leveldbjni-all-1.8.jar:/opt/hbase/lib/libthrift-0.9.0.jar:/opt/hbase/lib/log4j-1.2.17.jar:/opt/hbase/lib/metrics-core-2.2.0.jar:/opt/hbase/lib/netty-3.2.4.Final.jar:/opt/hbase/lib/netty-all-4.0.23.Final.jar:/opt/hbase/lib/paranamer-2.3.jar:/opt/hbase/lib/protobuf-java-2.5.0.jar:/opt/hbase/lib/servlet-api-2.5-6.1.14.jar:/opt/hbase/lib/servlet-api-2.5.jar:/opt/hbase/lib/slf4j-api-1.7.7.jar:/opt/hbase/lib/slf4j-log4j12-1.7.5.jar:/opt/hbase/lib/snappy-java-1.0.4.1.jar:/opt/hbase/lib/spymemcached-2.11.6.jar:/opt/hbase/lib/xmlenc-0.52.jar:/opt/hbase/lib/xz-1.0.jar:/opt/hbase/lib/zookeeper-3.4.6.jar:/opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-auth-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/opt/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/opt/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop/share/hadoop/common/lib/curator-framework-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/opt/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/opt/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop/share/hadoop/common/lib/curator-client-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/opt/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-annotations-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/opt/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop/share/hadoop/common/lib/htrace-core-3.0.4.jar:/opt/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop/share/hadoop/common/hadoop-common-2.6.0-tests.jar:/opt/hadoop/share/hadoop/common/hadoop-common-2.6.0.jar:/opt/hadoop/share/hadoop/common/hadoop-nfs-2.6.0.jar:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/opt/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.0-tests.jar:/opt/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jline-0.9.94.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-tests.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar
2015-11-08 16:41:35,662 INFO  [main] zookeeper.ZooKeeper: Client environment:java.library.path=/opt/hadoop/lib/native::/opt/hadoop/lib/native:
2015-11-08 16:41:35,662 INFO  [main] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2015-11-08 16:41:35,662 INFO  [main] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2015-11-08 16:41:35,662 INFO  [main] zookeeper.ZooKeeper: Client environment:os.name=Linux
2015-11-08 16:41:35,662 INFO  [main] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2015-11-08 16:41:35,662 INFO  [main] zookeeper.ZooKeeper: Client environment:os.version=2.6.32-573.el6.x86_64
2015-11-08 16:41:35,662 INFO  [main] zookeeper.ZooKeeper: Client environment:user.name=hadoop
2015-11-08 16:41:35,662 INFO  [main] zookeeper.ZooKeeper: Client environment:user.home=/home/hadoop
2015-11-08 16:41:35,662 INFO  [main] zookeeper.ZooKeeper: Client environment:user.dir=/opt/hbase/bin
2015-11-08 16:41:35,663 INFO  [main] zookeeper.ZooKeeper: Initiating client connection, connectString=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181 sessionTimeout=90000 watcher=master:160000x0, quorum=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181, baseZNode=/hbase
2015-11-08 16:41:35,677 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.101/192.168.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 16:41:35,680 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.101/192.168.1.101:2181, initiating session
2015-11-08 16:41:35,710 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.101/192.168.1.101:2181, sessionid = 0x50e641f6a70000, negotiated timeout = 90000
2015-11-08 16:41:35,786 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2015-11-08 16:41:35,787 INFO  [RpcServer.listener,port=16000] ipc.RpcServer: RpcServer.listener,port=16000: starting
2015-11-08 16:41:35,858 INFO  [main] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-11-08 16:41:35,861 INFO  [main] http.HttpRequestLog: Http request log for http.requests.master is not defined
2015-11-08 16:41:35,873 INFO  [main] http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.hbase.http.HttpServer$QuotingInputFilter)
2015-11-08 16:41:35,876 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context master
2015-11-08 16:41:35,876 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-11-08 16:41:35,876 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-11-08 16:41:35,898 INFO  [main] http.HttpServer: Jetty bound to port 16010
2015-11-08 16:41:35,898 INFO  [main] mortbay.log: jetty-6.1.26
2015-11-08 16:41:36,431 INFO  [main] mortbay.log: Started SelectChannelConnector@0.0.0.0:16010
2015-11-08 16:41:36,443 INFO  [main] master.HMaster: hbase.rootdir=hdfs://192.168.1.101:9000/hbase, hbase.cluster.distributed=true
2015-11-08 16:41:36,460 INFO  [main] master.HMaster: Adding backup master ZNode /hbase/backup-masters/master,16000,1446972094536
2015-11-08 16:41:36,629 INFO  [master:16000.activeMasterManager] master.ActiveMasterManager: Deleting ZNode for /hbase/backup-masters/master,16000,1446972094536 from backup master directory
2015-11-08 16:41:36,643 INFO  [master:16000.activeMasterManager] master.ActiveMasterManager: Registered Active Master=master,16000,1446972094536
2015-11-08 16:41:36,768 INFO  [master/master/192.168.1.101:16000] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x55a0eb24 connecting to ZooKeeper ensemble=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181
2015-11-08 16:41:36,768 INFO  [master/master/192.168.1.101:16000] zookeeper.ZooKeeper: Initiating client connection, connectString=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181 sessionTimeout=90000 watcher=hconnection-0x55a0eb240x0, quorum=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181, baseZNode=/hbase
2015-11-08 16:41:36,775 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 16:41:36,781 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.102/192.168.1.102:2181, initiating session
2015-11-08 16:41:36,806 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.102/192.168.1.102:2181, sessionid = 0x150e641f3350000, negotiated timeout = 90000
2015-11-08 16:41:37,235 INFO  [master:16000.activeMasterManager] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2015-11-08 16:41:37,244 INFO  [master:16000.activeMasterManager] coordination.SplitLogManagerCoordination: Found 0 orphan tasks and 0 rescan nodes
2015-11-08 16:41:37,294 INFO  [master:16000.activeMasterManager] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0xf7a18d9 connecting to ZooKeeper ensemble=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181
2015-11-08 16:41:37,294 INFO  [master:16000.activeMasterManager] zookeeper.ZooKeeper: Initiating client connection, connectString=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181 sessionTimeout=90000 watcher=hconnection-0xf7a18d90x0, quorum=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181, baseZNode=/hbase
2015-11-08 16:41:37,295 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 16:41:37,300 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.106/192.168.1.106:2181, initiating session
2015-11-08 16:41:37,310 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.106/192.168.1.106:2181, sessionid = 0x250e641f3940001, negotiated timeout = 90000
2015-11-08 16:41:37,352 INFO  [master:16000.activeMasterManager] balancer.StochasticLoadBalancer: loading config
2015-11-08 16:41:37,449 INFO  [master:16000.activeMasterManager] master.HMaster: Server active/primary master=master,16000,1446972094536, sessionid=0x50e641f6a70000, setting cluster-up flag (Was=false)
2015-11-08 16:41:37,450 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: ClusterId : 18e4235c-98ec-4147-8ac4-00cf10508c80
2015-11-08 16:41:37,486 INFO  [master:16000.activeMasterManager] procedure.ZKProcedureUtil: Clearing all procedure znodes: /hbase/online-snapshot/acquired /hbase/online-snapshot/reached /hbase/online-snapshot/abort
2015-11-08 16:41:37,504 INFO  [master:16000.activeMasterManager] procedure.ZKProcedureUtil: Clearing all procedure znodes: /hbase/flush-table-proc/acquired /hbase/flush-table-proc/reached /hbase/flush-table-proc/abort
2015-11-08 16:41:37,549 INFO  [master:16000.activeMasterManager] master.MasterCoprocessorHost: System coprocessor loading is enabled
2015-11-08 16:41:37,566 INFO  [master:16000.activeMasterManager] procedure2.ProcedureExecutor: Starting procedure executor threads=5
2015-11-08 16:41:37,567 INFO  [master:16000.activeMasterManager] wal.WALProcedureStore: Starting WAL Procedure Store lease recovery
2015-11-08 16:41:37,574 INFO  [master:16000.activeMasterManager] util.FSHDFSUtils: Recovering lease on dfs file hdfs://192.168.1.101:9000/hbase/MasterProcWALs/state-00000000000000000005.log
2015-11-08 16:41:37,581 INFO  [master:16000.activeMasterManager] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://192.168.1.101:9000/hbase/MasterProcWALs/state-00000000000000000005.log after 7ms
2015-11-08 16:41:37,659 INFO  [master:16000.activeMasterManager] wal.WALProcedureStore: Lease acquired for flushLogId: 6
2015-11-08 16:41:37,666 INFO  [master:16000.activeMasterManager] wal.ProcedureWALFormatReader: No active entry found in state log hdfs://192.168.1.101:9000/hbase/MasterProcWALs/state-00000000000000000005.log. removing it
2015-11-08 16:41:37,683 INFO  [master:16000.activeMasterManager] zookeeper.RecoverableZooKeeper: Process identifier=replicationLogCleaner connecting to ZooKeeper ensemble=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181
2015-11-08 16:41:37,684 INFO  [master:16000.activeMasterManager] zookeeper.ZooKeeper: Initiating client connection, connectString=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181 sessionTimeout=90000 watcher=replicationLogCleaner0x0, quorum=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181, baseZNode=/hbase
2015-11-08 16:41:37,684 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 16:41:37,684 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.106/192.168.1.106:2181, initiating session
2015-11-08 16:41:37,705 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.106/192.168.1.106:2181, sessionid = 0x250e641f3940003, negotiated timeout = 90000
2015-11-08 16:41:37,743 INFO  [master:16000.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 0 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2015-11-08 16:41:38,058 INFO  [B.defaultRpcServer.handler=3,queue=0,port=16000] master.MasterRpcServices: Client=hadoop/null shutdown
2015-11-08 16:41:38,058 INFO  [B.defaultRpcServer.handler=3,queue=0,port=16000] regionserver.HRegionServer: STOPPED: Cluster shutdown requested
2015-11-08 16:41:38,058 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: Stopping infoServer
2015-11-08 16:41:38,059 INFO  [master/master/192.168.1.101:16000] mortbay.log: Stopped SelectChannelConnector@0.0.0.0:16010
2015-11-08 16:41:38,094 INFO  [master:16000.activeMasterManager] master.ServerManager: Finished waiting for region servers count to settle; checked in 0, slept for 351 ms, expecting minimum of 1, maximum of 2147483647, master is stopped.
2015-11-08 16:41:38,094 WARN  [master:16000.activeMasterManager] master.MasterFileSystem: Master stopped while trying to get failed servers.
2015-11-08 16:41:38,160 INFO  [master/master/192.168.1.101:16000] procedure2.ProcedureExecutor: Stopping the procedure executor
2015-11-08 16:41:38,160 INFO  [master/master/192.168.1.101:16000] wal.WALProcedureStore: Stopping the WAL Procedure Store
2015-11-08 16:41:38,248 INFO  [master,16000,1446972094536_splitLogManager__ChoreService_1] master.SplitLogManager$TimeoutMonitor: Chore: SplitLogManager Timeout Monitor was stopped
2015-11-08 16:41:38,354 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: stopping server master,16000,1446972094536
2015-11-08 16:41:38,354 INFO  [master/master/192.168.1.101:16000] client.ConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x150e641f3350000
2015-11-08 16:41:38,367 INFO  [master/master/192.168.1.101:16000] zookeeper.ZooKeeper: Session: 0x150e641f3350000 closed
2015-11-08 16:41:38,367 INFO  [master/master/192.168.1.101:16000-EventThread] zookeeper.ClientCnxn: EventThread shut down
2015-11-08 16:41:38,367 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: stopping server master,16000,1446972094536; all regions closed.
2015-11-08 16:41:38,368 INFO  [master/master/192.168.1.101:16000] hbase.ChoreService: Chore service for: master,16000,1446972094536 had [[ScheduledChore: Name: HFileCleaner Period: 60000 Unit: MILLISECONDS], [ScheduledChore: Name: LogsCleaner Period: 60000 Unit: MILLISECONDS]] on shutdown
2015-11-08 16:41:38,376 INFO  [master/master/192.168.1.101:16000] client.ConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x250e641f3940001
2015-11-08 16:41:38,384 INFO  [master/master/192.168.1.101:16000] zookeeper.ZooKeeper: Session: 0x250e641f3940001 closed
2015-11-08 16:41:38,384 INFO  [master:16000.activeMasterManager-EventThread] zookeeper.ClientCnxn: EventThread shut down
2015-11-08 16:41:38,384 INFO  [master/master/192.168.1.101:16000] hbase.ChoreService: Chore service for: master,16000,1446972094536_splitLogManager_ had [] on shutdown
2015-11-08 16:41:38,384 INFO  [master/master/192.168.1.101:16000] flush.MasterFlushTableProcedureManager: stop: server shutting down.
2015-11-08 16:41:38,384 INFO  [master/master/192.168.1.101:16000] ipc.RpcServer: Stopping server on 16000
2015-11-08 16:41:38,385 INFO  [RpcServer.listener,port=16000] ipc.RpcServer: RpcServer.listener,port=16000: stopping
2015-11-08 16:41:38,386 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopped
2015-11-08 16:41:38,386 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopping
2015-11-08 16:41:38,397 INFO  [master/master/192.168.1.101:16000] zookeeper.RecoverableZooKeeper: Node /hbase/rs/master,16000,1446972094536 already deleted, retry=false
2015-11-08 16:41:38,409 INFO  [main-EventThread] zookeeper.ClientCnxn: EventThread shut down
2015-11-08 16:41:38,409 INFO  [master/master/192.168.1.101:16000] zookeeper.ZooKeeper: Session: 0x50e641f6a70000 closed
2015-11-08 16:41:38,409 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: stopping server master,16000,1446972094536; zookeeper connection closed.
2015-11-08 16:41:38,409 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: master/master/192.168.1.101:16000 exiting
Sun Nov  8 16:46:09 CST 2015 Stopping hbase (via master)
Sun Nov  8 16:47:34 CST 2015 Starting master on master
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 30141
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 10240
cpu time               (seconds, -t) unlimited
max user processes              (-u) 1024
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2015-11-08 16:47:35,338 INFO  [main] util.VersionInfo: HBase 1.1.2
2015-11-08 16:47:35,338 INFO  [main] util.VersionInfo: Source code repository git://hw11397.local/Volumes/hbase-1.1.2RC2/hbase revision=cc2b70cf03e3378800661ec5cab11eb43fafe0fc
2015-11-08 16:47:35,338 INFO  [main] util.VersionInfo: Compiled by ndimiduk on Wed Aug 26 20:11:27 PDT 2015
2015-11-08 16:47:35,338 INFO  [main] util.VersionInfo: From source with checksum 73da41f3d1b867b7aba6166c77fafc17
2015-11-08 16:47:35,724 INFO  [main] util.ServerCommandLine: env:TERM=xterm
2015-11-08 16:47:35,724 INFO  [main] util.ServerCommandLine: env:HADOOP_COMMON_LIB_NATIVE_DIR=/opt/hadoop/lib/native
2015-11-08 16:47:35,724 INFO  [main] util.ServerCommandLine: env:IMSETTINGS_MODULE=none
2015-11-08 16:47:35,724 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/opt/java
2015-11-08 16:47:35,724 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/opt/hbase
2015-11-08 16:47:35,724 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2015-11-08 16:47:35,724 INFO  [main] util.ServerCommandLine: env:SESSION_MANAGER=local/unix:@/tmp/.ICE-unix/2957,unix/unix:/tmp/.ICE-unix/2957
2015-11-08 16:47:35,724 INFO  [main] util.ServerCommandLine: env:IMSETTINGS_INTEGRATE_DESKTOP=yes
2015-11-08 16:47:35,724 INFO  [main] util.ServerCommandLine: env:GNOME_DESKTOP_SESSION_ID=this-is-deprecated
2015-11-08 16:47:35,724 INFO  [main] util.ServerCommandLine: env:MAIL=/var/spool/mail/hadoop
2015-11-08 16:47:35,724 INFO  [main] util.ServerCommandLine: env:XDG_SESSION_COOKIE=ab8c9d4f5491283c7c300d7800000013-1446970837.780533-57183565
2015-11-08 16:47:35,724 INFO  [main] util.ServerCommandLine: env:GDMSESSION=gnome
2015-11-08 16:47:35,724 INFO  [main] util.ServerCommandLine: env:HOSTNAME=master
2015-11-08 16:47:35,724 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/tmp/hbase-hadoop-master.znode
2015-11-08 16:47:35,724 INFO  [main] util.ServerCommandLine: env:PWD=/opt/hbase/bin
2015-11-08 16:47:35,725 INFO  [main] util.ServerCommandLine: env:HBASE_MASTER_OPTS= -XX:PermSize=128m -XX:MaxPermSize=128m
2015-11-08 16:47:35,725 INFO  [main] util.ServerCommandLine: env:CVS_RSH=ssh
2015-11-08 16:47:35,725 INFO  [main] util.ServerCommandLine: env:JAVA_LIBRARY_PATH=/opt/hadoop/lib/native::/opt/hadoop/lib/native:
2015-11-08 16:47:35,725 INFO  [main] util.ServerCommandLine: env:G_BROKEN_FILENAMES=1
2015-11-08 16:47:35,725 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2015-11-08 16:47:35,725 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2015-11-08 16:47:35,725 INFO  [main] util.ServerCommandLine: env:NLSPATH=/usr/dt/lib/nls/msg/%L/%N.cat
2015-11-08 16:47:35,725 INFO  [main] util.ServerCommandLine: env:GNOME_KEYRING_SOCKET=/tmp/keyring-8q0f1M/socket
2015-11-08 16:47:35,725 INFO  [main] util.ServerCommandLine: env:GDM_KEYBOARD_LAYOUT=us
2015-11-08 16:47:35,725 INFO  [main] util.ServerCommandLine: env:HBASE_REGIONSERVER_OPTS= -XX:PermSize=128m -XX:MaxPermSize=128m
2015-11-08 16:47:35,725 INFO  [main] util.ServerCommandLine: env:HISTSIZE=1000
2015-11-08 16:47:35,725 INFO  [main] util.ServerCommandLine: env:PATH=/opt/hbase:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin:/sbin:/opt/java//bin:/opt/java/jre/bin:/opt/hadoop/bin:/home/hadoop/bin
2015-11-08 16:47:35,725 INFO  [main] util.ServerCommandLine: env:QTLIB=/usr/lib64/qt-3.3/lib
2015-11-08 16:47:35,725 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2015-11-08 16:47:35,725 INFO  [main] util.ServerCommandLine: env:GDM_LANG=en_US.UTF-8
2015-11-08 16:47:35,726 INFO  [main] util.ServerCommandLine: env:XAUTHORITY=/var/run/gdm/auth-for-hadoop-ApHB7y/database
2015-11-08 16:47:35,726 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/tmp/hbase-hadoop-master.autorestart
2015-11-08 16:47:35,726 INFO  [main] util.ServerCommandLine: env:USERNAME=hadoop
2015-11-08 16:47:35,726 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-hadoop-master-master.log
2015-11-08 16:47:35,726 INFO  [main] util.ServerCommandLine: env:SSH_ASKPASS=/usr/libexec/openssh/gnome-ssh-askpass
2015-11-08 16:47:35,726 INFO  [main] util.ServerCommandLine: env:SHLVL=6
2015-11-08 16:47:35,726 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/opt/hbase/logs
2015-11-08 16:47:35,728 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-XX:+UseConcMarkSweepGC   -XX:PermSize=128m -XX:MaxPermSize=128m -Dhbase.log.dir=/opt/hbase/logs -Dhbase.log.file=hbase-hadoop-master-master.log -Dhbase.home.dir=/opt/hbase -Dhbase.id.str=hadoop -Dhbase.root.logger=INFO,RFA -Djava.library.path=/opt/hadoop/lib/native::/opt/hadoop/lib/native: -Dhbase.security.logger=INFO,RFAS
2015-11-08 16:47:35,728 INFO  [main] util.ServerCommandLine: env:XFILESEARCHPATH=/usr/dt/app-defaults/%L/Dt
2015-11-08 16:47:35,728 INFO  [main] util.ServerCommandLine: env:COLORTERM=gnome-terminal
2015-11-08 16:47:35,729 INFO  [main] util.ServerCommandLine: env:QT_IM_MODULE=xim
2015-11-08 16:47:35,729 INFO  [main] util.ServerCommandLine: env:WINDOWID=23070599
2015-11-08 16:47:35,730 INFO  [main] util.ServerCommandLine: env:LOGNAME=hadoop
2015-11-08 16:47:35,730 INFO  [main] util.ServerCommandLine: env:QTDIR=/usr/lib64/qt-3.3
2015-11-08 16:47:35,730 INFO  [main] util.ServerCommandLine: env:XMODIFIERS=@im=none
2015-11-08 16:47:35,730 INFO  [main] util.ServerCommandLine: env:SSH_AUTH_SOCK=/tmp/keyring-8q0f1M/socket.ssh
2015-11-08 16:47:35,730 INFO  [main] util.ServerCommandLine: env:HADOOP_HOME=/opt/hadoop
2015-11-08 16:47:35,730 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=:/opt/hadoop/lib/native::/opt/hadoop/lib/native:
2015-11-08 16:47:35,730 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2015-11-08 16:47:35,730 INFO  [main] util.ServerCommandLine: env:HADOOP_OPTS=-Djava.library.path=/opt/hadoop/lib/native
2015-11-08 16:47:35,730 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2015-11-08 16:47:35,730 INFO  [main] util.ServerCommandLine: env:DBUS_SESSION_BUS_ADDRESS=unix:abstract=/tmp/dbus-BE8cSLU3kg,guid=266d9eaea9c6327e69c81ff6000000c7
2015-11-08 16:47:35,730 INFO  [main] util.ServerCommandLine: env:GNOME_KEYRING_PID=2947
2015-11-08 16:47:35,730 INFO  [main] util.ServerCommandLine: env:GTK_RC_FILES=/etc/gtk/gtkrc:/home/hadoop/.gtkrc-1.2-gnome2
2015-11-08 16:47:35,730 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2015-11-08 16:47:35,731 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/opt/hbase/conf:/opt/java/lib/tools.jar:/opt/hbase:/opt/hbase/lib/activation-1.1.jar:/opt/hbase/lib/aopalliance-1.0.jar:/opt/hbase/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hbase/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hbase/lib/api-asn1-api-1.0.0-M20.jar:/opt/hbase/lib/api-util-1.0.0-M20.jar:/opt/hbase/lib/asm-3.1.jar:/opt/hbase/lib/avro-1.7.4.jar:/opt/hbase/lib/commons-beanutils-1.7.0.jar:/opt/hbase/lib/commons-beanutils-core-1.8.0.jar:/opt/hbase/lib/commons-cli-1.2.jar:/opt/hbase/lib/commons-codec-1.9.jar:/opt/hbase/lib/commons-collections-3.2.1.jar:/opt/hbase/lib/commons-compress-1.4.1.jar:/opt/hbase/lib/commons-configuration-1.6.jar:/opt/hbase/lib/commons-daemon-1.0.13.jar:/opt/hbase/lib/commons-digester-1.8.jar:/opt/hbase/lib/commons-el-1.0.jar:/opt/hbase/lib/commons-httpclient-3.1.jar:/opt/hbase/lib/commons-io-2.4.jar:/opt/hbase/lib/commons-lang-2.6.jar:/opt/hbase/lib/commons-logging-1.2.jar:/opt/hbase/lib/commons-math-2.2.jar:/opt/hbase/lib/commons-math3-3.1.1.jar:/opt/hbase/lib/commons-net-3.1.jar:/opt/hbase/lib/disruptor-3.3.0.jar:/opt/hbase/lib/findbugs-annotations-1.3.9-1.jar:/opt/hbase/lib/guava-12.0.1.jar:/opt/hbase/lib/guice-3.0.jar:/opt/hbase/lib/guice-servlet-3.0.jar:/opt/hbase/lib/hadoop-annotations-2.5.1.jar:/opt/hbase/lib/hadoop-auth-2.5.1.jar:/opt/hbase/lib/hadoop-client-2.5.1.jar:/opt/hbase/lib/hadoop-common-2.5.1.jar:/opt/hbase/lib/hadoop-hdfs-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-app-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-common-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-core-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-jobclient-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-shuffle-2.5.1.jar:/opt/hbase/lib/hadoop-yarn-api-2.5.1.jar:/opt/hbase/lib/hadoop-yarn-client-2.5.1.jar:/opt/hbase/lib/hadoop-yarn-common-2.5.1.jar:/opt/hbase/lib/hadoop-yarn-server-common-2.5.1.jar:/opt/hbase/lib/hbase-annotations-1.1.2.jar:/opt/hbase/lib/hbase-annotations-1.1.2-tests.jar:/opt/hbase/lib/hbase-client-1.1.2.jar:/opt/hbase/lib/hbase-common-1.1.2.jar:/opt/hbase/lib/hbase-common-1.1.2-tests.jar:/opt/hbase/lib/hbase-examples-1.1.2.jar:/opt/hbase/lib/hbase-hadoop2-compat-1.1.2.jar:/opt/hbase/lib/hbase-hadoop-compat-1.1.2.jar:/opt/hbase/lib/hbase-it-1.1.2.jar:/opt/hbase/lib/hbase-it-1.1.2-tests.jar:/opt/hbase/lib/hbase-prefix-tree-1.1.2.jar:/opt/hbase/lib/hbase-procedure-1.1.2.jar:/opt/hbase/lib/hbase-protocol-1.1.2.jar:/opt/hbase/lib/hbase-resource-bundle-1.1.2.jar:/opt/hbase/lib/hbase-rest-1.1.2.jar:/opt/hbase/lib/hbase-server-1.1.2.jar:/opt/hbase/lib/hbase-server-1.1.2-tests.jar:/opt/hbase/lib/hbase-shell-1.1.2.jar:/opt/hbase/lib/hbase-thrift-1.1.2.jar:/opt/hbase/lib/htrace-core-3.1.0-incubating.jar:/opt/hbase/lib/httpclient-4.2.5.jar:/opt/hbase/lib/httpcore-4.1.3.jar:/opt/hbase/lib/jackson-core-asl-1.9.13.jar:/opt/hbase/lib/jackson-jaxrs-1.9.13.jar:/opt/hbase/lib/jackson-mapper-asl-1.9.13.jar:/opt/hbase/lib/jackson-xc-1.9.13.jar:/opt/hbase/lib/jamon-runtime-2.3.1.jar:/opt/hbase/lib/jasper-compiler-5.5.23.jar:/opt/hbase/lib/jasper-runtime-5.5.23.jar:/opt/hbase/lib/javax.inject-1.jar:/opt/hbase/lib/java-xmlbuilder-0.4.jar:/opt/hbase/lib/jaxb-api-2.2.2.jar:/opt/hbase/lib/jaxb-impl-2.2.3-1.jar:/opt/hbase/lib/jcodings-1.0.8.jar:/opt/hbase/lib/jersey-client-1.9.jar:/opt/hbase/lib/jersey-core-1.9.jar:/opt/hbase/lib/jersey-guice-1.9.jar:/opt/hbase/lib/jersey-json-1.9.jar:/opt/hbase/lib/jersey-server-1.9.jar:/opt/hbase/lib/jets3t-0.9.0.jar:/opt/hbase/lib/jettison-1.3.3.jar:/opt/hbase/lib/jetty-6.1.26.jar:/opt/hbase/lib/jetty-sslengine-6.1.26.jar:/opt/hbase/lib/jetty-util-6.1.26.jar:/opt/hbase/lib/joni-2.1.2.jar:/opt/hbase/lib/jruby-complete-1.6.8.jar:/opt/hbase/lib/jsch-0.1.42.jar:/opt/hbase/lib/jsp-2.1-6.1.14.jar:/opt/hbase/lib/jsp-api-2.1-6.1.14.jar:/opt/hbase/lib/jsr305-1.3.9.jar:/opt/hbase/lib/junit-4.11.jar:/opt/hbase/lib/leveldbjni-all-1.8.jar:/opt/hbase/lib/libthrift-0.9.0.jar:/opt/hbase/lib/log4j-1.2.17.jar:/opt/hbase/lib/metrics-core-2.2.0.jar:/opt/hbase/lib/netty-3.2.4.Final.jar:/opt/hbase/lib/netty-all-4.0.23.Final.jar:/opt/hbase/lib/paranamer-2.3.jar:/opt/hbase/lib/protobuf-java-2.5.0.jar:/opt/hbase/lib/servlet-api-2.5-6.1.14.jar:/opt/hbase/lib/servlet-api-2.5.jar:/opt/hbase/lib/slf4j-api-1.7.7.jar:/opt/hbase/lib/slf4j-log4j12-1.7.5.jar:/opt/hbase/lib/snappy-java-1.0.4.1.jar:/opt/hbase/lib/spymemcached-2.11.6.jar:/opt/hbase/lib/xmlenc-0.52.jar:/opt/hbase/lib/xz-1.0.jar:/opt/hbase/lib/zookeeper-3.4.6.jar:/opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/contrib/capacity-scheduler/*.jar
2015-11-08 16:47:35,735 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2015-11-08 16:47:35,736 INFO  [main] util.ServerCommandLine: env:JRE_HOME=/opt/java/jre
2015-11-08 16:47:35,736 INFO  [main] util.ServerCommandLine: env:DESKTOP_SESSION=gnome
2015-11-08 16:47:35,736 INFO  [main] util.ServerCommandLine: env:QTINC=/usr/lib64/qt-3.3/include
2015-11-08 16:47:35,736 INFO  [main] util.ServerCommandLine: env:DISPLAY=192.168.1.100:1.0
2015-11-08 16:47:35,736 INFO  [main] util.ServerCommandLine: env:USER=hadoop
2015-11-08 16:47:35,736 INFO  [main] util.ServerCommandLine: env:HISTCONTROL=ignoredups
2015-11-08 16:47:35,736 INFO  [main] util.ServerCommandLine: env:HOME=/home/hadoop
2015-11-08 16:47:35,736 INFO  [main] util.ServerCommandLine: env:LESSOPEN=||/usr/bin/lesspipe.sh %s
2015-11-08 16:47:35,736 INFO  [main] util.ServerCommandLine: env:ORBIT_SOCKETDIR=/tmp/orbit-hadoop
2015-11-08 16:47:35,736 INFO  [main] util.ServerCommandLine: env:LANG=en_US.UTF-8
2015-11-08 16:47:35,736 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-hadoop-master-master
2015-11-08 16:47:35,736 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=hadoop
2015-11-08 16:47:35,738 INFO  [main] util.ServerCommandLine: vmName=Java HotSpot(TM) 64-Bit Server VM, vmVendor=Oracle Corporation, vmVersion=24.79-b02
2015-11-08 16:47:35,739 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_master, -XX:OnOutOfMemoryError=kill -9 %p, -XX:+UseConcMarkSweepGC, -XX:PermSize=128m, -XX:MaxPermSize=128m, -Dhbase.log.dir=/opt/hbase/logs, -Dhbase.log.file=hbase-hadoop-master-master.log, -Dhbase.home.dir=/opt/hbase, -Dhbase.id.str=hadoop, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=/opt/hadoop/lib/native::/opt/hadoop/lib/native:, -Dhbase.security.logger=INFO,RFAS]
2015-11-08 16:47:36,187 WARN  [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-11-08 16:47:36,394 INFO  [main] regionserver.RSRpcServices: master/master/192.168.1.101:16000 server-side HConnection retries=350
2015-11-08 16:47:36,534 INFO  [main] ipc.SimpleRpcScheduler: Using deadline as user call queue, count=3
2015-11-08 16:47:36,548 INFO  [main] ipc.RpcServer: master/master/192.168.1.101:16000: started 10 reader(s).
2015-11-08 16:47:36,597 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2015-11-08 16:47:36,645 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-11-08 16:47:36,645 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2015-11-08 16:47:37,174 INFO  [main] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2015-11-08 16:47:37,344 INFO  [main] zookeeper.RecoverableZooKeeper: Process identifier=master:16000 connecting to ZooKeeper ensemble=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181
2015-11-08 16:47:37,350 INFO  [main] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2015-11-08 16:47:37,350 INFO  [main] zookeeper.ZooKeeper: Client environment:host.name=master
2015-11-08 16:47:37,350 INFO  [main] zookeeper.ZooKeeper: Client environment:java.version=1.7.0_79
2015-11-08 16:47:37,350 INFO  [main] zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
2015-11-08 16:47:37,350 INFO  [main] zookeeper.ZooKeeper: Client environment:java.home=/opt/java/jre
2015-11-08 16:47:37,350 INFO  [main] zookeeper.ZooKeeper: Client environment:java.class.path=/opt/hbase/conf:/opt/java/lib/tools.jar:/opt/hbase:/opt/hbase/lib/activation-1.1.jar:/opt/hbase/lib/aopalliance-1.0.jar:/opt/hbase/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hbase/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hbase/lib/api-asn1-api-1.0.0-M20.jar:/opt/hbase/lib/api-util-1.0.0-M20.jar:/opt/hbase/lib/asm-3.1.jar:/opt/hbase/lib/avro-1.7.4.jar:/opt/hbase/lib/commons-beanutils-1.7.0.jar:/opt/hbase/lib/commons-beanutils-core-1.8.0.jar:/opt/hbase/lib/commons-cli-1.2.jar:/opt/hbase/lib/commons-codec-1.9.jar:/opt/hbase/lib/commons-collections-3.2.1.jar:/opt/hbase/lib/commons-compress-1.4.1.jar:/opt/hbase/lib/commons-configuration-1.6.jar:/opt/hbase/lib/commons-daemon-1.0.13.jar:/opt/hbase/lib/commons-digester-1.8.jar:/opt/hbase/lib/commons-el-1.0.jar:/opt/hbase/lib/commons-httpclient-3.1.jar:/opt/hbase/lib/commons-io-2.4.jar:/opt/hbase/lib/commons-lang-2.6.jar:/opt/hbase/lib/commons-logging-1.2.jar:/opt/hbase/lib/commons-math-2.2.jar:/opt/hbase/lib/commons-math3-3.1.1.jar:/opt/hbase/lib/commons-net-3.1.jar:/opt/hbase/lib/disruptor-3.3.0.jar:/opt/hbase/lib/findbugs-annotations-1.3.9-1.jar:/opt/hbase/lib/guava-12.0.1.jar:/opt/hbase/lib/guice-3.0.jar:/opt/hbase/lib/guice-servlet-3.0.jar:/opt/hbase/lib/hadoop-annotations-2.5.1.jar:/opt/hbase/lib/hadoop-auth-2.5.1.jar:/opt/hbase/lib/hadoop-client-2.5.1.jar:/opt/hbase/lib/hadoop-common-2.5.1.jar:/opt/hbase/lib/hadoop-hdfs-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-app-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-common-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-core-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-jobclient-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-shuffle-2.5.1.jar:/opt/hbase/lib/hadoop-yarn-api-2.5.1.jar:/opt/hbase/lib/hadoop-yarn-client-2.5.1.jar:/opt/hbase/lib/hadoop-yarn-common-2.5.1.jar:/opt/hbase/lib/hadoop-yarn-server-common-2.5.1.jar:/opt/hbase/lib/hbase-annotations-1.1.2.jar:/opt/hbase/lib/hbase-annotations-1.1.2-tests.jar:/opt/hbase/lib/hbase-client-1.1.2.jar:/opt/hbase/lib/hbase-common-1.1.2.jar:/opt/hbase/lib/hbase-common-1.1.2-tests.jar:/opt/hbase/lib/hbase-examples-1.1.2.jar:/opt/hbase/lib/hbase-hadoop2-compat-1.1.2.jar:/opt/hbase/lib/hbase-hadoop-compat-1.1.2.jar:/opt/hbase/lib/hbase-it-1.1.2.jar:/opt/hbase/lib/hbase-it-1.1.2-tests.jar:/opt/hbase/lib/hbase-prefix-tree-1.1.2.jar:/opt/hbase/lib/hbase-procedure-1.1.2.jar:/opt/hbase/lib/hbase-protocol-1.1.2.jar:/opt/hbase/lib/hbase-resource-bundle-1.1.2.jar:/opt/hbase/lib/hbase-rest-1.1.2.jar:/opt/hbase/lib/hbase-server-1.1.2.jar:/opt/hbase/lib/hbase-server-1.1.2-tests.jar:/opt/hbase/lib/hbase-shell-1.1.2.jar:/opt/hbase/lib/hbase-thrift-1.1.2.jar:/opt/hbase/lib/htrace-core-3.1.0-incubating.jar:/opt/hbase/lib/httpclient-4.2.5.jar:/opt/hbase/lib/httpcore-4.1.3.jar:/opt/hbase/lib/jackson-core-asl-1.9.13.jar:/opt/hbase/lib/jackson-jaxrs-1.9.13.jar:/opt/hbase/lib/jackson-mapper-asl-1.9.13.jar:/opt/hbase/lib/jackson-xc-1.9.13.jar:/opt/hbase/lib/jamon-runtime-2.3.1.jar:/opt/hbase/lib/jasper-compiler-5.5.23.jar:/opt/hbase/lib/jasper-runtime-5.5.23.jar:/opt/hbase/lib/javax.inject-1.jar:/opt/hbase/lib/java-xmlbuilder-0.4.jar:/opt/hbase/lib/jaxb-api-2.2.2.jar:/opt/hbase/lib/jaxb-impl-2.2.3-1.jar:/opt/hbase/lib/jcodings-1.0.8.jar:/opt/hbase/lib/jersey-client-1.9.jar:/opt/hbase/lib/jersey-core-1.9.jar:/opt/hbase/lib/jersey-guice-1.9.jar:/opt/hbase/lib/jersey-json-1.9.jar:/opt/hbase/lib/jersey-server-1.9.jar:/opt/hbase/lib/jets3t-0.9.0.jar:/opt/hbase/lib/jettison-1.3.3.jar:/opt/hbase/lib/jetty-6.1.26.jar:/opt/hbase/lib/jetty-sslengine-6.1.26.jar:/opt/hbase/lib/jetty-util-6.1.26.jar:/opt/hbase/lib/joni-2.1.2.jar:/opt/hbase/lib/jruby-complete-1.6.8.jar:/opt/hbase/lib/jsch-0.1.42.jar:/opt/hbase/lib/jsp-2.1-6.1.14.jar:/opt/hbase/lib/jsp-api-2.1-6.1.14.jar:/opt/hbase/lib/jsr305-1.3.9.jar:/opt/hbase/lib/junit-4.11.jar:/opt/hbase/lib/leveldbjni-all-1.8.jar:/opt/hbase/lib/libthrift-0.9.0.jar:/opt/hbase/lib/log4j-1.2.17.jar:/opt/hbase/lib/metrics-core-2.2.0.jar:/opt/hbase/lib/netty-3.2.4.Final.jar:/opt/hbase/lib/netty-all-4.0.23.Final.jar:/opt/hbase/lib/paranamer-2.3.jar:/opt/hbase/lib/protobuf-java-2.5.0.jar:/opt/hbase/lib/servlet-api-2.5-6.1.14.jar:/opt/hbase/lib/servlet-api-2.5.jar:/opt/hbase/lib/slf4j-api-1.7.7.jar:/opt/hbase/lib/slf4j-log4j12-1.7.5.jar:/opt/hbase/lib/snappy-java-1.0.4.1.jar:/opt/hbase/lib/spymemcached-2.11.6.jar:/opt/hbase/lib/xmlenc-0.52.jar:/opt/hbase/lib/xz-1.0.jar:/opt/hbase/lib/zookeeper-3.4.6.jar:/opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-auth-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/opt/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/opt/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop/share/hadoop/common/lib/curator-framework-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/opt/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/opt/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop/share/hadoop/common/lib/curator-client-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/opt/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-annotations-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/opt/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop/share/hadoop/common/lib/htrace-core-3.0.4.jar:/opt/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop/share/hadoop/common/hadoop-common-2.6.0-tests.jar:/opt/hadoop/share/hadoop/common/hadoop-common-2.6.0.jar:/opt/hadoop/share/hadoop/common/hadoop-nfs-2.6.0.jar:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/opt/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.0-tests.jar:/opt/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jline-0.9.94.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-tests.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar
2015-11-08 16:47:37,350 INFO  [main] zookeeper.ZooKeeper: Client environment:java.library.path=/opt/hadoop/lib/native::/opt/hadoop/lib/native:
2015-11-08 16:47:37,350 INFO  [main] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2015-11-08 16:47:37,350 INFO  [main] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2015-11-08 16:47:37,350 INFO  [main] zookeeper.ZooKeeper: Client environment:os.name=Linux
2015-11-08 16:47:37,350 INFO  [main] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2015-11-08 16:47:37,350 INFO  [main] zookeeper.ZooKeeper: Client environment:os.version=2.6.32-573.el6.x86_64
2015-11-08 16:47:37,350 INFO  [main] zookeeper.ZooKeeper: Client environment:user.name=hadoop
2015-11-08 16:47:37,350 INFO  [main] zookeeper.ZooKeeper: Client environment:user.home=/home/hadoop
2015-11-08 16:47:37,350 INFO  [main] zookeeper.ZooKeeper: Client environment:user.dir=/opt/hbase/bin
2015-11-08 16:47:37,351 INFO  [main] zookeeper.ZooKeeper: Initiating client connection, connectString=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181 sessionTimeout=90000 watcher=master:160000x0, quorum=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181, baseZNode=/hbase
2015-11-08 16:47:37,362 INFO  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 16:47:37,365 INFO  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.102/192.168.1.102:2181, initiating session
2015-11-08 16:47:37,451 INFO  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.102/192.168.1.102:2181, sessionid = 0x150e64779e70000, negotiated timeout = 90000
2015-11-08 16:47:37,539 INFO  [RpcServer.listener,port=16000] ipc.RpcServer: RpcServer.listener,port=16000: starting
2015-11-08 16:47:37,539 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2015-11-08 16:47:37,590 INFO  [main] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-11-08 16:47:37,594 INFO  [main] http.HttpRequestLog: Http request log for http.requests.master is not defined
2015-11-08 16:47:37,603 INFO  [main] http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.hbase.http.HttpServer$QuotingInputFilter)
2015-11-08 16:47:37,606 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context master
2015-11-08 16:47:37,606 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-11-08 16:47:37,606 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-11-08 16:47:37,625 INFO  [main] http.HttpServer: Jetty bound to port 16010
2015-11-08 16:47:37,625 INFO  [main] mortbay.log: jetty-6.1.26
2015-11-08 16:47:37,996 INFO  [main] mortbay.log: Started SelectChannelConnector@0.0.0.0:16010
2015-11-08 16:47:37,999 INFO  [main] master.HMaster: hbase.rootdir=hdfs://192.168.1.101:9000/hbase, hbase.cluster.distributed=true
2015-11-08 16:47:38,011 INFO  [main] master.HMaster: Adding backup master ZNode /hbase/backup-masters/master,16000,1446972456659
2015-11-08 16:47:38,169 INFO  [master:16000.activeMasterManager] master.ActiveMasterManager: Deleting ZNode for /hbase/backup-masters/master,16000,1446972456659 from backup master directory
2015-11-08 16:47:38,187 INFO  [master:16000.activeMasterManager] master.ActiveMasterManager: Registered Active Master=master,16000,1446972456659
2015-11-08 16:47:38,202 INFO  [master/master/192.168.1.101:16000] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x26948174 connecting to ZooKeeper ensemble=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181
2015-11-08 16:47:38,202 INFO  [master/master/192.168.1.101:16000] zookeeper.ZooKeeper: Initiating client connection, connectString=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181 sessionTimeout=90000 watcher=hconnection-0x269481740x0, quorum=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181, baseZNode=/hbase
2015-11-08 16:47:38,202 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.101/192.168.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 16:47:38,203 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.101/192.168.1.101:2181, initiating session
2015-11-08 16:47:38,222 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.101/192.168.1.101:2181, sessionid = 0x50e6477d410000, negotiated timeout = 90000
2015-11-08 16:47:38,557 INFO  [master:16000.activeMasterManager] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2015-11-08 16:47:38,572 INFO  [master:16000.activeMasterManager] coordination.SplitLogManagerCoordination: Found 0 orphan tasks and 0 rescan nodes
2015-11-08 16:47:38,636 INFO  [master:16000.activeMasterManager] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x1d4a6e1c connecting to ZooKeeper ensemble=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181
2015-11-08 16:47:38,636 INFO  [master:16000.activeMasterManager] zookeeper.ZooKeeper: Initiating client connection, connectString=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181 sessionTimeout=90000 watcher=hconnection-0x1d4a6e1c0x0, quorum=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181, baseZNode=/hbase
2015-11-08 16:47:38,636 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 16:47:38,637 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.102/192.168.1.102:2181, initiating session
2015-11-08 16:47:38,653 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.102/192.168.1.102:2181, sessionid = 0x150e64779e70001, negotiated timeout = 90000
2015-11-08 16:47:38,677 INFO  [master:16000.activeMasterManager] balancer.StochasticLoadBalancer: loading config
2015-11-08 16:47:38,748 INFO  [master:16000.activeMasterManager] master.HMaster: Server active/primary master=master,16000,1446972456659, sessionid=0x150e64779e70000, setting cluster-up flag (Was=false)
2015-11-08 16:47:38,752 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: ClusterId : 18e4235c-98ec-4147-8ac4-00cf10508c80
2015-11-08 16:47:38,796 INFO  [master:16000.activeMasterManager] procedure.ZKProcedureUtil: Clearing all procedure znodes: /hbase/online-snapshot/acquired /hbase/online-snapshot/reached /hbase/online-snapshot/abort
2015-11-08 16:47:38,847 INFO  [master:16000.activeMasterManager] procedure.ZKProcedureUtil: Clearing all procedure znodes: /hbase/flush-table-proc/acquired /hbase/flush-table-proc/reached /hbase/flush-table-proc/abort
2015-11-08 16:47:38,891 INFO  [master:16000.activeMasterManager] master.MasterCoprocessorHost: System coprocessor loading is enabled
2015-11-08 16:47:38,902 INFO  [master:16000.activeMasterManager] procedure2.ProcedureExecutor: Starting procedure executor threads=5
2015-11-08 16:47:38,903 INFO  [master:16000.activeMasterManager] wal.WALProcedureStore: Starting WAL Procedure Store lease recovery
2015-11-08 16:47:38,910 INFO  [master:16000.activeMasterManager] util.FSHDFSUtils: Recovering lease on dfs file hdfs://192.168.1.101:9000/hbase/MasterProcWALs/state-00000000000000000006.log
2015-11-08 16:47:38,914 INFO  [master:16000.activeMasterManager] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://192.168.1.101:9000/hbase/MasterProcWALs/state-00000000000000000006.log after 4ms
2015-11-08 16:47:38,962 INFO  [master:16000.activeMasterManager] wal.WALProcedureStore: Lease acquired for flushLogId: 7
2015-11-08 16:47:38,967 INFO  [master:16000.activeMasterManager] wal.ProcedureWALFormatReader: No active entry found in state log hdfs://192.168.1.101:9000/hbase/MasterProcWALs/state-00000000000000000006.log. removing it
2015-11-08 16:47:38,982 INFO  [master:16000.activeMasterManager] zookeeper.RecoverableZooKeeper: Process identifier=replicationLogCleaner connecting to ZooKeeper ensemble=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181
2015-11-08 16:47:38,982 INFO  [master:16000.activeMasterManager] zookeeper.ZooKeeper: Initiating client connection, connectString=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181 sessionTimeout=90000 watcher=replicationLogCleaner0x0, quorum=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181, baseZNode=/hbase
2015-11-08 16:47:38,983 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 16:47:38,983 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.106/192.168.1.106:2181, initiating session
2015-11-08 16:47:39,001 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.106/192.168.1.106:2181, sessionid = 0x250e6477a200000, negotiated timeout = 90000
2015-11-08 16:47:39,016 INFO  [master:16000.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 0 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2015-11-08 16:47:39,134 INFO  [PriorityRpcServer.handler=0,queue=0,port=16000] master.ServerManager: Registering server=master,16020,1446972095922
2015-11-08 16:47:39,162 INFO  [PriorityRpcServer.handler=2,queue=0,port=16000] master.ServerManager: Registering server=slave2,16020,1446972096396
2015-11-08 16:47:39,166 INFO  [master:16000.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 2, slept for 150 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2015-11-08 16:47:39,175 INFO  [PriorityRpcServer.handler=1,queue=1,port=16000] master.ServerManager: Registering server=slave1,16020,1446972096399
2015-11-08 16:47:39,217 INFO  [master:16000.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 3, slept for 200 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2015-11-08 16:47:40,719 INFO  [master:16000.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 3, slept for 1703 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2015-11-08 16:47:42,222 INFO  [master:16000.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 3, slept for 3206 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2015-11-08 16:47:43,526 INFO  [master:16000.activeMasterManager] master.ServerManager: Finished waiting for region servers count to settle; checked in 3, slept for 4510 ms, expecting minimum of 1, maximum of 2147483647, master is running
2015-11-08 16:47:43,545 INFO  [master:16000.activeMasterManager] master.MasterFileSystem: Log folder hdfs://192.168.1.101:9000/hbase/WALs/master,16020,1446972095922 belongs to an existing region server
2015-11-08 16:47:43,549 INFO  [master:16000.activeMasterManager] master.MasterFileSystem: Log folder hdfs://192.168.1.101:9000/hbase/WALs/slave1,16020,1446972096399 belongs to an existing region server
2015-11-08 16:47:43,552 INFO  [master:16000.activeMasterManager] master.MasterFileSystem: Log folder hdfs://192.168.1.101:9000/hbase/WALs/slave2,16020,1446972096396 belongs to an existing region server
2015-11-08 16:47:43,661 INFO  [master:16000.activeMasterManager] zookeeper.MetaTableLocator: Failed verification of hbase:meta,,1 at address=master,16020,1446971438113, exception=org.apache.hadoop.hbase.NotServingRegionException: Region hbase:meta,,1 is not online on master,16020,1446972095922
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2898)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.getRegion(RSRpcServices.java:947)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.getRegionInfo(RSRpcServices.java:1232)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$2.callBlockingMethod(AdminProtos.java:22233)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2114)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:101)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:130)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:107)
	at java.lang.Thread.run(Thread.java:745)

2015-11-08 16:47:43,680 INFO  [master:16000.activeMasterManager] master.SplitLogManager: dead splitlog workers [master,16020,1446971438113]
2015-11-08 16:47:43,684 INFO  [master:16000.activeMasterManager] master.SplitLogManager: hdfs://192.168.1.101:9000/hbase/WALs/master,16020,1446971438113-splitting is empty dir, no logs to split
2015-11-08 16:47:43,685 INFO  [master:16000.activeMasterManager] master.SplitLogManager: started splitting 0 logs in [hdfs://192.168.1.101:9000/hbase/WALs/master,16020,1446971438113-splitting] for [master,16020,1446971438113]
2015-11-08 16:47:43,694 INFO  [master:16000.activeMasterManager] master.SplitLogManager: finished splitting (more than or equal to) 0 bytes in 0 log files in [hdfs://192.168.1.101:9000/hbase/WALs/master,16020,1446971438113-splitting] in 9ms
2015-11-08 16:47:43,694 INFO  [master:16000.activeMasterManager] zookeeper.MetaTableLocator: Deleting hbase:meta region location in ZooKeeper
2015-11-08 16:47:43,786 INFO  [master:16000.activeMasterManager] master.AssignmentManager: Assigning hbase:meta,,1.1588230740 to slave2,16020,1446972096396
2015-11-08 16:47:43,786 INFO  [master:16000.activeMasterManager] master.RegionStates: Transition {1588230740 state=OFFLINE, ts=1446972463754, server=null} to {1588230740 state=PENDING_OPEN, ts=1446972463786, server=slave2,16020,1446972096396}
2015-11-08 16:47:43,886 INFO  [master:16000.activeMasterManager] master.ServerManager: AssignmentManager hasn't finished failover cleanup; waiting
2015-11-08 16:47:43,936 INFO  [AM.ZK.Worker-pool2-t1] master.RegionStates: Transition {1588230740 state=PENDING_OPEN, ts=1446972463786, server=slave2,16020,1446972096396} to {1588230740 state=OPENING, ts=1446972463936, server=slave2,16020,1446972096396}
2015-11-08 16:47:44,779 INFO  [AM.ZK.Worker-pool2-t2] master.RegionStates: Transition {1588230740 state=OPENING, ts=1446972463936, server=slave2,16020,1446972096396} to {1588230740 state=OPEN, ts=1446972464779, server=slave2,16020,1446972096396}
2015-11-08 16:47:44,782 INFO  [AM.ZK.Worker-pool2-t2] coordination.ZkOpenRegionCoordination: Handling OPENED of 1588230740 from master,16000,1446972456659; deleting unassigned node
2015-11-08 16:47:44,805 INFO  [master:16000.activeMasterManager] master.HMaster: hbase:meta with replicaId 0 assigned=1, rit=false, location=slave2,16020,1446972096396
2015-11-08 16:47:45,023 INFO  [master:16000.activeMasterManager] hbase.MetaMigrationConvertingToPB: META already up-to date with PB serialization
2015-11-08 16:47:45,077 INFO  [master:16000.activeMasterManager] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=OPEN, ts=1446972465077, server=slave2,16020,1446971438717} to {6f3d653b8b106cc2df931825f52d6dec state=OFFLINE, ts=1446972465077, server=slave2,16020,1446971438717}
2015-11-08 16:47:45,084 INFO  [master:16000.activeMasterManager] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=OFFLINE, ts=1446972465077, server=slave2,16020,1446971438717} to {6f3d653b8b106cc2df931825f52d6dec state=CLOSED, ts=1446972465084, server=slave2,16020,1446971438717}
2015-11-08 16:47:45,088 INFO  [master:16000.activeMasterManager] master.AssignmentManager: Clean cluster startup. Assigning user regions
2015-11-08 16:47:45,102 INFO  [master:16000.activeMasterManager] balancer.BaseLoadBalancer: Reassigned 1 regions. 1 retained the pre-restart assignment. 
2015-11-08 16:47:45,102 INFO  [master:16000.activeMasterManager] master.AssignmentManager: Bulk assigning 1 region(s) across 3 server(s), retainAssignment=true
2015-11-08 16:47:45,105 INFO  [master,16000,1446972456659-GeneralBulkAssigner-2] master.AssignmentManager: Assigning 1 region(s) to slave2,16020,1446972096396
2015-11-08 16:47:45,108 INFO  [master,16000,1446972456659-GeneralBulkAssigner-2] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=CLOSED, ts=1446972465084, server=slave2,16020,1446971438717} to {6f3d653b8b106cc2df931825f52d6dec state=OFFLINE, ts=1446972465108, server=slave2,16020,1446971438717}
2015-11-08 16:47:45,134 INFO  [master,16000,1446972456659-GeneralBulkAssigner-2] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=OFFLINE, ts=1446972465108, server=slave2,16020,1446971438717} to {6f3d653b8b106cc2df931825f52d6dec state=PENDING_OPEN, ts=1446972465134, server=slave2,16020,1446972096396}
2015-11-08 16:47:45,184 INFO  [master:16000.activeMasterManager] master.AssignmentManager: Bulk assigning done
2015-11-08 16:47:45,196 INFO  [AM.ZK.Worker-pool2-t5] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=PENDING_OPEN, ts=1446972465134, server=slave2,16020,1446972096396} to {6f3d653b8b106cc2df931825f52d6dec state=OPENING, ts=1446972465196, server=slave2,16020,1446972096396}
2015-11-08 16:47:45,197 INFO  [master:16000.activeMasterManager] master.AssignmentManager: Joined the cluster in 174ms, failover=false
2015-11-08 16:47:45,607 INFO  [AM.ZK.Worker-pool2-t6] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=OPENING, ts=1446972465196, server=slave2,16020,1446972096396} to {6f3d653b8b106cc2df931825f52d6dec state=OPEN, ts=1446972465607, server=slave2,16020,1446972096396}
2015-11-08 16:47:45,634 INFO  [AM.ZK.Worker-pool2-t8] master.RegionStates: Offlined 6f3d653b8b106cc2df931825f52d6dec from slave2,16020,1446971438717
2015-11-08 16:47:45,864 INFO  [master:16000.activeMasterManager] master.HMaster: Master has completed initialization
2015-11-08 16:47:45,875 INFO  [master:16000.activeMasterManager] quotas.MasterQuotaManager: Quota support disabled
Sun Nov  8 16:48:27 CST 2015 Stopping hbase (via master)
2015-11-08 16:48:30,185 INFO  [B.defaultRpcServer.handler=3,queue=0,port=16000] master.MasterRpcServices: Client=hadoop/null shutdown
2015-11-08 16:48:30,185 INFO  [B.defaultRpcServer.handler=3,queue=0,port=16000] regionserver.HRegionServer: STOPPED: Cluster shutdown requested
2015-11-08 16:48:30,185 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: Stopping infoServer
2015-11-08 16:48:30,187 INFO  [master/master/192.168.1.101:16000] mortbay.log: Stopped SelectChannelConnector@0.0.0.0:16010
2015-11-08 16:48:30,287 INFO  [master/master/192.168.1.101:16000] procedure2.ProcedureExecutor: Stopping the procedure executor
2015-11-08 16:48:30,287 INFO  [master/master/192.168.1.101:16000] wal.WALProcedureStore: Stopping the WAL Procedure Store
2015-11-08 16:48:30,445 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: stopping server master,16000,1446972456659
2015-11-08 16:48:30,446 INFO  [master/master/192.168.1.101:16000] client.ConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x50e6477d410000
2015-11-08 16:48:30,461 INFO  [master/master/192.168.1.101:16000-EventThread] zookeeper.ClientCnxn: EventThread shut down
2015-11-08 16:48:30,461 INFO  [master/master/192.168.1.101:16000] zookeeper.ZooKeeper: Session: 0x50e6477d410000 closed
2015-11-08 16:48:30,561 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: stopping server master,16000,1446972456659; all regions closed.
2015-11-08 16:48:30,562 INFO  [master/master/192.168.1.101:16000] hbase.ChoreService: Chore service for: master,16000,1446972456659 had [[ScheduledChore: Name: HFileCleaner Period: 60000 Unit: MILLISECONDS], [ScheduledChore: Name: CatalogJanitor-master:16000 Period: 300000 Unit: MILLISECONDS], [ScheduledChore: Name: LogsCleaner Period: 60000 Unit: MILLISECONDS], [ScheduledChore: Name: master,16000,1446972456659-BalancerChore Period: 300000 Unit: MILLISECONDS], [ScheduledChore: Name: master,16000,1446972456659-ClusterStatusChore Period: 60000 Unit: MILLISECONDS]] on shutdown
2015-11-08 16:48:30,563 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave2,16020,1446972096396, master,16020,1446972095922, slave1,16020,1446972096399
2015-11-08 16:48:30,573 INFO  [master,16000,1446972456659_splitLogManager__ChoreService_1] master.SplitLogManager$TimeoutMonitor: Chore: SplitLogManager Timeout Monitor was stopped
2015-11-08 16:48:31,584 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave2,16020,1446972096396, master,16020,1446972095922, slave1,16020,1446972096399
2015-11-08 16:48:32,606 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave2,16020,1446972096396, master,16020,1446972095922, slave1,16020,1446972096399
2015-11-08 16:48:33,628 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave2,16020,1446972096396, master,16020,1446972095922, slave1,16020,1446972096399
2015-11-08 16:48:34,650 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave2,16020,1446972096396, master,16020,1446972095922, slave1,16020,1446972096399
2015-11-08 16:48:35,673 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave2,16020,1446972096396, master,16020,1446972095922, slave1,16020,1446972096399
2015-11-08 16:48:36,694 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave2,16020,1446972096396, master,16020,1446972095922, slave1,16020,1446972096399
2015-11-08 16:48:37,716 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave2,16020,1446972096396, master,16020,1446972095922, slave1,16020,1446972096399
2015-11-08 16:48:38,737 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave2,16020,1446972096396, master,16020,1446972095922, slave1,16020,1446972096399
2015-11-08 16:48:39,659 INFO  [main-EventThread] zookeeper.RegionServerTracker: RegionServer ephemeral node deleted, processing expiration [master,16020,1446972095922]
2015-11-08 16:48:39,659 INFO  [main-EventThread] master.ServerManager: Cluster shutdown set; master,16020,1446972095922 expired; onlineServers=2
2015-11-08 16:48:39,773 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave2,16020,1446972096396, slave1,16020,1446972096399
2015-11-08 16:48:39,951 INFO  [main-EventThread] zookeeper.RegionServerTracker: RegionServer ephemeral node deleted, processing expiration [slave1,16020,1446972096399]
2015-11-08 16:48:39,951 INFO  [main-EventThread] master.ServerManager: Cluster shutdown set; slave1,16020,1446972096399 expired; onlineServers=1
2015-11-08 16:48:40,867 INFO  [master/master/192.168.1.101:16000] master.ServerManager: Waiting on regionserver(s) to go down slave2,16020,1446972096396
2015-11-08 16:48:41,374 INFO  [main-EventThread] zookeeper.RegionServerTracker: RegionServer ephemeral node deleted, processing expiration [slave2,16020,1446972096396]
2015-11-08 16:48:41,374 INFO  [main-EventThread] master.ServerManager: Cluster shutdown set; slave2,16020,1446972096396 expired; onlineServers=0
2015-11-08 16:48:41,392 INFO  [master/master/192.168.1.101:16000] client.ConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x150e64779e70001
2015-11-08 16:48:41,404 INFO  [master/master/192.168.1.101:16000] zookeeper.ZooKeeper: Session: 0x150e64779e70001 closed
2015-11-08 16:48:41,404 INFO  [master:16000.activeMasterManager-EventThread] zookeeper.ClientCnxn: EventThread shut down
2015-11-08 16:48:41,507 INFO  [master/master/192.168.1.101:16000] hbase.ChoreService: Chore service for: master,16000,1446972456659_splitLogManager_ had [] on shutdown
2015-11-08 16:48:41,507 INFO  [master/master/192.168.1.101:16000] flush.MasterFlushTableProcedureManager: stop: server shutting down.
2015-11-08 16:48:41,507 INFO  [master/master/192.168.1.101:16000] ipc.RpcServer: Stopping server on 16000
2015-11-08 16:48:41,508 INFO  [RpcServer.listener,port=16000] ipc.RpcServer: RpcServer.listener,port=16000: stopping
2015-11-08 16:48:41,509 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopped
2015-11-08 16:48:41,509 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopping
2015-11-08 16:48:41,526 INFO  [master/master/192.168.1.101:16000] zookeeper.RecoverableZooKeeper: Node /hbase/rs/master,16000,1446972456659 already deleted, retry=false
2015-11-08 16:48:41,540 INFO  [main-EventThread] zookeeper.ClientCnxn: EventThread shut down
2015-11-08 16:48:41,540 INFO  [master/master/192.168.1.101:16000] zookeeper.ZooKeeper: Session: 0x150e64779e70000 closed
2015-11-08 16:48:41,541 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: stopping server master,16000,1446972456659; zookeeper connection closed.
2015-11-08 16:48:41,541 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: master/master/192.168.1.101:16000 exiting
Sun Nov  8 16:49:46 CST 2015 Starting master on master
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 30141
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 10240
cpu time               (seconds, -t) unlimited
max user processes              (-u) 1024
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2015-11-08 16:49:46,965 INFO  [main] util.VersionInfo: HBase 1.1.2
2015-11-08 16:49:46,965 INFO  [main] util.VersionInfo: Source code repository git://hw11397.local/Volumes/hbase-1.1.2RC2/hbase revision=cc2b70cf03e3378800661ec5cab11eb43fafe0fc
2015-11-08 16:49:46,965 INFO  [main] util.VersionInfo: Compiled by ndimiduk on Wed Aug 26 20:11:27 PDT 2015
2015-11-08 16:49:46,965 INFO  [main] util.VersionInfo: From source with checksum 73da41f3d1b867b7aba6166c77fafc17
2015-11-08 16:49:47,307 INFO  [main] util.ServerCommandLine: env:TERM=xterm
2015-11-08 16:49:47,307 INFO  [main] util.ServerCommandLine: env:HADOOP_COMMON_LIB_NATIVE_DIR=/opt/hadoop/lib/native
2015-11-08 16:49:47,307 INFO  [main] util.ServerCommandLine: env:IMSETTINGS_MODULE=none
2015-11-08 16:49:47,307 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/opt/java
2015-11-08 16:49:47,307 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/opt/hbase
2015-11-08 16:49:47,307 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2015-11-08 16:49:47,307 INFO  [main] util.ServerCommandLine: env:SESSION_MANAGER=local/unix:@/tmp/.ICE-unix/2957,unix/unix:/tmp/.ICE-unix/2957
2015-11-08 16:49:47,307 INFO  [main] util.ServerCommandLine: env:IMSETTINGS_INTEGRATE_DESKTOP=yes
2015-11-08 16:49:47,307 INFO  [main] util.ServerCommandLine: env:GNOME_DESKTOP_SESSION_ID=this-is-deprecated
2015-11-08 16:49:47,308 INFO  [main] util.ServerCommandLine: env:MAIL=/var/spool/mail/hadoop
2015-11-08 16:49:47,308 INFO  [main] util.ServerCommandLine: env:XDG_SESSION_COOKIE=ab8c9d4f5491283c7c300d7800000013-1446970837.780533-57183565
2015-11-08 16:49:47,308 INFO  [main] util.ServerCommandLine: env:GDMSESSION=gnome
2015-11-08 16:49:47,308 INFO  [main] util.ServerCommandLine: env:HOSTNAME=master
2015-11-08 16:49:47,308 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/tmp/hbase-hadoop-master.znode
2015-11-08 16:49:47,308 INFO  [main] util.ServerCommandLine: env:PWD=/opt/hbase/bin
2015-11-08 16:49:47,308 INFO  [main] util.ServerCommandLine: env:HBASE_MASTER_OPTS= -XX:PermSize=128m -XX:MaxPermSize=128m
2015-11-08 16:49:47,308 INFO  [main] util.ServerCommandLine: env:CVS_RSH=ssh
2015-11-08 16:49:47,308 INFO  [main] util.ServerCommandLine: env:JAVA_LIBRARY_PATH=/opt/hadoop/lib/native::/opt/hadoop/lib/native:
2015-11-08 16:49:47,308 INFO  [main] util.ServerCommandLine: env:G_BROKEN_FILENAMES=1
2015-11-08 16:49:47,308 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2015-11-08 16:49:47,308 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2015-11-08 16:49:47,308 INFO  [main] util.ServerCommandLine: env:NLSPATH=/usr/dt/lib/nls/msg/%L/%N.cat
2015-11-08 16:49:47,308 INFO  [main] util.ServerCommandLine: env:GNOME_KEYRING_SOCKET=/tmp/keyring-8q0f1M/socket
2015-11-08 16:49:47,308 INFO  [main] util.ServerCommandLine: env:GDM_KEYBOARD_LAYOUT=us
2015-11-08 16:49:47,309 INFO  [main] util.ServerCommandLine: env:HBASE_REGIONSERVER_OPTS= -XX:PermSize=128m -XX:MaxPermSize=128m
2015-11-08 16:49:47,309 INFO  [main] util.ServerCommandLine: env:HISTSIZE=1000
2015-11-08 16:49:47,309 INFO  [main] util.ServerCommandLine: env:PATH=/opt/hbase:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin:/sbin:/opt/java//bin:/opt/java/jre/bin:/opt/hadoop/bin:/home/hadoop/bin
2015-11-08 16:49:47,309 INFO  [main] util.ServerCommandLine: env:QTLIB=/usr/lib64/qt-3.3/lib
2015-11-08 16:49:47,309 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2015-11-08 16:49:47,309 INFO  [main] util.ServerCommandLine: env:GDM_LANG=en_US.UTF-8
2015-11-08 16:49:47,309 INFO  [main] util.ServerCommandLine: env:XAUTHORITY=/var/run/gdm/auth-for-hadoop-ApHB7y/database
2015-11-08 16:49:47,309 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/tmp/hbase-hadoop-master.autorestart
2015-11-08 16:49:47,309 INFO  [main] util.ServerCommandLine: env:USERNAME=hadoop
2015-11-08 16:49:47,309 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-hadoop-master-master.log
2015-11-08 16:49:47,309 INFO  [main] util.ServerCommandLine: env:SSH_ASKPASS=/usr/libexec/openssh/gnome-ssh-askpass
2015-11-08 16:49:47,309 INFO  [main] util.ServerCommandLine: env:SHLVL=6
2015-11-08 16:49:47,309 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/opt/hbase/logs
2015-11-08 16:49:47,310 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-XX:+UseConcMarkSweepGC   -XX:PermSize=128m -XX:MaxPermSize=128m -Dhbase.log.dir=/opt/hbase/logs -Dhbase.log.file=hbase-hadoop-master-master.log -Dhbase.home.dir=/opt/hbase -Dhbase.id.str=hadoop -Dhbase.root.logger=INFO,RFA -Djava.library.path=/opt/hadoop/lib/native::/opt/hadoop/lib/native: -Dhbase.security.logger=INFO,RFAS
2015-11-08 16:49:47,310 INFO  [main] util.ServerCommandLine: env:XFILESEARCHPATH=/usr/dt/app-defaults/%L/Dt
2015-11-08 16:49:47,310 INFO  [main] util.ServerCommandLine: env:COLORTERM=gnome-terminal
2015-11-08 16:49:47,310 INFO  [main] util.ServerCommandLine: env:QT_IM_MODULE=xim
2015-11-08 16:49:47,310 INFO  [main] util.ServerCommandLine: env:WINDOWID=23070685
2015-11-08 16:49:47,310 INFO  [main] util.ServerCommandLine: env:LOGNAME=hadoop
2015-11-08 16:49:47,310 INFO  [main] util.ServerCommandLine: env:QTDIR=/usr/lib64/qt-3.3
2015-11-08 16:49:47,310 INFO  [main] util.ServerCommandLine: env:XMODIFIERS=@im=none
2015-11-08 16:49:47,310 INFO  [main] util.ServerCommandLine: env:SSH_AUTH_SOCK=/tmp/keyring-8q0f1M/socket.ssh
2015-11-08 16:49:47,310 INFO  [main] util.ServerCommandLine: env:HADOOP_HOME=/opt/hadoop
2015-11-08 16:49:47,310 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=:/opt/hadoop/lib/native::/opt/hadoop/lib/native:
2015-11-08 16:49:47,310 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2015-11-08 16:49:47,310 INFO  [main] util.ServerCommandLine: env:HADOOP_OPTS=-Djava.library.path=/opt/hadoop/lib/native
2015-11-08 16:49:47,310 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2015-11-08 16:49:47,310 INFO  [main] util.ServerCommandLine: env:DBUS_SESSION_BUS_ADDRESS=unix:abstract=/tmp/dbus-BE8cSLU3kg,guid=266d9eaea9c6327e69c81ff6000000c7
2015-11-08 16:49:47,311 INFO  [main] util.ServerCommandLine: env:GNOME_KEYRING_PID=2947
2015-11-08 16:49:47,311 INFO  [main] util.ServerCommandLine: env:GTK_RC_FILES=/etc/gtk/gtkrc:/home/hadoop/.gtkrc-1.2-gnome2
2015-11-08 16:49:47,311 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2015-11-08 16:49:47,311 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/opt/hbase/conf:/opt/java/lib/tools.jar:/opt/hbase:/opt/hbase/lib/activation-1.1.jar:/opt/hbase/lib/aopalliance-1.0.jar:/opt/hbase/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hbase/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hbase/lib/api-asn1-api-1.0.0-M20.jar:/opt/hbase/lib/api-util-1.0.0-M20.jar:/opt/hbase/lib/asm-3.1.jar:/opt/hbase/lib/avro-1.7.4.jar:/opt/hbase/lib/commons-beanutils-1.7.0.jar:/opt/hbase/lib/commons-beanutils-core-1.8.0.jar:/opt/hbase/lib/commons-cli-1.2.jar:/opt/hbase/lib/commons-codec-1.9.jar:/opt/hbase/lib/commons-collections-3.2.1.jar:/opt/hbase/lib/commons-compress-1.4.1.jar:/opt/hbase/lib/commons-configuration-1.6.jar:/opt/hbase/lib/commons-daemon-1.0.13.jar:/opt/hbase/lib/commons-digester-1.8.jar:/opt/hbase/lib/commons-el-1.0.jar:/opt/hbase/lib/commons-httpclient-3.1.jar:/opt/hbase/lib/commons-io-2.4.jar:/opt/hbase/lib/commons-lang-2.6.jar:/opt/hbase/lib/commons-logging-1.2.jar:/opt/hbase/lib/commons-math-2.2.jar:/opt/hbase/lib/commons-math3-3.1.1.jar:/opt/hbase/lib/commons-net-3.1.jar:/opt/hbase/lib/disruptor-3.3.0.jar:/opt/hbase/lib/findbugs-annotations-1.3.9-1.jar:/opt/hbase/lib/guava-12.0.1.jar:/opt/hbase/lib/guice-3.0.jar:/opt/hbase/lib/guice-servlet-3.0.jar:/opt/hbase/lib/hadoop-annotations-2.5.1.jar:/opt/hbase/lib/hadoop-auth-2.5.1.jar:/opt/hbase/lib/hadoop-client-2.5.1.jar:/opt/hbase/lib/hadoop-common-2.5.1.jar:/opt/hbase/lib/hadoop-hdfs-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-app-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-common-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-core-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-jobclient-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-shuffle-2.5.1.jar:/opt/hbase/lib/hadoop-yarn-api-2.5.1.jar:/opt/hbase/lib/hadoop-yarn-client-2.5.1.jar:/opt/hbase/lib/hadoop-yarn-common-2.5.1.jar:/opt/hbase/lib/hadoop-yarn-server-common-2.5.1.jar:/opt/hbase/lib/hbase-annotations-1.1.2.jar:/opt/hbase/lib/hbase-annotations-1.1.2-tests.jar:/opt/hbase/lib/hbase-client-1.1.2.jar:/opt/hbase/lib/hbase-common-1.1.2.jar:/opt/hbase/lib/hbase-common-1.1.2-tests.jar:/opt/hbase/lib/hbase-examples-1.1.2.jar:/opt/hbase/lib/hbase-hadoop2-compat-1.1.2.jar:/opt/hbase/lib/hbase-hadoop-compat-1.1.2.jar:/opt/hbase/lib/hbase-it-1.1.2.jar:/opt/hbase/lib/hbase-it-1.1.2-tests.jar:/opt/hbase/lib/hbase-prefix-tree-1.1.2.jar:/opt/hbase/lib/hbase-procedure-1.1.2.jar:/opt/hbase/lib/hbase-protocol-1.1.2.jar:/opt/hbase/lib/hbase-resource-bundle-1.1.2.jar:/opt/hbase/lib/hbase-rest-1.1.2.jar:/opt/hbase/lib/hbase-server-1.1.2.jar:/opt/hbase/lib/hbase-server-1.1.2-tests.jar:/opt/hbase/lib/hbase-shell-1.1.2.jar:/opt/hbase/lib/hbase-thrift-1.1.2.jar:/opt/hbase/lib/htrace-core-3.1.0-incubating.jar:/opt/hbase/lib/httpclient-4.2.5.jar:/opt/hbase/lib/httpcore-4.1.3.jar:/opt/hbase/lib/jackson-core-asl-1.9.13.jar:/opt/hbase/lib/jackson-jaxrs-1.9.13.jar:/opt/hbase/lib/jackson-mapper-asl-1.9.13.jar:/opt/hbase/lib/jackson-xc-1.9.13.jar:/opt/hbase/lib/jamon-runtime-2.3.1.jar:/opt/hbase/lib/jasper-compiler-5.5.23.jar:/opt/hbase/lib/jasper-runtime-5.5.23.jar:/opt/hbase/lib/javax.inject-1.jar:/opt/hbase/lib/java-xmlbuilder-0.4.jar:/opt/hbase/lib/jaxb-api-2.2.2.jar:/opt/hbase/lib/jaxb-impl-2.2.3-1.jar:/opt/hbase/lib/jcodings-1.0.8.jar:/opt/hbase/lib/jersey-client-1.9.jar:/opt/hbase/lib/jersey-core-1.9.jar:/opt/hbase/lib/jersey-guice-1.9.jar:/opt/hbase/lib/jersey-json-1.9.jar:/opt/hbase/lib/jersey-server-1.9.jar:/opt/hbase/lib/jets3t-0.9.0.jar:/opt/hbase/lib/jettison-1.3.3.jar:/opt/hbase/lib/jetty-6.1.26.jar:/opt/hbase/lib/jetty-sslengine-6.1.26.jar:/opt/hbase/lib/jetty-util-6.1.26.jar:/opt/hbase/lib/joni-2.1.2.jar:/opt/hbase/lib/jruby-complete-1.6.8.jar:/opt/hbase/lib/jsch-0.1.42.jar:/opt/hbase/lib/jsp-2.1-6.1.14.jar:/opt/hbase/lib/jsp-api-2.1-6.1.14.jar:/opt/hbase/lib/jsr305-1.3.9.jar:/opt/hbase/lib/junit-4.11.jar:/opt/hbase/lib/leveldbjni-all-1.8.jar:/opt/hbase/lib/libthrift-0.9.0.jar:/opt/hbase/lib/log4j-1.2.17.jar:/opt/hbase/lib/metrics-core-2.2.0.jar:/opt/hbase/lib/netty-3.2.4.Final.jar:/opt/hbase/lib/netty-all-4.0.23.Final.jar:/opt/hbase/lib/paranamer-2.3.jar:/opt/hbase/lib/protobuf-java-2.5.0.jar:/opt/hbase/lib/servlet-api-2.5-6.1.14.jar:/opt/hbase/lib/servlet-api-2.5.jar:/opt/hbase/lib/slf4j-api-1.7.7.jar:/opt/hbase/lib/slf4j-log4j12-1.7.5.jar:/opt/hbase/lib/snappy-java-1.0.4.1.jar:/opt/hbase/lib/spymemcached-2.11.6.jar:/opt/hbase/lib/xmlenc-0.52.jar:/opt/hbase/lib/xz-1.0.jar:/opt/hbase/lib/zookeeper-3.4.6.jar:/opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/contrib/capacity-scheduler/*.jar
2015-11-08 16:49:47,312 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2015-11-08 16:49:47,312 INFO  [main] util.ServerCommandLine: env:JRE_HOME=/opt/java/jre
2015-11-08 16:49:47,312 INFO  [main] util.ServerCommandLine: env:DESKTOP_SESSION=gnome
2015-11-08 16:49:47,312 INFO  [main] util.ServerCommandLine: env:QTINC=/usr/lib64/qt-3.3/include
2015-11-08 16:49:47,312 INFO  [main] util.ServerCommandLine: env:DISPLAY=192.168.1.100:1.0
2015-11-08 16:49:47,312 INFO  [main] util.ServerCommandLine: env:USER=hadoop
2015-11-08 16:49:47,312 INFO  [main] util.ServerCommandLine: env:HISTCONTROL=ignoredups
2015-11-08 16:49:47,312 INFO  [main] util.ServerCommandLine: env:HOME=/home/hadoop
2015-11-08 16:49:47,312 INFO  [main] util.ServerCommandLine: env:LESSOPEN=||/usr/bin/lesspipe.sh %s
2015-11-08 16:49:47,312 INFO  [main] util.ServerCommandLine: env:ORBIT_SOCKETDIR=/tmp/orbit-hadoop
2015-11-08 16:49:47,312 INFO  [main] util.ServerCommandLine: env:LANG=en_US.UTF-8
2015-11-08 16:49:47,312 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-hadoop-master-master
2015-11-08 16:49:47,312 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=hadoop
2015-11-08 16:49:47,314 INFO  [main] util.ServerCommandLine: vmName=Java HotSpot(TM) 64-Bit Server VM, vmVendor=Oracle Corporation, vmVersion=24.79-b02
2015-11-08 16:49:47,314 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_master, -XX:OnOutOfMemoryError=kill -9 %p, -XX:+UseConcMarkSweepGC, -XX:PermSize=128m, -XX:MaxPermSize=128m, -Dhbase.log.dir=/opt/hbase/logs, -Dhbase.log.file=hbase-hadoop-master-master.log, -Dhbase.home.dir=/opt/hbase, -Dhbase.id.str=hadoop, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=/opt/hadoop/lib/native::/opt/hadoop/lib/native:, -Dhbase.security.logger=INFO,RFAS]
2015-11-08 16:49:47,801 WARN  [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-11-08 16:49:48,057 INFO  [main] regionserver.RSRpcServices: master/master/192.168.1.101:16000 server-side HConnection retries=350
2015-11-08 16:49:48,218 INFO  [main] ipc.SimpleRpcScheduler: Using deadline as user call queue, count=3
2015-11-08 16:49:48,247 INFO  [main] ipc.RpcServer: master/master/192.168.1.101:16000: started 10 reader(s).
2015-11-08 16:49:48,318 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2015-11-08 16:49:48,385 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-11-08 16:49:48,385 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2015-11-08 16:49:49,208 INFO  [main] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2015-11-08 16:49:49,446 INFO  [main] zookeeper.RecoverableZooKeeper: Process identifier=master:16000 connecting to ZooKeeper ensemble=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181
2015-11-08 16:49:49,455 INFO  [main] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2015-11-08 16:49:49,455 INFO  [main] zookeeper.ZooKeeper: Client environment:host.name=master
2015-11-08 16:49:49,455 INFO  [main] zookeeper.ZooKeeper: Client environment:java.version=1.7.0_79
2015-11-08 16:49:49,455 INFO  [main] zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
2015-11-08 16:49:49,455 INFO  [main] zookeeper.ZooKeeper: Client environment:java.home=/opt/java/jre
2015-11-08 16:49:49,455 INFO  [main] zookeeper.ZooKeeper: Client environment:java.class.path=/opt/hbase/conf:/opt/java/lib/tools.jar:/opt/hbase:/opt/hbase/lib/activation-1.1.jar:/opt/hbase/lib/aopalliance-1.0.jar:/opt/hbase/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hbase/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hbase/lib/api-asn1-api-1.0.0-M20.jar:/opt/hbase/lib/api-util-1.0.0-M20.jar:/opt/hbase/lib/asm-3.1.jar:/opt/hbase/lib/avro-1.7.4.jar:/opt/hbase/lib/commons-beanutils-1.7.0.jar:/opt/hbase/lib/commons-beanutils-core-1.8.0.jar:/opt/hbase/lib/commons-cli-1.2.jar:/opt/hbase/lib/commons-codec-1.9.jar:/opt/hbase/lib/commons-collections-3.2.1.jar:/opt/hbase/lib/commons-compress-1.4.1.jar:/opt/hbase/lib/commons-configuration-1.6.jar:/opt/hbase/lib/commons-daemon-1.0.13.jar:/opt/hbase/lib/commons-digester-1.8.jar:/opt/hbase/lib/commons-el-1.0.jar:/opt/hbase/lib/commons-httpclient-3.1.jar:/opt/hbase/lib/commons-io-2.4.jar:/opt/hbase/lib/commons-lang-2.6.jar:/opt/hbase/lib/commons-logging-1.2.jar:/opt/hbase/lib/commons-math-2.2.jar:/opt/hbase/lib/commons-math3-3.1.1.jar:/opt/hbase/lib/commons-net-3.1.jar:/opt/hbase/lib/disruptor-3.3.0.jar:/opt/hbase/lib/findbugs-annotations-1.3.9-1.jar:/opt/hbase/lib/guava-12.0.1.jar:/opt/hbase/lib/guice-3.0.jar:/opt/hbase/lib/guice-servlet-3.0.jar:/opt/hbase/lib/hadoop-annotations-2.5.1.jar:/opt/hbase/lib/hadoop-auth-2.5.1.jar:/opt/hbase/lib/hadoop-client-2.5.1.jar:/opt/hbase/lib/hadoop-common-2.5.1.jar:/opt/hbase/lib/hadoop-hdfs-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-app-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-common-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-core-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-jobclient-2.5.1.jar:/opt/hbase/lib/hadoop-mapreduce-client-shuffle-2.5.1.jar:/opt/hbase/lib/hadoop-yarn-api-2.5.1.jar:/opt/hbase/lib/hadoop-yarn-client-2.5.1.jar:/opt/hbase/lib/hadoop-yarn-common-2.5.1.jar:/opt/hbase/lib/hadoop-yarn-server-common-2.5.1.jar:/opt/hbase/lib/hbase-annotations-1.1.2.jar:/opt/hbase/lib/hbase-annotations-1.1.2-tests.jar:/opt/hbase/lib/hbase-client-1.1.2.jar:/opt/hbase/lib/hbase-common-1.1.2.jar:/opt/hbase/lib/hbase-common-1.1.2-tests.jar:/opt/hbase/lib/hbase-examples-1.1.2.jar:/opt/hbase/lib/hbase-hadoop2-compat-1.1.2.jar:/opt/hbase/lib/hbase-hadoop-compat-1.1.2.jar:/opt/hbase/lib/hbase-it-1.1.2.jar:/opt/hbase/lib/hbase-it-1.1.2-tests.jar:/opt/hbase/lib/hbase-prefix-tree-1.1.2.jar:/opt/hbase/lib/hbase-procedure-1.1.2.jar:/opt/hbase/lib/hbase-protocol-1.1.2.jar:/opt/hbase/lib/hbase-resource-bundle-1.1.2.jar:/opt/hbase/lib/hbase-rest-1.1.2.jar:/opt/hbase/lib/hbase-server-1.1.2.jar:/opt/hbase/lib/hbase-server-1.1.2-tests.jar:/opt/hbase/lib/hbase-shell-1.1.2.jar:/opt/hbase/lib/hbase-thrift-1.1.2.jar:/opt/hbase/lib/htrace-core-3.1.0-incubating.jar:/opt/hbase/lib/httpclient-4.2.5.jar:/opt/hbase/lib/httpcore-4.1.3.jar:/opt/hbase/lib/jackson-core-asl-1.9.13.jar:/opt/hbase/lib/jackson-jaxrs-1.9.13.jar:/opt/hbase/lib/jackson-mapper-asl-1.9.13.jar:/opt/hbase/lib/jackson-xc-1.9.13.jar:/opt/hbase/lib/jamon-runtime-2.3.1.jar:/opt/hbase/lib/jasper-compiler-5.5.23.jar:/opt/hbase/lib/jasper-runtime-5.5.23.jar:/opt/hbase/lib/javax.inject-1.jar:/opt/hbase/lib/java-xmlbuilder-0.4.jar:/opt/hbase/lib/jaxb-api-2.2.2.jar:/opt/hbase/lib/jaxb-impl-2.2.3-1.jar:/opt/hbase/lib/jcodings-1.0.8.jar:/opt/hbase/lib/jersey-client-1.9.jar:/opt/hbase/lib/jersey-core-1.9.jar:/opt/hbase/lib/jersey-guice-1.9.jar:/opt/hbase/lib/jersey-json-1.9.jar:/opt/hbase/lib/jersey-server-1.9.jar:/opt/hbase/lib/jets3t-0.9.0.jar:/opt/hbase/lib/jettison-1.3.3.jar:/opt/hbase/lib/jetty-6.1.26.jar:/opt/hbase/lib/jetty-sslengine-6.1.26.jar:/opt/hbase/lib/jetty-util-6.1.26.jar:/opt/hbase/lib/joni-2.1.2.jar:/opt/hbase/lib/jruby-complete-1.6.8.jar:/opt/hbase/lib/jsch-0.1.42.jar:/opt/hbase/lib/jsp-2.1-6.1.14.jar:/opt/hbase/lib/jsp-api-2.1-6.1.14.jar:/opt/hbase/lib/jsr305-1.3.9.jar:/opt/hbase/lib/junit-4.11.jar:/opt/hbase/lib/leveldbjni-all-1.8.jar:/opt/hbase/lib/libthrift-0.9.0.jar:/opt/hbase/lib/log4j-1.2.17.jar:/opt/hbase/lib/metrics-core-2.2.0.jar:/opt/hbase/lib/netty-3.2.4.Final.jar:/opt/hbase/lib/netty-all-4.0.23.Final.jar:/opt/hbase/lib/paranamer-2.3.jar:/opt/hbase/lib/protobuf-java-2.5.0.jar:/opt/hbase/lib/servlet-api-2.5-6.1.14.jar:/opt/hbase/lib/servlet-api-2.5.jar:/opt/hbase/lib/slf4j-api-1.7.7.jar:/opt/hbase/lib/slf4j-log4j12-1.7.5.jar:/opt/hbase/lib/snappy-java-1.0.4.1.jar:/opt/hbase/lib/spymemcached-2.11.6.jar:/opt/hbase/lib/xmlenc-0.52.jar:/opt/hbase/lib/xz-1.0.jar:/opt/hbase/lib/zookeeper-3.4.6.jar:/opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-auth-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/opt/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/opt/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop/share/hadoop/common/lib/curator-framework-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/opt/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/opt/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop/share/hadoop/common/lib/curator-client-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/opt/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-annotations-2.6.0.jar:/opt/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/opt/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop/share/hadoop/common/lib/htrace-core-3.0.4.jar:/opt/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop/share/hadoop/common/hadoop-common-2.6.0-tests.jar:/opt/hadoop/share/hadoop/common/hadoop-common-2.6.0.jar:/opt/hadoop/share/hadoop/common/hadoop-nfs-2.6.0.jar:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/opt/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.6.0-tests.jar:/opt/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jline-0.9.94.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.6.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-tests.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar
2015-11-08 16:49:49,455 INFO  [main] zookeeper.ZooKeeper: Client environment:java.library.path=/opt/hadoop/lib/native::/opt/hadoop/lib/native:
2015-11-08 16:49:49,455 INFO  [main] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2015-11-08 16:49:49,455 INFO  [main] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2015-11-08 16:49:49,455 INFO  [main] zookeeper.ZooKeeper: Client environment:os.name=Linux
2015-11-08 16:49:49,455 INFO  [main] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2015-11-08 16:49:49,455 INFO  [main] zookeeper.ZooKeeper: Client environment:os.version=2.6.32-573.el6.x86_64
2015-11-08 16:49:49,456 INFO  [main] zookeeper.ZooKeeper: Client environment:user.name=hadoop
2015-11-08 16:49:49,456 INFO  [main] zookeeper.ZooKeeper: Client environment:user.home=/home/hadoop
2015-11-08 16:49:49,456 INFO  [main] zookeeper.ZooKeeper: Client environment:user.dir=/opt/hbase/bin
2015-11-08 16:49:49,457 INFO  [main] zookeeper.ZooKeeper: Initiating client connection, connectString=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181 sessionTimeout=90000 watcher=master:160000x0, quorum=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181, baseZNode=/hbase
2015-11-08 16:49:49,476 INFO  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 16:49:49,479 INFO  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.106/192.168.1.106:2181, initiating session
2015-11-08 16:49:49,562 INFO  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.106/192.168.1.106:2181, sessionid = 0x250e6497c8a0000, negotiated timeout = 90000
2015-11-08 16:49:49,631 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2015-11-08 16:49:49,631 INFO  [RpcServer.listener,port=16000] ipc.RpcServer: RpcServer.listener,port=16000: starting
2015-11-08 16:49:49,713 INFO  [main] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-11-08 16:49:49,716 INFO  [main] http.HttpRequestLog: Http request log for http.requests.master is not defined
2015-11-08 16:49:49,731 INFO  [main] http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.hbase.http.HttpServer$QuotingInputFilter)
2015-11-08 16:49:49,734 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context master
2015-11-08 16:49:49,734 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-11-08 16:49:49,734 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-11-08 16:49:49,755 INFO  [main] http.HttpServer: Jetty bound to port 16010
2015-11-08 16:49:49,755 INFO  [main] mortbay.log: jetty-6.1.26
2015-11-08 16:49:50,237 INFO  [main] mortbay.log: Started SelectChannelConnector@0.0.0.0:16010
2015-11-08 16:49:50,244 INFO  [main] master.HMaster: hbase.rootdir=hdfs://192.168.1.101:9000/hbase, hbase.cluster.distributed=true
2015-11-08 16:49:50,269 INFO  [main] master.HMaster: Adding backup master ZNode /hbase/backup-masters/master,16000,1446972588401
2015-11-08 16:49:50,478 INFO  [master:16000.activeMasterManager] master.ActiveMasterManager: Deleting ZNode for /hbase/backup-masters/master,16000,1446972588401 from backup master directory
2015-11-08 16:49:50,490 INFO  [master:16000.activeMasterManager] master.ActiveMasterManager: Registered Active Master=master,16000,1446972588401
2015-11-08 16:49:50,615 INFO  [master/master/192.168.1.101:16000] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x18e5eaed connecting to ZooKeeper ensemble=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181
2015-11-08 16:49:50,615 INFO  [master/master/192.168.1.101:16000] zookeeper.ZooKeeper: Initiating client connection, connectString=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181 sessionTimeout=90000 watcher=hconnection-0x18e5eaed0x0, quorum=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181, baseZNode=/hbase
2015-11-08 16:49:50,625 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 16:49:50,625 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.102/192.168.1.102:2181, initiating session
2015-11-08 16:49:50,661 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.102/192.168.1.102:2181, sessionid = 0x150e6497c4e0000, negotiated timeout = 90000
2015-11-08 16:49:50,912 INFO  [master:16000.activeMasterManager] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2015-11-08 16:49:50,930 INFO  [master:16000.activeMasterManager] coordination.SplitLogManagerCoordination: Found 0 orphan tasks and 0 rescan nodes
2015-11-08 16:49:50,973 INFO  [master:16000.activeMasterManager] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x7e807ed8 connecting to ZooKeeper ensemble=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181
2015-11-08 16:49:50,973 INFO  [master:16000.activeMasterManager] zookeeper.ZooKeeper: Initiating client connection, connectString=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181 sessionTimeout=90000 watcher=hconnection-0x7e807ed80x0, quorum=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181, baseZNode=/hbase
2015-11-08 16:49:50,974 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.101/192.168.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 16:49:50,974 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.101/192.168.1.101:2181, initiating session
2015-11-08 16:49:51,002 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.101/192.168.1.101:2181, sessionid = 0x50e6497fc90000, negotiated timeout = 90000
2015-11-08 16:49:51,034 INFO  [master:16000.activeMasterManager] balancer.StochasticLoadBalancer: loading config
2015-11-08 16:49:51,117 INFO  [master:16000.activeMasterManager] master.HMaster: Server active/primary master=master,16000,1446972588401, sessionid=0x250e6497c8a0000, setting cluster-up flag (Was=false)
2015-11-08 16:49:51,119 INFO  [master/master/192.168.1.101:16000] regionserver.HRegionServer: ClusterId : 18e4235c-98ec-4147-8ac4-00cf10508c80
2015-11-08 16:49:51,145 INFO  [master:16000.activeMasterManager] procedure.ZKProcedureUtil: Clearing all procedure znodes: /hbase/online-snapshot/acquired /hbase/online-snapshot/reached /hbase/online-snapshot/abort
2015-11-08 16:49:51,165 INFO  [master:16000.activeMasterManager] procedure.ZKProcedureUtil: Clearing all procedure znodes: /hbase/flush-table-proc/acquired /hbase/flush-table-proc/reached /hbase/flush-table-proc/abort
2015-11-08 16:49:51,213 INFO  [master:16000.activeMasterManager] master.MasterCoprocessorHost: System coprocessor loading is enabled
2015-11-08 16:49:51,230 INFO  [master:16000.activeMasterManager] procedure2.ProcedureExecutor: Starting procedure executor threads=5
2015-11-08 16:49:51,231 INFO  [master:16000.activeMasterManager] wal.WALProcedureStore: Starting WAL Procedure Store lease recovery
2015-11-08 16:49:51,236 INFO  [master:16000.activeMasterManager] util.FSHDFSUtils: Recovering lease on dfs file hdfs://192.168.1.101:9000/hbase/MasterProcWALs/state-00000000000000000007.log
2015-11-08 16:49:51,243 INFO  [master:16000.activeMasterManager] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://192.168.1.101:9000/hbase/MasterProcWALs/state-00000000000000000007.log after 6ms
2015-11-08 16:49:51,306 INFO  [master:16000.activeMasterManager] wal.WALProcedureStore: Lease acquired for flushLogId: 8
2015-11-08 16:49:51,313 INFO  [master:16000.activeMasterManager] wal.ProcedureWALFormatReader: No active entry found in state log hdfs://192.168.1.101:9000/hbase/MasterProcWALs/state-00000000000000000007.log. removing it
2015-11-08 16:49:51,329 INFO  [master:16000.activeMasterManager] zookeeper.RecoverableZooKeeper: Process identifier=replicationLogCleaner connecting to ZooKeeper ensemble=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181
2015-11-08 16:49:51,329 INFO  [master:16000.activeMasterManager] zookeeper.ZooKeeper: Initiating client connection, connectString=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181 sessionTimeout=90000 watcher=replicationLogCleaner0x0, quorum=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181, baseZNode=/hbase
2015-11-08 16:49:51,330 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.101/192.168.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-08 16:49:51,330 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.101/192.168.1.101:2181, initiating session
2015-11-08 16:49:51,338 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.101/192.168.1.101:2181, sessionid = 0x50e6497fc90001, negotiated timeout = 90000
2015-11-08 16:49:51,373 INFO  [master:16000.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 0 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2015-11-08 16:49:51,854 INFO  [PriorityRpcServer.handler=16,queue=0,port=16000] master.ServerManager: Registering server=master,16020,1446972589711
2015-11-08 16:49:51,875 INFO  [master:16000.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 1, slept for 502 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2015-11-08 16:49:52,864 INFO  [PriorityRpcServer.handler=17,queue=1,port=16000] master.ServerManager: Registering server=slave2,16020,1446972590072
2015-11-08 16:49:52,877 INFO  [master:16000.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 2, slept for 1504 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2015-11-08 16:49:53,249 INFO  [PriorityRpcServer.handler=14,queue=0,port=16000] master.ServerManager: Registering server=slave1,16020,1446972590261
2015-11-08 16:49:53,277 INFO  [master:16000.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 3, slept for 1904 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2015-11-08 16:49:54,780 INFO  [master:16000.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 3, slept for 3407 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2015-11-08 16:49:55,884 INFO  [master:16000.activeMasterManager] master.ServerManager: Finished waiting for region servers count to settle; checked in 3, slept for 4511 ms, expecting minimum of 1, maximum of 2147483647, master is running
2015-11-08 16:49:55,903 INFO  [master:16000.activeMasterManager] master.MasterFileSystem: Log folder hdfs://192.168.1.101:9000/hbase/WALs/master,16020,1446972589711 belongs to an existing region server
2015-11-08 16:49:55,908 INFO  [master:16000.activeMasterManager] master.MasterFileSystem: Log folder hdfs://192.168.1.101:9000/hbase/WALs/slave1,16020,1446972590261 belongs to an existing region server
2015-11-08 16:49:55,913 INFO  [master:16000.activeMasterManager] master.MasterFileSystem: Log folder hdfs://192.168.1.101:9000/hbase/WALs/slave2,16020,1446972590072 belongs to an existing region server
2015-11-08 16:49:56,083 INFO  [master:16000.activeMasterManager] zookeeper.MetaTableLocator: Failed verification of hbase:meta,,1 at address=slave2,16020,1446972096396, exception=org.apache.hadoop.hbase.NotServingRegionException: Region hbase:meta,,1 is not online on slave2,16020,1446972590072
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2898)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.getRegion(RSRpcServices.java:947)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.getRegionInfo(RSRpcServices.java:1232)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$2.callBlockingMethod(AdminProtos.java:22233)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2114)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:101)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:130)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:107)
	at java.lang.Thread.run(Thread.java:745)

2015-11-08 16:49:56,101 INFO  [master:16000.activeMasterManager] master.SplitLogManager: dead splitlog workers [slave2,16020,1446972096396]
2015-11-08 16:49:56,106 INFO  [master:16000.activeMasterManager] master.SplitLogManager: hdfs://192.168.1.101:9000/hbase/WALs/slave2,16020,1446972096396-splitting is empty dir, no logs to split
2015-11-08 16:49:56,107 INFO  [master:16000.activeMasterManager] master.SplitLogManager: started splitting 0 logs in [hdfs://192.168.1.101:9000/hbase/WALs/slave2,16020,1446972096396-splitting] for [slave2,16020,1446972096396]
2015-11-08 16:49:56,115 INFO  [master:16000.activeMasterManager] master.SplitLogManager: finished splitting (more than or equal to) 0 bytes in 0 log files in [hdfs://192.168.1.101:9000/hbase/WALs/slave2,16020,1446972096396-splitting] in 8ms
2015-11-08 16:49:56,116 INFO  [master:16000.activeMasterManager] zookeeper.MetaTableLocator: Deleting hbase:meta region location in ZooKeeper
2015-11-08 16:49:56,196 INFO  [master:16000.activeMasterManager] master.AssignmentManager: Assigning hbase:meta,,1.1588230740 to slave2,16020,1446972590072
2015-11-08 16:49:56,196 INFO  [master:16000.activeMasterManager] master.RegionStates: Transition {1588230740 state=OFFLINE, ts=1446972596171, server=null} to {1588230740 state=PENDING_OPEN, ts=1446972596196, server=slave2,16020,1446972590072}
2015-11-08 16:49:56,263 INFO  [master:16000.activeMasterManager] master.ServerManager: AssignmentManager hasn't finished failover cleanup; waiting
2015-11-08 16:49:56,323 INFO  [AM.ZK.Worker-pool2-t1] master.RegionStates: Transition {1588230740 state=PENDING_OPEN, ts=1446972596196, server=slave2,16020,1446972590072} to {1588230740 state=OPENING, ts=1446972596323, server=slave2,16020,1446972590072}
2015-11-08 16:49:57,150 INFO  [AM.ZK.Worker-pool2-t2] master.RegionStates: Transition {1588230740 state=OPENING, ts=1446972596323, server=slave2,16020,1446972590072} to {1588230740 state=OPEN, ts=1446972597150, server=slave2,16020,1446972590072}
2015-11-08 16:49:57,153 INFO  [AM.ZK.Worker-pool2-t2] coordination.ZkOpenRegionCoordination: Handling OPENED of 1588230740 from master,16000,1446972588401; deleting unassigned node
2015-11-08 16:49:57,173 INFO  [master:16000.activeMasterManager] master.HMaster: hbase:meta with replicaId 0 assigned=1, rit=false, location=slave2,16020,1446972590072
2015-11-08 16:49:57,342 INFO  [master:16000.activeMasterManager] hbase.MetaMigrationConvertingToPB: META already up-to date with PB serialization
2015-11-08 16:49:57,386 INFO  [master:16000.activeMasterManager] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=OPEN, ts=1446972597386, server=slave2,16020,1446972096396} to {6f3d653b8b106cc2df931825f52d6dec state=OFFLINE, ts=1446972597386, server=slave2,16020,1446972096396}
2015-11-08 16:49:57,394 INFO  [master:16000.activeMasterManager] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=OFFLINE, ts=1446972597386, server=slave2,16020,1446972096396} to {6f3d653b8b106cc2df931825f52d6dec state=CLOSED, ts=1446972597394, server=slave2,16020,1446972096396}
2015-11-08 16:49:57,397 INFO  [master:16000.activeMasterManager] master.AssignmentManager: Clean cluster startup. Assigning user regions
2015-11-08 16:49:57,410 INFO  [master:16000.activeMasterManager] balancer.BaseLoadBalancer: Reassigned 1 regions. 1 retained the pre-restart assignment. 
2015-11-08 16:49:57,410 INFO  [master:16000.activeMasterManager] master.AssignmentManager: Bulk assigning 1 region(s) across 3 server(s), retainAssignment=true
2015-11-08 16:49:57,413 INFO  [master,16000,1446972588401-GeneralBulkAssigner-2] master.AssignmentManager: Assigning 1 region(s) to slave2,16020,1446972590072
2015-11-08 16:49:57,418 INFO  [master,16000,1446972588401-GeneralBulkAssigner-2] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=CLOSED, ts=1446972597394, server=slave2,16020,1446972096396} to {6f3d653b8b106cc2df931825f52d6dec state=OFFLINE, ts=1446972597418, server=slave2,16020,1446972096396}
2015-11-08 16:49:57,439 INFO  [master,16000,1446972588401-GeneralBulkAssigner-2] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=OFFLINE, ts=1446972597418, server=slave2,16020,1446972096396} to {6f3d653b8b106cc2df931825f52d6dec state=PENDING_OPEN, ts=1446972597439, server=slave2,16020,1446972590072}
2015-11-08 16:49:57,496 INFO  [master:16000.activeMasterManager] master.AssignmentManager: Bulk assigning done
2015-11-08 16:49:57,549 INFO  [AM.ZK.Worker-pool2-t5] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=PENDING_OPEN, ts=1446972597439, server=slave2,16020,1446972590072} to {6f3d653b8b106cc2df931825f52d6dec state=OPENING, ts=1446972597549, server=slave2,16020,1446972590072}
2015-11-08 16:49:57,556 INFO  [master:16000.activeMasterManager] master.AssignmentManager: Joined the cluster in 214ms, failover=false
2015-11-08 16:49:57,903 INFO  [AM.ZK.Worker-pool2-t6] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=OPENING, ts=1446972597549, server=slave2,16020,1446972590072} to {6f3d653b8b106cc2df931825f52d6dec state=OPEN, ts=1446972597903, server=slave2,16020,1446972590072}
2015-11-08 16:49:57,920 INFO  [AM.ZK.Worker-pool2-t8] master.RegionStates: Offlined 6f3d653b8b106cc2df931825f52d6dec from slave2,16020,1446972096396
2015-11-08 16:49:58,143 INFO  [master:16000.activeMasterManager] master.HMaster: Master has completed initialization
2015-11-08 16:49:58,154 INFO  [master:16000.activeMasterManager] quotas.MasterQuotaManager: Quota support disabled
2015-11-08 16:54:57,610 INFO  [master,16000,1446972588401_ChoreService_1] master.HMaster: balance hri=hbase:namespace,,1446969270988.6f3d653b8b106cc2df931825f52d6dec., src=slave2,16020,1446972590072, dest=slave1,16020,1446972590261
2015-11-08 16:54:57,635 INFO  [master,16000,1446972588401_ChoreService_1] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=OPEN, ts=1446972597920, server=slave2,16020,1446972590072} to {6f3d653b8b106cc2df931825f52d6dec state=PENDING_CLOSE, ts=1446972897635, server=slave2,16020,1446972590072}
2015-11-08 16:54:57,804 INFO  [AM.ZK.Worker-pool2-t10] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=PENDING_CLOSE, ts=1446972897635, server=slave2,16020,1446972590072} to {6f3d653b8b106cc2df931825f52d6dec state=CLOSED, ts=1446972897804, server=slave2,16020,1446972590072}
2015-11-08 16:54:57,804 INFO  [AM.ZK.Worker-pool2-t10] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=CLOSED, ts=1446972897804, server=slave2,16020,1446972590072} to {6f3d653b8b106cc2df931825f52d6dec state=OFFLINE, ts=1446972897804, server=slave2,16020,1446972590072}
2015-11-08 16:54:57,816 INFO  [AM.ZK.Worker-pool2-t10] master.AssignmentManager: Assigning hbase:namespace,,1446969270988.6f3d653b8b106cc2df931825f52d6dec. to slave1,16020,1446972590261
2015-11-08 16:54:57,817 INFO  [AM.ZK.Worker-pool2-t10] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=OFFLINE, ts=1446972897804, server=slave2,16020,1446972590072} to {6f3d653b8b106cc2df931825f52d6dec state=PENDING_OPEN, ts=1446972897816, server=slave1,16020,1446972590261}
2015-11-08 16:54:58,150 INFO  [AM.ZK.Worker-pool2-t12] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=PENDING_OPEN, ts=1446972897816, server=slave1,16020,1446972590261} to {6f3d653b8b106cc2df931825f52d6dec state=OPENING, ts=1446972898150, server=slave1,16020,1446972590261}
2015-11-08 16:54:59,001 INFO  [AM.ZK.Worker-pool2-t13] master.RegionStates: Transition {6f3d653b8b106cc2df931825f52d6dec state=OPENING, ts=1446972898150, server=slave1,16020,1446972590261} to {6f3d653b8b106cc2df931825f52d6dec state=OPEN, ts=1446972899001, server=slave1,16020,1446972590261}
2015-11-08 16:54:59,024 INFO  [AM.ZK.Worker-pool2-t15] master.RegionStates: Offlined 6f3d653b8b106cc2df931825f52d6dec from slave2,16020,1446972590072
2015-11-09 11:03:14,288 WARN  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Session 0x50e6497fc90000 for server 192.168.1.101/192.168.1.101:2181, unexpected error, closing socket connection and attempting reconnect
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:68)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:366)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2015-11-09 11:03:14,521 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-09 11:03:14,522 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.106/192.168.1.106:2181, initiating session
2015-11-09 11:03:14,525 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x50e6497fc90000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-09 11:03:14,743 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-09 11:03:14,743 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.102/192.168.1.102:2181, initiating session
2015-11-09 11:03:14,747 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x50e6497fc90000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-09 11:03:15,314 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x150e6497c4e0000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-09 11:03:15,749 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x50e6497fc90001, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-09 11:03:16,133 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-09 11:03:16,134 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.106/192.168.1.106:2181, initiating session
2015-11-09 11:03:16,137 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.106/192.168.1.106:2181, sessionid = 0x150e6497c4e0000, negotiated timeout = 90000
2015-11-09 11:03:16,407 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-09 11:03:16,407 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.102/192.168.1.102:2181, initiating session
2015-11-09 11:03:16,412 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.102/192.168.1.102:2181, sessionid = 0x50e6497fc90001, negotiated timeout = 90000
2015-11-09 11:03:16,791 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.101/192.168.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-09 11:03:16,792 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.101/192.168.1.101:2181, initiating session
2015-11-09 11:03:16,795 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.101/192.168.1.101:2181, sessionid = 0x50e6497fc90000, negotiated timeout = 90000
2015-11-09 11:03:16,929 INFO  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x250e6497c8a0000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-09 11:03:17,031 WARN  [master,16000,1446972588401_ChoreService_1] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/backup-masters
2015-11-09 11:03:17,756 INFO  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-09 11:03:17,757 INFO  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.102/192.168.1.102:2181, initiating session
2015-11-09 11:03:17,762 INFO  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.102/192.168.1.102:2181, sessionid = 0x250e6497c8a0000, negotiated timeout = 90000
2015-11-09 13:19:22,084 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x50e6497fc90001, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-09 13:19:22,092 INFO  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x250e6497c8a0000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-09 13:19:22,193 WARN  [master,16000,1446972588401_ChoreService_1] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/backup-masters
2015-11-09 13:19:22,736 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.101/192.168.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-09 13:19:22,736 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.101/192.168.1.101:2181, initiating session
2015-11-09 13:19:22,737 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x250e6497c8a0000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-09 13:19:22,803 WARN  [master/master/192.168.1.101:16000-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session 0x150e6497c4e0000 for server 192.168.1.106/192.168.1.106:2181, unexpected error, closing socket connection and attempting reconnect
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:68)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:366)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2015-11-09 13:19:22,807 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-09 13:19:22,807 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.106/192.168.1.106:2181, initiating session
2015-11-09 13:19:22,810 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x50e6497fc90001, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-09 13:19:23,072 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.101/192.168.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-09 13:19:23,072 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.101/192.168.1.101:2181, initiating session
2015-11-09 13:19:23,074 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x150e6497c4e0000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-09 13:19:23,121 WARN  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Session 0x50e6497fc90000 for server 192.168.1.101/192.168.1.101:2181, unexpected error, closing socket connection and attempting reconnect
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:68)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:366)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2015-11-09 13:19:23,620 INFO  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-09 13:19:23,621 INFO  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.106/192.168.1.106:2181, initiating session
2015-11-09 13:19:23,622 INFO  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x250e6497c8a0000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-09 13:19:23,653 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.101/192.168.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-09 13:19:23,653 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.101/192.168.1.101:2181, initiating session
2015-11-09 13:19:23,655 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.101/192.168.1.101:2181, sessionid = 0x50e6497fc90001, negotiated timeout = 90000
2015-11-09 13:19:23,722 WARN  [master,16000,1446972588401_ChoreService_1] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/backup-masters
2015-11-09 13:19:23,770 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-09 13:19:23,771 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.106/192.168.1.106:2181, initiating session
2015-11-09 13:19:23,772 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x50e6497fc90000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-09 13:19:23,836 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-09 13:19:23,836 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.102/192.168.1.102:2181, initiating session
2015-11-09 13:19:23,839 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.102/192.168.1.102:2181, sessionid = 0x150e6497c4e0000, negotiated timeout = 90000
2015-11-09 13:19:24,681 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-09 13:19:24,681 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.102/192.168.1.102:2181, initiating session
2015-11-09 13:19:24,684 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.102/192.168.1.102:2181, sessionid = 0x50e6497fc90000, negotiated timeout = 90000
2015-11-09 13:19:25,058 INFO  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-09 13:19:25,059 INFO  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.102/192.168.1.102:2181, initiating session
2015-11-09 13:19:25,061 INFO  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.102/192.168.1.102:2181, sessionid = 0x250e6497c8a0000, negotiated timeout = 90000
2015-11-09 15:42:22,721 INFO  [B.defaultRpcServer.handler=5,queue=2,port=16000] master.HMaster: Client=hadoop/null create 'eleme', {NAME => 'restaurants', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'FALSE', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}
2015-11-09 15:42:23,045 WARN  [B.defaultRpcServer.handler=5,queue=2,port=16000] wal.WALProcedureStore: failed to create log file with id=9
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): failed to create file /hbase/MasterProcWALs/state-00000000000000000009.log for DFSClient_NONMAPREDUCE_916772947_1 for client 192.168.1.101 because current leaseholder is trying to recreate file.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2988)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2737)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2632)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2519)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:566)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:394)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1411)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.create(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.create(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:264)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.create(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.create(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:1612)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1488)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1413)
	at org.apache.hadoop.hdfs.DistributedFileSystem$6.doCall(DistributedFileSystem.java:387)
	at org.apache.hadoop.hdfs.DistributedFileSystem$6.doCall(DistributedFileSystem.java:383)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:383)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:327)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:906)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:887)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:784)
	at org.apache.hadoop.hbase.procedure2.store.wal.WALProcedureStore.rollWriter(WALProcedureStore.java:706)
	at org.apache.hadoop.hbase.procedure2.store.wal.WALProcedureStore.rollWriter(WALProcedureStore.java:676)
	at org.apache.hadoop.hbase.procedure2.store.wal.WALProcedureStore.checkAndTryRoll(WALProcedureStore.java:655)
	at org.apache.hadoop.hbase.procedure2.store.wal.WALProcedureStore.insert(WALProcedureStore.java:355)
	at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.submitProcedure(ProcedureExecutor.java:524)
	at org.apache.hadoop.hbase.master.HMaster.createTable(HMaster.java:1459)
	at org.apache.hadoop.hbase.master.MasterRpcServices.createTable(MasterRpcServices.java:422)
	at org.apache.hadoop.hbase.protobuf.generated.MasterProtos$MasterService$2.callBlockingMethod(MasterProtos.java:48502)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2114)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:101)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:130)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:107)
	at java.lang.Thread.run(Thread.java:745)
2015-11-09 15:42:23,048 WARN  [B.defaultRpcServer.handler=5,queue=2,port=16000] wal.WALProcedureStore: someone else has already created log 8
2015-11-09 15:42:23,526 INFO  [RegionOpenAndInitThread-eleme-1] regionserver.HRegion: creating HRegion eleme HTD == 'eleme', {NAME => 'restaurants', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'FALSE', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://192.168.1.101:9000/hbase/.tmp Table name == eleme
2015-11-09 15:42:23,594 INFO  [RegionOpenAndInitThread-eleme-1] regionserver.HRegion: Closed eleme,,1447054942696.b667c97e743c4f599c51db112300bbd5.
2015-11-09 15:42:23,818 INFO  [ProcedureExecutorThread-1] hbase.MetaTableAccessor: Added 1
2015-11-09 15:42:23,976 INFO  [ProcedureExecutorThread-1] zookeeper.ZKTableStateManager: Moving table eleme state from null to ENABLING
2015-11-09 15:42:24,033 INFO  [ProcedureExecutorThread-1] master.AssignmentManager: Bulk assigning 1 region(s) across 3 server(s), round-robin=true
2015-11-09 15:42:24,033 INFO  [master,16000,1446972588401-GeneralBulkAssigner-0] master.AssignmentManager: Assigning 1 region(s) to master,16020,1446972589711
2015-11-09 15:42:24,054 INFO  [master,16000,1446972588401-GeneralBulkAssigner-0] master.RegionStates: Transition {b667c97e743c4f599c51db112300bbd5 state=OFFLINE, ts=1447054944033, server=null} to {b667c97e743c4f599c51db112300bbd5 state=PENDING_OPEN, ts=1447054944054, server=master,16020,1446972589711}
2015-11-09 15:42:24,168 INFO  [AM.ZK.Worker-pool2-t17] master.RegionStates: Transition {b667c97e743c4f599c51db112300bbd5 state=PENDING_OPEN, ts=1447054944054, server=master,16020,1446972589711} to {b667c97e743c4f599c51db112300bbd5 state=OPENING, ts=1447054944168, server=master,16020,1446972589711}
2015-11-09 15:42:24,472 INFO  [AM.ZK.Worker-pool2-t18] master.RegionStates: Transition {b667c97e743c4f599c51db112300bbd5 state=OPENING, ts=1447054944168, server=master,16020,1446972589711} to {b667c97e743c4f599c51db112300bbd5 state=OPEN, ts=1447054944472, server=master,16020,1446972589711}
2015-11-09 15:42:24,489 INFO  [ProcedureExecutorThread-1] master.AssignmentManager: Bulk assigning done
2015-11-09 15:42:24,489 INFO  [ProcedureExecutorThread-1] zookeeper.ZKTableStateManager: Moving table eleme state from ENABLING to ENABLED
2015-11-10 21:18:16,242 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 30 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-10 21:18:17,244 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 31 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-10 21:18:18,246 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 32 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-10 21:18:19,248 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 33 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-10 21:18:20,250 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 34 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-10 21:18:22,072 WARN  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Session 0x50e6497fc90001 for server 192.168.1.101/192.168.1.101:2181, unexpected error, closing socket connection and attempting reconnect
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:68)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:366)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2015-11-10 21:18:22,274 WARN  [master/master/192.168.1.101:16000-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Session 0x150e6497c4e0000 for server 192.168.1.102/192.168.1.102:2181, unexpected error, closing socket connection and attempting reconnect
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:68)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:366)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2015-11-10 21:18:22,298 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x50e6497fc90000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-10 21:18:22,425 INFO  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x250e6497c8a0000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-10 21:18:22,440 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.101/192.168.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-10 21:18:22,441 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.101/192.168.1.101:2181, initiating session
2015-11-10 21:18:22,442 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x50e6497fc90000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-10 21:18:22,479 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-10 21:18:22,479 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.102/192.168.1.102:2181, initiating session
2015-11-10 21:18:22,483 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.102/192.168.1.102:2181, sessionid = 0x50e6497fc90001, negotiated timeout = 90000
2015-11-10 21:18:22,525 WARN  [master,16000,1446972588401_ChoreService_1] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/backup-masters
2015-11-10 21:18:22,691 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-10 21:18:22,692 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.106/192.168.1.106:2181, initiating session
2015-11-10 21:18:22,695 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.106/192.168.1.106:2181, sessionid = 0x150e6497c4e0000, negotiated timeout = 90000
2015-11-10 21:18:22,897 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.101/192.168.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-10 21:18:22,898 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.101/192.168.1.101:2181, initiating session
2015-11-10 21:18:22,898 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x250e6497c8a0000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-10 21:18:23,262 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-10 21:18:23,263 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.106/192.168.1.106:2181, initiating session
2015-11-10 21:18:23,265 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.106/192.168.1.106:2181, sessionid = 0x50e6497fc90000, negotiated timeout = 90000
2015-11-10 21:18:23,696 INFO  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-10 21:18:23,696 INFO  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.106/192.168.1.106:2181, initiating session
2015-11-10 21:18:23,699 INFO  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.106/192.168.1.106:2181, sessionid = 0x250e6497c8a0000, negotiated timeout = 90000
2015-11-10 21:19:51,266 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 30 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-10 21:19:51,356 WARN  [snapshot-log-cleaner-cache-refresher] snapshot.SnapshotFileCache: Failed to refresh snapshot hfile cache!
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.getFileInfo(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:707)
	at sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.getFileInfo(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1785)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1068)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1064)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1064)
	at org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache.refreshCache(SnapshotFileCache.java:210)
	at org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache.access$000(SnapshotFileCache.java:76)
	at org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache$RefreshCacheTask.run(SnapshotFileCache.java:316)
	at java.util.TimerThread.mainLoop(Timer.java:555)
	at java.util.TimerThread.run(Timer.java:505)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 30 more
2015-11-10 21:19:51,358 WARN  [master,16000,1446972588401_ChoreService_1] cleaner.CleanerChore: Error while cleaning the logs
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.getListing(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.getListing(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getListing(ClientNamenodeProtocolTranslatorPB.java:523)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.getListing(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.getListing(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:1766)
	at org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:1749)
	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatusInternal(DistributedFileSystem.java:643)
	at org.apache.hadoop.hdfs.DistributedFileSystem.access$600(DistributedFileSystem.java:101)
	at org.apache.hadoop.hdfs.DistributedFileSystem$14.doCall(DistributedFileSystem.java:705)
	at org.apache.hadoop.hdfs.DistributedFileSystem$14.doCall(DistributedFileSystem.java:701)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatus(DistributedFileSystem.java:701)
	at org.apache.hadoop.hbase.util.FSUtils.listStatus(FSUtils.java:1721)
	at org.apache.hadoop.hbase.util.FSUtils.listStatus(FSUtils.java:1741)
	at org.apache.hadoop.hbase.master.cleaner.CleanerChore.chore(CleanerChore.java:123)
	at org.apache.hadoop.hbase.ScheduledChore.run(ScheduledChore.java:185)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 39 more
2015-11-10 21:19:51,365 WARN  [snapshot-hfile-cleaner-cache-refresher] snapshot.SnapshotFileCache: Failed to refresh snapshot hfile cache!
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.getFileInfo(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:707)
	at sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.getFileInfo(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1785)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1068)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1064)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1064)
	at org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache.refreshCache(SnapshotFileCache.java:210)
	at org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache.access$000(SnapshotFileCache.java:76)
	at org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache$RefreshCacheTask.run(SnapshotFileCache.java:316)
	at java.util.TimerThread.mainLoop(Timer.java:555)
	at java.util.TimerThread.run(Timer.java:505)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 30 more
2015-11-10 21:19:51,373 WARN  [master,16000,1446972588401_ChoreService_1] cleaner.CleanerChore: Error while cleaning the logs
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.getListing(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.getListing(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getListing(ClientNamenodeProtocolTranslatorPB.java:523)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.getListing(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.getListing(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:1766)
	at org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:1749)
	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatusInternal(DistributedFileSystem.java:643)
	at org.apache.hadoop.hdfs.DistributedFileSystem.access$600(DistributedFileSystem.java:101)
	at org.apache.hadoop.hdfs.DistributedFileSystem$14.doCall(DistributedFileSystem.java:705)
	at org.apache.hadoop.hdfs.DistributedFileSystem$14.doCall(DistributedFileSystem.java:701)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatus(DistributedFileSystem.java:701)
	at org.apache.hadoop.hbase.util.FSUtils.listStatus(FSUtils.java:1721)
	at org.apache.hadoop.hbase.util.FSUtils.listStatus(FSUtils.java:1741)
	at org.apache.hadoop.hbase.master.cleaner.CleanerChore.chore(CleanerChore.java:123)
	at org.apache.hadoop.hbase.ScheduledChore.run(ScheduledChore.java:185)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 39 more
2015-11-10 21:19:52,268 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 31 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-10 21:19:53,270 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 32 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-10 21:19:54,272 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 33 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-10 21:19:55,274 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 34 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-10 21:19:56,277 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 35 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-10 21:19:57,279 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 36 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-10 21:19:58,163 WARN  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session 0x250e6497c8a0000 for server 192.168.1.106/192.168.1.106:2181, unexpected error, closing socket connection and attempting reconnect
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:68)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:366)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2015-11-10 21:19:58,263 WARN  [master,16000,1446972588401_ChoreService_1] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/backup-masters
2015-11-10 21:19:58,508 INFO  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-10 21:19:58,509 INFO  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.102/192.168.1.102:2181, initiating session
2015-11-10 21:19:58,511 INFO  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x250e6497c8a0000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-10 21:19:58,766 WARN  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Session 0x50e6497fc90001 for server 192.168.1.102/192.168.1.102:2181, unexpected error, closing socket connection and attempting reconnect
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:68)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:366)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2015-11-10 21:19:58,871 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x150e6497c4e0000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-10 21:19:58,873 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x50e6497fc90000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-10 21:19:59,472 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.101/192.168.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-10 21:19:59,473 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.101/192.168.1.101:2181, initiating session
2015-11-10 21:19:59,473 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x250e6497c8a0000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-10 21:19:59,537 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.101/192.168.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-10 21:19:59,538 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.101/192.168.1.101:2181, initiating session
2015-11-10 21:19:59,540 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.101/192.168.1.101:2181, sessionid = 0x150e6497c4e0000, negotiated timeout = 90000
2015-11-10 21:19:59,573 WARN  [master,16000,1446972588401_ChoreService_1] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/backup-masters
2015-11-10 21:19:59,646 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-10 21:19:59,647 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.102/192.168.1.102:2181, initiating session
2015-11-10 21:19:59,650 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.102/192.168.1.102:2181, sessionid = 0x50e6497fc90000, negotiated timeout = 90000
2015-11-10 21:19:59,701 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-10 21:19:59,702 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.106/192.168.1.106:2181, initiating session
2015-11-10 21:19:59,704 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.106/192.168.1.106:2181, sessionid = 0x50e6497fc90001, negotiated timeout = 90000
2015-11-10 21:20:00,737 INFO  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-10 21:20:00,737 INFO  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.106/192.168.1.106:2181, initiating session
2015-11-10 21:20:00,740 INFO  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.106/192.168.1.106:2181, sessionid = 0x250e6497c8a0000, negotiated timeout = 90000
2015-11-11 10:42:51,357 WARN  [master,16000,1446972588401_ChoreService_1] cleaner.CleanerChore: Error while cleaning the logs
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.getListing(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.getListing(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getListing(ClientNamenodeProtocolTranslatorPB.java:523)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.getListing(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.getListing(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:1766)
	at org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:1749)
	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatusInternal(DistributedFileSystem.java:643)
	at org.apache.hadoop.hdfs.DistributedFileSystem.access$600(DistributedFileSystem.java:101)
	at org.apache.hadoop.hdfs.DistributedFileSystem$14.doCall(DistributedFileSystem.java:705)
	at org.apache.hadoop.hdfs.DistributedFileSystem$14.doCall(DistributedFileSystem.java:701)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatus(DistributedFileSystem.java:701)
	at org.apache.hadoop.hbase.util.FSUtils.listStatus(FSUtils.java:1721)
	at org.apache.hadoop.hbase.util.FSUtils.listStatus(FSUtils.java:1741)
	at org.apache.hadoop.hbase.master.cleaner.CleanerChore.chore(CleanerChore.java:123)
	at org.apache.hadoop.hbase.ScheduledChore.run(ScheduledChore.java:185)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 39 more
2015-11-11 10:42:51,374 WARN  [master,16000,1446972588401_ChoreService_1] cleaner.CleanerChore: Error while cleaning the logs
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.getListing(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.getListing(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getListing(ClientNamenodeProtocolTranslatorPB.java:523)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.getListing(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.getListing(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:1766)
	at org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:1749)
	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatusInternal(DistributedFileSystem.java:643)
	at org.apache.hadoop.hdfs.DistributedFileSystem.access$600(DistributedFileSystem.java:101)
	at org.apache.hadoop.hdfs.DistributedFileSystem$14.doCall(DistributedFileSystem.java:705)
	at org.apache.hadoop.hdfs.DistributedFileSystem$14.doCall(DistributedFileSystem.java:701)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatus(DistributedFileSystem.java:701)
	at org.apache.hadoop.hbase.util.FSUtils.listStatus(FSUtils.java:1721)
	at org.apache.hadoop.hbase.util.FSUtils.listStatus(FSUtils.java:1741)
	at org.apache.hadoop.hbase.master.cleaner.CleanerChore.chore(CleanerChore.java:123)
	at org.apache.hadoop.hbase.ScheduledChore.run(ScheduledChore.java:185)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 39 more
2015-11-11 10:43:05,616 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 30 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-11 10:43:06,618 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 31 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-11 10:43:07,253 WARN  [master/master/192.168.1.101:16000-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Session 0x150e6497c4e0000 for server 192.168.1.101/192.168.1.101:2181, unexpected error, closing socket connection and attempting reconnect
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:68)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:366)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2015-11-11 10:43:08,119 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-11 10:43:08,119 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.102/192.168.1.102:2181, initiating session
2015-11-11 10:43:08,123 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.102/192.168.1.102:2181, sessionid = 0x150e6497c4e0000, negotiated timeout = 90000
2015-11-11 10:43:08,291 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x50e6497fc90001, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-11 10:43:08,340 WARN  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Session 0x50e6497fc90000 for server 192.168.1.102/192.168.1.102:2181, unexpected error, closing socket connection and attempting reconnect
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:68)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:366)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2015-11-11 10:43:08,431 INFO  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x250e6497c8a0000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-11 10:43:08,531 WARN  [master,16000,1446972588401_ChoreService_1] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/backup-masters
2015-11-11 10:43:08,770 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.101/192.168.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-11 10:43:08,770 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.101/192.168.1.101:2181, initiating session
2015-11-11 10:43:08,771 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x50e6497fc90001, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-11 10:43:08,858 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.101/192.168.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-11 10:43:08,858 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.101/192.168.1.101:2181, initiating session
2015-11-11 10:43:08,859 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x50e6497fc90000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-11 10:43:09,150 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-11 10:43:09,151 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.102/192.168.1.102:2181, initiating session
2015-11-11 10:43:09,155 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.102/192.168.1.102:2181, sessionid = 0x50e6497fc90001, negotiated timeout = 90000
2015-11-11 10:43:09,501 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-11 10:43:09,502 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.106/192.168.1.106:2181, initiating session
2015-11-11 10:43:09,504 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.106/192.168.1.106:2181, sessionid = 0x50e6497fc90000, negotiated timeout = 90000
2015-11-11 10:43:09,529 INFO  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-11 10:43:09,529 INFO  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.102/192.168.1.102:2181, initiating session
2015-11-11 10:43:09,533 INFO  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.102/192.168.1.102:2181, sessionid = 0x250e6497c8a0000, negotiated timeout = 90000
2015-11-11 19:16:12,717 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 30 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-11 19:16:13,718 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 31 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-11 19:16:14,897 WARN  [master/master/192.168.1.101:16000-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Session 0x150e6497c4e0000 for server 192.168.1.102/192.168.1.102:2181, unexpected error, closing socket connection and attempting reconnect
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:68)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:366)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2015-11-11 19:16:15,016 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x50e6497fc90000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-11 19:16:15,164 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-11 19:16:15,165 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.102/192.168.1.102:2181, initiating session
2015-11-11 19:16:15,170 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.102/192.168.1.102:2181, sessionid = 0x50e6497fc90000, negotiated timeout = 90000
2015-11-11 19:16:15,417 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-11 19:16:15,417 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.106/192.168.1.106:2181, initiating session
2015-11-11 19:16:15,419 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.106/192.168.1.106:2181, sessionid = 0x150e6497c4e0000, negotiated timeout = 90000
2015-11-11 19:16:21,818 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Client session timed out, have not heard from server in 60026ms for sessionid 0x50e6497fc90001, closing socket connection and attempting reconnect
2015-11-11 19:16:22,899 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-11 19:16:27,585 INFO  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Client session timed out, have not heard from server in 60000ms for sessionid 0x250e6497c8a0000, closing socket connection and attempting reconnect
2015-11-11 19:16:27,686 WARN  [master,16000,1446972588401_ChoreService_1] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/backup-masters
2015-11-11 19:16:28,500 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.101/192.168.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-11 19:16:28,500 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.101/192.168.1.101:2181, initiating session
2015-11-11 19:16:28,503 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x250e6497c8a0000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-11 19:16:28,833 INFO  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-11 19:16:28,834 INFO  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.106/192.168.1.106:2181, initiating session
2015-11-11 19:16:28,836 INFO  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.106/192.168.1.106:2181, sessionid = 0x250e6497c8a0000, negotiated timeout = 90000
2015-11-11 19:16:29,898 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.106/192.168.1.106:2181, initiating session
2015-11-11 19:16:29,901 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.106/192.168.1.106:2181, sessionid = 0x50e6497fc90001, negotiated timeout = 90000
2015-11-12 10:47:51,357 WARN  [master,16000,1446972588401_ChoreService_1] cleaner.CleanerChore: Error while cleaning the logs
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.getListing(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.getListing(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getListing(ClientNamenodeProtocolTranslatorPB.java:523)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.getListing(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.getListing(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:1766)
	at org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:1749)
	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatusInternal(DistributedFileSystem.java:643)
	at org.apache.hadoop.hdfs.DistributedFileSystem.access$600(DistributedFileSystem.java:101)
	at org.apache.hadoop.hdfs.DistributedFileSystem$14.doCall(DistributedFileSystem.java:705)
	at org.apache.hadoop.hdfs.DistributedFileSystem$14.doCall(DistributedFileSystem.java:701)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatus(DistributedFileSystem.java:701)
	at org.apache.hadoop.hbase.util.FSUtils.listStatus(FSUtils.java:1721)
	at org.apache.hadoop.hbase.util.FSUtils.listStatus(FSUtils.java:1741)
	at org.apache.hadoop.hbase.master.cleaner.CleanerChore.chore(CleanerChore.java:123)
	at org.apache.hadoop.hbase.ScheduledChore.run(ScheduledChore.java:185)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 39 more
2015-11-12 10:47:51,373 WARN  [master,16000,1446972588401_ChoreService_1] cleaner.CleanerChore: Error while cleaning the logs
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.getListing(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.getListing(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getListing(ClientNamenodeProtocolTranslatorPB.java:523)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.getListing(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.getListing(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:1766)
	at org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:1749)
	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatusInternal(DistributedFileSystem.java:643)
	at org.apache.hadoop.hdfs.DistributedFileSystem.access$600(DistributedFileSystem.java:101)
	at org.apache.hadoop.hdfs.DistributedFileSystem$14.doCall(DistributedFileSystem.java:705)
	at org.apache.hadoop.hdfs.DistributedFileSystem$14.doCall(DistributedFileSystem.java:701)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatus(DistributedFileSystem.java:701)
	at org.apache.hadoop.hbase.util.FSUtils.listStatus(FSUtils.java:1721)
	at org.apache.hadoop.hbase.util.FSUtils.listStatus(FSUtils.java:1741)
	at org.apache.hadoop.hbase.master.cleaner.CleanerChore.chore(CleanerChore.java:123)
	at org.apache.hadoop.hbase.ScheduledChore.run(ScheduledChore.java:185)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 39 more
2015-11-12 10:47:51,989 WARN  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session 0x50e6497fc90001 for server 192.168.1.106/192.168.1.106:2181, unexpected error, closing socket connection and attempting reconnect
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:68)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:366)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2015-11-12 10:47:52,741 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.101/192.168.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-12 10:47:52,742 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.101/192.168.1.101:2181, initiating session
2015-11-12 10:47:52,742 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x50e6497fc90001, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-12 10:47:53,118 WARN  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session 0x250e6497c8a0000 for server 192.168.1.106/192.168.1.106:2181, unexpected error, closing socket connection and attempting reconnect
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:68)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:366)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2015-11-12 10:47:53,270 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x50e6497fc90000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-12 10:47:53,376 INFO  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-12 10:47:53,376 INFO  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.102/192.168.1.102:2181, initiating session
2015-11-12 10:47:53,377 INFO  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x250e6497c8a0000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-12 10:47:53,770 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-12 10:47:53,770 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.102/192.168.1.102:2181, initiating session
2015-11-12 10:47:53,772 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x50e6497fc90001, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-12 10:47:54,215 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.101/192.168.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-12 10:47:54,215 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.101/192.168.1.101:2181, initiating session
2015-11-12 10:47:54,216 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x50e6497fc90000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-12 10:47:54,464 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.101/192.168.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-12 10:47:54,464 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.101/192.168.1.101:2181, initiating session
2015-11-12 10:47:54,465 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x250e6497c8a0000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-12 10:47:54,765 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x150e6497c4e0000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-12 10:47:55,310 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-12 10:47:55,311 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.106/192.168.1.106:2181, initiating session
2015-11-12 10:47:55,313 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.106/192.168.1.106:2181, sessionid = 0x50e6497fc90000, negotiated timeout = 90000
2015-11-12 10:47:55,454 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-12 10:47:55,454 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.106/192.168.1.106:2181, initiating session
2015-11-12 10:47:55,457 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.106/192.168.1.106:2181, sessionid = 0x50e6497fc90001, negotiated timeout = 90000
2015-11-12 10:47:55,631 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.101/192.168.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-12 10:47:55,632 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.101/192.168.1.101:2181, initiating session
2015-11-12 10:47:55,633 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.101/192.168.1.101:2181, sessionid = 0x150e6497c4e0000, negotiated timeout = 90000
2015-11-12 10:47:55,653 INFO  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-12 10:47:55,653 INFO  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.106/192.168.1.106:2181, initiating session
2015-11-12 10:47:55,655 INFO  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.106/192.168.1.106:2181, sessionid = 0x250e6497c8a0000, negotiated timeout = 90000
2015-11-15 15:50:36,211 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 30 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-15 15:50:37,213 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 31 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-15 15:50:38,933 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x150e6497c4e0000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-15 15:50:39,464 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-15 15:50:39,464 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.102/192.168.1.102:2181, initiating session
2015-11-15 15:50:39,466 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x150e6497c4e0000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-15 15:50:40,179 WARN  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session 0x50e6497fc90000 for server 192.168.1.106/192.168.1.106:2181, unexpected error, closing socket connection and attempting reconnect
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:68)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:366)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2015-11-15 15:50:40,247 WARN  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session 0x250e6497c8a0000 for server 192.168.1.106/192.168.1.106:2181, unexpected error, closing socket connection and attempting reconnect
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:68)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:366)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2015-11-15 15:50:40,362 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-15 15:50:40,363 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.106/192.168.1.106:2181, initiating session
2015-11-15 15:50:40,365 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.106/192.168.1.106:2181, sessionid = 0x150e6497c4e0000, negotiated timeout = 90000
2015-11-15 15:50:40,618 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-15 15:50:40,619 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.102/192.168.1.102:2181, initiating session
2015-11-15 15:50:40,628 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.102/192.168.1.102:2181, sessionid = 0x50e6497fc90000, negotiated timeout = 90000
2015-11-15 15:50:40,781 INFO  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-15 15:50:40,782 INFO  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.102/192.168.1.102:2181, initiating session
2015-11-15 15:50:40,783 INFO  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x250e6497c8a0000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-15 15:50:40,986 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.101/192.168.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-15 15:50:40,986 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.101/192.168.1.101:2181, initiating session
2015-11-15 15:50:40,987 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x250e6497c8a0000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-15 15:50:42,317 INFO  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-15 15:50:42,317 INFO  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.106/192.168.1.106:2181, initiating session
2015-11-15 15:50:42,320 INFO  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.106/192.168.1.106:2181, sessionid = 0x250e6497c8a0000, negotiated timeout = 90000
2015-11-15 15:50:42,378 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x50e6497fc90001, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-15 15:50:43,426 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.101/192.168.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-15 15:50:43,427 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.101/192.168.1.101:2181, initiating session
2015-11-15 15:50:43,428 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x50e6497fc90001, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-15 15:50:43,593 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-15 15:50:43,594 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.102/192.168.1.102:2181, initiating session
2015-11-15 15:50:43,595 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x50e6497fc90001, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-15 15:50:45,417 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-15 15:50:45,417 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.106/192.168.1.106:2181, initiating session
2015-11-15 15:50:45,421 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.106/192.168.1.106:2181, sessionid = 0x50e6497fc90001, negotiated timeout = 90000
2015-11-16 19:24:17,217 INFO  [B.defaultRpcServer.handler=10,queue=1,port=16000] master.HMaster: Client=hadoop/null disable eleme
2015-11-16 19:24:19,308 INFO  [ProcedureExecutorThread-0] zookeeper.ZKTableStateManager: Moving table eleme state from DISABLING to DISABLING
2015-11-16 19:24:19,476 INFO  [ProcedureExecutorThread-0] procedure.DisableTableProcedure: Offlining 1 regions.
2015-11-16 19:24:19,494 INFO  [master,16000,1446972588401-org.apache.hadoop.hbase.master.procedure.DisableTableProcedure$BulkDisabler-0] master.RegionStates: Transition {b667c97e743c4f599c51db112300bbd5 state=OPEN, ts=1447054944489, server=master,16020,1446972589711} to {b667c97e743c4f599c51db112300bbd5 state=PENDING_CLOSE, ts=1447673059494, server=master,16020,1446972589711}
2015-11-16 19:24:19,602 INFO  [AM.ZK.Worker-pool2-t22] master.RegionStates: Transition {b667c97e743c4f599c51db112300bbd5 state=PENDING_CLOSE, ts=1447673059494, server=master,16020,1446972589711} to {b667c97e743c4f599c51db112300bbd5 state=OFFLINE, ts=1447673059602, server=master,16020,1446972589711}
2015-11-16 19:24:19,602 INFO  [AM.ZK.Worker-pool2-t22] master.RegionStates: Offlined b667c97e743c4f599c51db112300bbd5 from master,16020,1446972589711
2015-11-16 19:24:20,632 INFO  [ProcedureExecutorThread-0] zookeeper.ZKTableStateManager: Moving table eleme state from DISABLING to DISABLED
2015-11-16 19:24:20,651 INFO  [ProcedureExecutorThread-0] procedure.DisableTableProcedure: Disabled table, eleme, is completed.
2015-11-16 19:24:28,257 INFO  [B.defaultRpcServer.handler=12,queue=0,port=16000] master.HMaster: Client=hadoop/null delete eleme
2015-11-16 19:24:28,634 INFO  [ProcedureExecutorThread-2] hbase.MetaTableAccessor: Deleted [{ENCODED => b667c97e743c4f599c51db112300bbd5, NAME => 'eleme,,1447054942696.b667c97e743c4f599c51db112300bbd5.', STARTKEY => '', ENDKEY => ''}]
2015-11-16 20:22:01,111 INFO  [B.defaultRpcServer.handler=20,queue=2,port=16000] master.HMaster: Client=hadoop/null create 'eleme', {NAME => 'info', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'FALSE', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}
2015-11-16 20:22:01,638 INFO  [RegionOpenAndInitThread-eleme-1] regionserver.HRegion: creating HRegion eleme HTD == 'eleme', {NAME => 'info', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'FALSE', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://192.168.1.101:9000/hbase/.tmp Table name == eleme
2015-11-16 20:22:01,687 INFO  [RegionOpenAndInitThread-eleme-1] regionserver.HRegion: Closed eleme,,1447676521110.4d45f34a15b9c4c1292a465e7ee33cd9.
2015-11-16 20:22:01,860 INFO  [ProcedureExecutorThread-3] hbase.MetaTableAccessor: Added 1
2015-11-16 20:22:01,995 INFO  [ProcedureExecutorThread-3] zookeeper.ZKTableStateManager: Moving table eleme state from null to ENABLING
2015-11-16 20:22:02,032 INFO  [ProcedureExecutorThread-3] master.AssignmentManager: Bulk assigning 1 region(s) across 3 server(s), round-robin=true
2015-11-16 20:22:02,033 INFO  [master,16000,1446972588401-GeneralBulkAssigner-1] master.AssignmentManager: Assigning 1 region(s) to slave1,16020,1446972590261
2015-11-16 20:22:02,044 INFO  [master,16000,1446972588401-GeneralBulkAssigner-1] master.RegionStates: Transition {4d45f34a15b9c4c1292a465e7ee33cd9 state=OFFLINE, ts=1447676522033, server=null} to {4d45f34a15b9c4c1292a465e7ee33cd9 state=PENDING_OPEN, ts=1447676522044, server=slave1,16020,1446972590261}
2015-11-16 20:22:02,092 INFO  [AM.ZK.Worker-pool2-t26] master.RegionStates: Transition {4d45f34a15b9c4c1292a465e7ee33cd9 state=PENDING_OPEN, ts=1447676522044, server=slave1,16020,1446972590261} to {4d45f34a15b9c4c1292a465e7ee33cd9 state=OPENING, ts=1447676522092, server=slave1,16020,1446972590261}
2015-11-16 20:22:02,210 INFO  [AM.ZK.Worker-pool2-t27] master.RegionStates: Transition {4d45f34a15b9c4c1292a465e7ee33cd9 state=OPENING, ts=1447676522092, server=slave1,16020,1446972590261} to {4d45f34a15b9c4c1292a465e7ee33cd9 state=OPEN, ts=1447676522210, server=slave1,16020,1446972590261}
2015-11-16 20:22:02,218 INFO  [ProcedureExecutorThread-3] master.AssignmentManager: Bulk assigning done
2015-11-16 20:22:02,218 INFO  [ProcedureExecutorThread-3] zookeeper.ZKTableStateManager: Moving table eleme state from ENABLING to ENABLED
2015-11-17 02:51:29,258 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 30 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-17 02:51:30,260 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 31 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-17 02:51:31,262 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 32 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-17 02:51:32,266 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 33 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-17 02:51:33,267 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 34 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-17 02:51:34,270 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 35 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-17 02:51:35,271 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 36 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-17 02:51:36,273 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 37 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-17 02:51:37,275 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 38 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-17 02:51:38,277 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 39 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-17 02:51:39,279 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 40 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-17 02:51:40,281 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 41 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-17 02:51:41,283 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 42 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-17 02:51:42,284 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 43 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-17 02:51:43,287 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 44 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-17 02:51:44,289 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 45 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-17 02:51:45,291 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 46 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-17 02:51:46,293 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 47 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-17 02:51:47,295 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 48 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-17 02:51:48,259 WARN  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Session 0x50e6497fc90000 for server 192.168.1.102/192.168.1.102:2181, unexpected error, closing socket connection and attempting reconnect
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:68)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:366)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2015-11-17 02:51:48,720 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.101/192.168.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-17 02:51:48,720 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.101/192.168.1.101:2181, initiating session
2015-11-17 02:51:48,721 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x50e6497fc90000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-17 02:51:49,058 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-17 02:51:49,059 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.106/192.168.1.106:2181, initiating session
2015-11-17 02:51:49,060 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x50e6497fc90000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-17 02:51:50,740 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-17 02:51:50,740 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.102/192.168.1.102:2181, initiating session
2015-11-17 02:51:50,744 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.102/192.168.1.102:2181, sessionid = 0x50e6497fc90000, negotiated timeout = 90000
2015-11-17 02:51:51,441 WARN  [master/master/192.168.1.101:16000-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session 0x150e6497c4e0000 for server 192.168.1.106/192.168.1.106:2181, unexpected error, closing socket connection and attempting reconnect
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:68)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:366)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2015-11-17 02:51:51,658 WARN  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session 0x50e6497fc90001 for server 192.168.1.106/192.168.1.106:2181, unexpected error, closing socket connection and attempting reconnect
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:68)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:366)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2015-11-17 02:51:52,015 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.101/192.168.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-17 02:51:52,015 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.101/192.168.1.101:2181, initiating session
2015-11-17 02:51:52,017 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.101/192.168.1.101:2181, sessionid = 0x50e6497fc90001, negotiated timeout = 90000
2015-11-17 02:51:52,137 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.101/192.168.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-17 02:51:52,137 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.101/192.168.1.101:2181, initiating session
2015-11-17 02:51:52,139 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.101/192.168.1.101:2181, sessionid = 0x150e6497c4e0000, negotiated timeout = 90000
2015-11-17 02:51:52,817 WARN  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session 0x250e6497c8a0000 for server 192.168.1.106/192.168.1.106:2181, unexpected error, closing socket connection and attempting reconnect
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:68)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:366)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2015-11-17 02:51:53,606 INFO  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-17 02:51:53,607 INFO  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.102/192.168.1.102:2181, initiating session
2015-11-17 02:51:53,611 INFO  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.102/192.168.1.102:2181, sessionid = 0x250e6497c8a0000, negotiated timeout = 90000
2015-11-17 05:26:20,137 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x50e6497fc90000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-17 05:26:20,138 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x150e6497c4e0000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-17 05:26:20,454 INFO  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x250e6497c8a0000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-17 05:26:20,554 WARN  [master,16000,1446972588401_ChoreService_1] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/backup-masters
2015-11-17 05:26:20,563 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.101/192.168.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-17 05:26:20,563 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.101/192.168.1.101:2181, initiating session
2015-11-17 05:26:20,564 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x50e6497fc90000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-17 05:26:20,578 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x50e6497fc90001, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-17 05:26:20,885 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-17 05:26:20,885 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.102/192.168.1.102:2181, initiating session
2015-11-17 05:26:20,889 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.102/192.168.1.102:2181, sessionid = 0x150e6497c4e0000, negotiated timeout = 90000
2015-11-17 05:26:21,229 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.101/192.168.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-17 05:26:21,229 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.101/192.168.1.101:2181, initiating session
2015-11-17 05:26:21,230 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x250e6497c8a0000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-17 05:26:21,257 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-17 05:26:21,257 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.106/192.168.1.106:2181, initiating session
2015-11-17 05:26:21,260 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.106/192.168.1.106:2181, sessionid = 0x50e6497fc90000, negotiated timeout = 90000
2015-11-17 05:26:21,372 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-17 05:26:21,372 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.102/192.168.1.102:2181, initiating session
2015-11-17 05:26:21,376 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.102/192.168.1.102:2181, sessionid = 0x50e6497fc90001, negotiated timeout = 90000
2015-11-17 05:26:22,225 INFO  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-17 05:26:22,226 INFO  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.106/192.168.1.106:2181, initiating session
2015-11-17 05:26:22,228 INFO  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.106/192.168.1.106:2181, sessionid = 0x250e6497c8a0000, negotiated timeout = 90000
2015-11-17 23:52:29,343 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 30 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-17 23:52:30,345 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 31 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-17 23:52:31,347 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 32 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-17 23:52:32,349 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 33 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-17 23:52:33,351 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 34 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-17 23:52:34,353 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 35 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-17 23:52:35,354 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 36 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-17 23:52:36,357 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 37 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-17 23:52:37,359 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 38 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-17 23:52:38,361 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 39 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-17 23:52:39,936 WARN  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session 0x250e6497c8a0000 for server 192.168.1.106/192.168.1.106:2181, unexpected error, closing socket connection and attempting reconnect
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:68)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:366)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2015-11-17 23:52:40,150 WARN  [master/master/192.168.1.101:16000-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Session 0x150e6497c4e0000 for server 192.168.1.102/192.168.1.102:2181, unexpected error, closing socket connection and attempting reconnect
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:68)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:366)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2015-11-17 23:52:40,154 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x50e6497fc90001, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-17 23:52:40,232 INFO  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-17 23:52:40,233 INFO  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.102/192.168.1.102:2181, initiating session
2015-11-17 23:52:40,234 INFO  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x250e6497c8a0000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-17 23:52:40,684 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-17 23:52:40,684 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.106/192.168.1.106:2181, initiating session
2015-11-17 23:52:40,687 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.106/192.168.1.106:2181, sessionid = 0x150e6497c4e0000, negotiated timeout = 90000
2015-11-17 23:52:41,193 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.101/192.168.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-17 23:52:41,193 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.101/192.168.1.101:2181, initiating session
2015-11-17 23:52:41,194 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x250e6497c8a0000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-17 23:52:41,247 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-17 23:52:41,247 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.106/192.168.1.106:2181, initiating session
2015-11-17 23:52:41,249 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.106/192.168.1.106:2181, sessionid = 0x50e6497fc90001, negotiated timeout = 90000
2015-11-17 23:52:41,429 WARN  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session 0x50e6497fc90000 for server 192.168.1.106/192.168.1.106:2181, unexpected error, closing socket connection and attempting reconnect
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:68)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:366)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2015-11-17 23:52:42,331 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-17 23:52:42,331 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.102/192.168.1.102:2181, initiating session
2015-11-17 23:52:42,335 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.102/192.168.1.102:2181, sessionid = 0x50e6497fc90000, negotiated timeout = 90000
2015-11-17 23:52:42,335 INFO  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-17 23:52:42,336 INFO  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.106/192.168.1.106:2181, initiating session
2015-11-17 23:52:42,338 INFO  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.106/192.168.1.106:2181, sessionid = 0x250e6497c8a0000, negotiated timeout = 90000
2015-11-18 01:44:51,056 WARN  [master,16000,1446972588401_ChoreService_1] cleaner.CleanerChore: Error while cleaning the logs
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.getListing(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.getListing(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getListing(ClientNamenodeProtocolTranslatorPB.java:523)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.getListing(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.getListing(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:1766)
	at org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:1749)
	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatusInternal(DistributedFileSystem.java:643)
	at org.apache.hadoop.hdfs.DistributedFileSystem.access$600(DistributedFileSystem.java:101)
	at org.apache.hadoop.hdfs.DistributedFileSystem$14.doCall(DistributedFileSystem.java:705)
	at org.apache.hadoop.hdfs.DistributedFileSystem$14.doCall(DistributedFileSystem.java:701)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatus(DistributedFileSystem.java:701)
	at org.apache.hadoop.hbase.util.FSUtils.listStatus(FSUtils.java:1721)
	at org.apache.hadoop.hbase.util.FSUtils.listStatus(FSUtils.java:1741)
	at org.apache.hadoop.hbase.master.cleaner.CleanerChore.chore(CleanerChore.java:123)
	at org.apache.hadoop.hbase.ScheduledChore.run(ScheduledChore.java:185)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 39 more
2015-11-18 01:44:51,065 WARN  [master,16000,1446972588401_ChoreService_1] cleaner.CleanerChore: Error while cleaning the logs
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.getListing(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.getListing(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getListing(ClientNamenodeProtocolTranslatorPB.java:523)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.getListing(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.getListing(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:1766)
	at org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:1749)
	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatusInternal(DistributedFileSystem.java:643)
	at org.apache.hadoop.hdfs.DistributedFileSystem.access$600(DistributedFileSystem.java:101)
	at org.apache.hadoop.hdfs.DistributedFileSystem$14.doCall(DistributedFileSystem.java:705)
	at org.apache.hadoop.hdfs.DistributedFileSystem$14.doCall(DistributedFileSystem.java:701)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatus(DistributedFileSystem.java:701)
	at org.apache.hadoop.hbase.util.FSUtils.listStatus(FSUtils.java:1721)
	at org.apache.hadoop.hbase.util.FSUtils.listStatus(FSUtils.java:1741)
	at org.apache.hadoop.hbase.master.cleaner.CleanerChore.chore(CleanerChore.java:123)
	at org.apache.hadoop.hbase.ScheduledChore.run(ScheduledChore.java:185)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 39 more
2015-11-18 01:44:51,356 WARN  [snapshot-log-cleaner-cache-refresher] snapshot.SnapshotFileCache: Failed to refresh snapshot hfile cache!
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.getFileInfo(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:707)
	at sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.getFileInfo(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1785)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1068)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1064)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1064)
	at org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache.refreshCache(SnapshotFileCache.java:210)
	at org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache.access$000(SnapshotFileCache.java:76)
	at org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache$RefreshCacheTask.run(SnapshotFileCache.java:316)
	at java.util.TimerThread.mainLoop(Timer.java:555)
	at java.util.TimerThread.run(Timer.java:505)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 30 more
2015-11-18 01:44:51,365 WARN  [snapshot-hfile-cleaner-cache-refresher] snapshot.SnapshotFileCache: Failed to refresh snapshot hfile cache!
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.getFileInfo(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:707)
	at sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.getFileInfo(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1785)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1068)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1064)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1064)
	at org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache.refreshCache(SnapshotFileCache.java:210)
	at org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache.access$000(SnapshotFileCache.java:76)
	at org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache$RefreshCacheTask.run(SnapshotFileCache.java:316)
	at java.util.TimerThread.mainLoop(Timer.java:555)
	at java.util.TimerThread.run(Timer.java:505)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 30 more
2015-11-18 01:45:09,914 WARN  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session 0x250e6497c8a0000 for server 192.168.1.106/192.168.1.106:2181, unexpected error, closing socket connection and attempting reconnect
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:68)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:366)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2015-11-18 01:45:10,014 WARN  [master,16000,1446972588401_ChoreService_1] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/backup-masters
2015-11-18 01:45:10,311 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x50e6497fc90000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-18 01:45:10,814 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.101/192.168.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-18 01:45:10,814 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.101/192.168.1.101:2181, initiating session
2015-11-18 01:45:10,815 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x50e6497fc90000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-18 01:45:11,001 INFO  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-18 01:45:11,001 INFO  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.102/192.168.1.102:2181, initiating session
2015-11-18 01:45:11,003 INFO  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x250e6497c8a0000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-18 01:45:11,103 WARN  [master,16000,1446972588401_ChoreService_1] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/backup-masters
2015-11-18 01:45:11,370 WARN  [master/master/192.168.1.101:16000-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session 0x150e6497c4e0000 for server 192.168.1.106/192.168.1.106:2181, unexpected error, closing socket connection and attempting reconnect
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:68)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:366)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2015-11-18 01:45:11,512 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.101/192.168.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-18 01:45:11,512 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.101/192.168.1.101:2181, initiating session
2015-11-18 01:45:11,520 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x150e6497c4e0000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-18 01:45:11,604 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-18 01:45:11,605 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.106/192.168.1.106:2181, initiating session
2015-11-18 01:45:11,607 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.106/192.168.1.106:2181, sessionid = 0x50e6497fc90000, negotiated timeout = 90000
2015-11-18 01:45:11,868 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.101/192.168.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-18 01:45:11,869 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.101/192.168.1.101:2181, initiating session
2015-11-18 01:45:11,869 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x250e6497c8a0000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-18 01:45:11,923 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x50e6497fc90001, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-18 01:45:12,349 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-18 01:45:12,349 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.102/192.168.1.102:2181, initiating session
2015-11-18 01:45:12,353 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.102/192.168.1.102:2181, sessionid = 0x150e6497c4e0000, negotiated timeout = 90000
2015-11-18 01:45:12,431 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.101/192.168.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-18 01:45:12,431 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.101/192.168.1.101:2181, initiating session
2015-11-18 01:45:12,432 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x50e6497fc90001, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-18 01:45:13,419 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-18 01:45:13,420 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.102/192.168.1.102:2181, initiating session
2015-11-18 01:45:13,421 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x50e6497fc90001, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-18 01:45:13,701 INFO  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-18 01:45:13,701 INFO  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.106/192.168.1.106:2181, initiating session
2015-11-18 01:45:13,704 INFO  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.106/192.168.1.106:2181, sessionid = 0x250e6497c8a0000, negotiated timeout = 90000
2015-11-18 01:45:14,751 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-18 01:45:14,751 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.106/192.168.1.106:2181, initiating session
2015-11-18 01:45:14,754 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.106/192.168.1.106:2181, sessionid = 0x50e6497fc90001, negotiated timeout = 90000
2015-11-18 16:29:49,473 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 30 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-18 16:29:50,475 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 31 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-18 16:29:51,048 WARN  [master,16000,1446972588401_ChoreService_1] cleaner.CleanerChore: Error while cleaning the logs
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.getListing(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.getListing(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getListing(ClientNamenodeProtocolTranslatorPB.java:523)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.getListing(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.getListing(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:1766)
	at org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:1749)
	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatusInternal(DistributedFileSystem.java:643)
	at org.apache.hadoop.hdfs.DistributedFileSystem.access$600(DistributedFileSystem.java:101)
	at org.apache.hadoop.hdfs.DistributedFileSystem$14.doCall(DistributedFileSystem.java:705)
	at org.apache.hadoop.hdfs.DistributedFileSystem$14.doCall(DistributedFileSystem.java:701)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatus(DistributedFileSystem.java:701)
	at org.apache.hadoop.hbase.util.FSUtils.listStatus(FSUtils.java:1721)
	at org.apache.hadoop.hbase.util.FSUtils.listStatus(FSUtils.java:1741)
	at org.apache.hadoop.hbase.master.cleaner.CleanerChore.chore(CleanerChore.java:123)
	at org.apache.hadoop.hbase.ScheduledChore.run(ScheduledChore.java:185)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 39 more
2015-11-18 16:29:51,064 WARN  [master,16000,1446972588401_ChoreService_1] cleaner.CleanerChore: Error while cleaning the logs
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.getListing(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.getListing(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getListing(ClientNamenodeProtocolTranslatorPB.java:523)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.getListing(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.getListing(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:1766)
	at org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:1749)
	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatusInternal(DistributedFileSystem.java:643)
	at org.apache.hadoop.hdfs.DistributedFileSystem.access$600(DistributedFileSystem.java:101)
	at org.apache.hadoop.hdfs.DistributedFileSystem$14.doCall(DistributedFileSystem.java:705)
	at org.apache.hadoop.hdfs.DistributedFileSystem$14.doCall(DistributedFileSystem.java:701)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatus(DistributedFileSystem.java:701)
	at org.apache.hadoop.hbase.util.FSUtils.listStatus(FSUtils.java:1721)
	at org.apache.hadoop.hbase.util.FSUtils.listStatus(FSUtils.java:1741)
	at org.apache.hadoop.hbase.master.cleaner.CleanerChore.chore(CleanerChore.java:123)
	at org.apache.hadoop.hbase.ScheduledChore.run(ScheduledChore.java:185)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 39 more
2015-11-18 16:29:51,355 WARN  [snapshot-log-cleaner-cache-refresher] snapshot.SnapshotFileCache: Failed to refresh snapshot hfile cache!
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.getFileInfo(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:707)
	at sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.getFileInfo(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1785)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1068)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1064)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1064)
	at org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache.refreshCache(SnapshotFileCache.java:210)
	at org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache.access$000(SnapshotFileCache.java:76)
	at org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache$RefreshCacheTask.run(SnapshotFileCache.java:316)
	at java.util.TimerThread.mainLoop(Timer.java:555)
	at java.util.TimerThread.run(Timer.java:505)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 30 more
2015-11-18 16:29:51,366 WARN  [snapshot-hfile-cleaner-cache-refresher] snapshot.SnapshotFileCache: Failed to refresh snapshot hfile cache!
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.getFileInfo(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:707)
	at sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.getFileInfo(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1785)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1068)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1064)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1064)
	at org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache.refreshCache(SnapshotFileCache.java:210)
	at org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache.access$000(SnapshotFileCache.java:76)
	at org.apache.hadoop.hbase.master.snapshot.SnapshotFileCache$RefreshCacheTask.run(SnapshotFileCache.java:316)
	at java.util.TimerThread.mainLoop(Timer.java:555)
	at java.util.TimerThread.run(Timer.java:505)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 30 more
2015-11-18 16:29:51,478 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 32 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-18 16:29:52,480 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 33 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-18 16:29:53,485 WARN  [LeaseRenewer:hadoop@192.168.1.101:9000] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_916772947_1] for 34 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "master/192.168.1.101"; destination host is: "master":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:540)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:814)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 26 more
2015-11-18 16:29:53,933 WARN  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session 0x50e6497fc90000 for server 192.168.1.106/192.168.1.106:2181, unexpected error, closing socket connection and attempting reconnect
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:68)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:366)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2015-11-18 16:29:54,082 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-18 16:29:54,083 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.102/192.168.1.102:2181, initiating session
2015-11-18 16:29:54,084 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x50e6497fc90000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-18 16:29:54,128 WARN  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session 0x50e6497fc90001 for server 192.168.1.106/192.168.1.106:2181, unexpected error, closing socket connection and attempting reconnect
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:68)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:366)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2015-11-18 16:29:54,455 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x150e6497c4e0000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-18 16:29:54,526 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.101/192.168.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-18 16:29:54,527 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.101/192.168.1.101:2181, initiating session
2015-11-18 16:29:54,527 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x50e6497fc90001, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-18 16:29:54,883 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-18 16:29:54,883 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.106/192.168.1.106:2181, initiating session
2015-11-18 16:29:54,884 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x150e6497c4e0000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-18 16:29:55,017 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.101/192.168.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-18 16:29:55,017 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.101/192.168.1.101:2181, initiating session
2015-11-18 16:29:55,018 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x50e6497fc90000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-18 16:29:55,088 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.101/192.168.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-18 16:29:55,088 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.101/192.168.1.101:2181, initiating session
2015-11-18 16:29:55,089 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x150e6497c4e0000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-18 16:29:55,611 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-18 16:29:55,611 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.102/192.168.1.102:2181, initiating session
2015-11-18 16:29:55,613 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x50e6497fc90001, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-18 16:29:56,012 INFO  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x250e6497c8a0000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-18 16:29:56,523 INFO  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-18 16:29:56,524 INFO  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.102/192.168.1.102:2181, initiating session
2015-11-18 16:29:56,525 INFO  [main-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x250e6497c8a0000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-18 16:29:56,749 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-18 16:29:56,749 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.106/192.168.1.106:2181, initiating session
2015-11-18 16:29:56,752 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.106/192.168.1.106:2181, sessionid = 0x50e6497fc90000, negotiated timeout = 90000
2015-11-18 16:29:57,036 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.102/192.168.1.102:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-18 16:29:57,039 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.102/192.168.1.102:2181, initiating session
2015-11-18 16:29:57,045 INFO  [master/master/192.168.1.101:16000-SendThread(192.168.1.102:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.102/192.168.1.102:2181, sessionid = 0x150e6497c4e0000, negotiated timeout = 90000
2015-11-18 16:29:57,267 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-18 16:29:57,279 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.106/192.168.1.106:2181, initiating session
2015-11-18 16:29:57,292 INFO  [master:16000.activeMasterManager-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.106/192.168.1.106:2181, sessionid = 0x50e6497fc90001, negotiated timeout = 90000
2015-11-18 16:29:57,302 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.101/192.168.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-18 16:29:57,302 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.101/192.168.1.101:2181, initiating session
2015-11-18 16:29:57,303 INFO  [main-SendThread(192.168.1.101:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x250e6497c8a0000, likely server has closed socket, closing socket connection and attempting reconnect
2015-11-18 16:29:57,403 WARN  [master,16000,1446972588401_ChoreService_1] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=192.168.1.101:2181,192.168.1.102:2181,192.168.1.106:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/backup-masters
2015-11-18 16:29:58,875 INFO  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Opening socket connection to server 192.168.1.106/192.168.1.106:2181. Will not attempt to authenticate using SASL (unknown error)
2015-11-18 16:29:58,876 INFO  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Socket connection established to 192.168.1.106/192.168.1.106:2181, initiating session
2015-11-18 16:29:58,878 INFO  [main-SendThread(192.168.1.106:2181)] zookeeper.ClientCnxn: Session establishment complete on server 192.168.1.106/192.168.1.106:2181, sessionid = 0x250e6497c8a0000, negotiated timeout = 90000
